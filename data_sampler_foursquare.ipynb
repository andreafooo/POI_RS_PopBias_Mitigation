{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "\n",
    "dataset = \"foursquarenyc\"\n",
    "\n",
    "DATASET_DIR = f\"/Volumes/Forster Neu/Masterarbeit Data/{dataset}_dataset/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkin_df = pd.read_csv(DATASET_DIR + \"foursquare_data.csv\", sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkin_df.rename(columns={\"userId\": \"user_id\", \"venueId\": \"business_id\", \"venueCategoryId\" : \"category_id\", \"utcTimestamp\": \"timestamp\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1083"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkin_df[\"user_id\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of users, number of POIs 2293 61858\n",
      "Sparsity: 0.9959552918331572\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of users, number of POIs\", len(checkin_df[\"user_id\"].unique()), len(checkin_df[\"business_id\"].unique())\n",
    ")\n",
    "print(\"Sparsity:\", 1 - len(checkin_df) / (len(checkin_df[\"user_id\"].unique()) * len(checkin_df[\"business_id\"].unique())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_df(df, min_reviews=10):\n",
    "    while True:\n",
    "        # Filter businesses with at least min_reviews reviews\n",
    "        business_counts = df[\"business_id\"].value_counts()\n",
    "        business_mask = df['business_id'].map(business_counts) >= min_reviews\n",
    "        df_filtered = df.loc[business_mask]\n",
    "\n",
    "        # Filter users with at least min_reviews reviews\n",
    "        user_counts = df_filtered['user_id'].value_counts()\n",
    "        user_mask = df_filtered['user_id'].map(user_counts) >= min_reviews\n",
    "        df_filtered = df_filtered.loc[user_mask]\n",
    "\n",
    "        # If the size of the filtered DataFrame didn't change, break the loop\n",
    "        if df_filtered.shape[0] == df.shape[0]:\n",
    "            break\n",
    "\n",
    "        # Update the DataFrame for the next iteration\n",
    "        df = df_filtered\n",
    "\n",
    "    return df_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkin_df_filtered = filter_df(checkin_df, min_reviews=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "sep_num = int(checkin_df_filtered[\"user_id\"].nunique()/3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Calculate the value counts of `business_id`\n",
    "value_counts = checkin_df_filtered['business_id'].value_counts().reset_index()\n",
    "value_counts.columns = ['business_id', 'count']\n",
    "\n",
    "# Step 2: Normalize the counts y dividing by the maximum value count\n",
    "max_count = value_counts['count'].max()\n",
    "value_counts['business_popularity'] = value_counts['count'] / max_count\n",
    "\n",
    "# Step 3: Merge the normalized counts back into the original DataFrame\n",
    "checkin_df_filtered = checkin_df_filtered.merge(value_counts[['business_id', 'business_popularity']], on='business_id', how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_popularity_calculator(checkin_df_filtered, sep_num):\n",
    "    # Filter out instances with the specified business_id\n",
    "    try:\n",
    "        checkin_df_filtered = checkin_df_filtered[checkin_df_filtered['business_id'] != \"00000000000000000000000000000000\"]\n",
    "    except Exception as e:\n",
    "        print(\"No such field found to filter out\")\n",
    "    # Calculate average popularity per user\n",
    "    average_popularity_per_user = checkin_df_filtered.groupby('user_id')['business_popularity'].mean().reset_index()\n",
    "    average_popularity_per_user.columns = ['user_id', 'average_popularity']\n",
    "\n",
    "    average_popularity_per_user = average_popularity_per_user.sort_values(by=\"average_popularity\", ascending=False)\n",
    "\n",
    "    \n",
    "    # Sort by average popularity\n",
    "    \n",
    "\n",
    "    # Get top 1000 users\n",
    "    high_pop_user_df_sample = average_popularity_per_user.head(sep_num)\n",
    "    \n",
    "    # Get the middle 1000 users around the median\n",
    "    median_index = len(average_popularity_per_user) // 2\n",
    "    start_med_index = max(median_index -int (sep_num/2), 0)\n",
    "    end_med_index = min(median_index + int(sep_num/2), len(average_popularity_per_user))\n",
    "    med_pop_user_df_sample = average_popularity_per_user.iloc[start_med_index:end_med_index]\n",
    "    \n",
    "    # Get the lowest 1000 users\n",
    "    low_pop_user_df_sample = average_popularity_per_user.tail(sep_num)\n",
    "\n",
    "    unique_users = list(set(high_pop_user_df_sample[\"user_id\"].tolist() + med_pop_user_df_sample[\"user_id\"].tolist() + low_pop_user_df_sample[\"user_id\"].tolist()))\n",
    "\n",
    "    checkin_df_sample = checkin_df_filtered[checkin_df_filtered[\"user_id\"].isin(unique_users)]\n",
    "\n",
    "    checkin_df_sample = filter_df(checkin_df_sample, min_reviews=10)\n",
    "\n",
    "    checkin_df_sample = checkin_df_sample[checkin_df_sample[\"user_id\"].isin(unique_users)]\n",
    "\n",
    "\n",
    "    \n",
    "    return checkin_df_sample, high_pop_user_df_sample, med_pop_user_df_sample, low_pop_user_df_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkin_df_sample, high_pop_user_df_sample, medium_pop_user_df_sample, low_pop_user_df_sample = user_popularity_calculator(checkin_df_filtered, sep_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2292"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(checkin_df_sample[\"user_id\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "764"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(low_pop_user_df_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def data_sample_maker(high_pop_user_df, medium_pop_user_df, low_pop_user_df, checkin_df_filtered):\n",
    "#     # sampling not necessary because the dataset is so small\n",
    "\n",
    "#     high_pop_user_df_sample = high_pop_user_df.copy()\n",
    "#     medium_pop_user_df_sample = medium_pop_user_df.copy()\n",
    "#     low_pop_user_df_sample = low_pop_user_df.copy()\n",
    "\n",
    "#     unique_users = list(set(high_pop_user_df_sample[\"user_id\"].tolist() + medium_pop_user_df_sample[\"user_id\"].tolist() + low_pop_user_df_sample[\"user_id\"].tolist()))\n",
    "\n",
    "#     checkin_df_sample = checkin_df_filtered.loc[checkin_df_filtered[\"user_id\"].isin(unique_users)]\n",
    "\n",
    "#     return checkin_df_sample, high_pop_user_df_sample, medium_pop_user_df_sample, low_pop_user_df_sample\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkin_df_sample, high_pop_user_df_sample, medium_pop_user_df_sample, low_pop_user_df_sample = data_sample_maker(high_pop_user_df, medium_pop_user_df, low_pop_user_df, checkin_df_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_saver(df, filename, framework):\n",
    "    if not os.path.exists(DATASET_DIR + \"processed_data_\" + framework):\n",
    "        os.makedirs(DATASET_DIR + \"processed_data_\" + framework)\n",
    "    \n",
    "    df.to_csv(DATASET_DIR + \"processed_data_\" + framework + \"/\" + filename + \".csv\")\n",
    "    print(\"Data saved as \" + framework + filename + \".csv\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved as cornacuser_events.csv\n",
      "Data saved as cornachigh_pop_user_sample.csv\n",
      "Data saved as cornacmedium_pop_user_sample.csv\n",
      "Data saved as cornaclow_pop_user_sample.csv\n"
     ]
    }
   ],
   "source": [
    "# first of all saving data for cornac\n",
    "data_saver(checkin_df_sample, \"user_events\", \"cornac\")\n",
    "data_saver(high_pop_user_df_sample, \"high_pop_user_sample\", \"cornac\")\n",
    "data_saver(medium_pop_user_df_sample, \"medium_pop_user_sample\", \"cornac\")\n",
    "data_saver(low_pop_user_df_sample, \"low_pop_user_sample\", \"cornac\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_saver_recbole(df, framework, suffix):\n",
    "    \n",
    "    if not os.path.exists(DATASET_DIR + \"processed_data_\" + framework):\n",
    "        os.makedirs(DATASET_DIR + \"processed_data_\" + framework)\n",
    "\n",
    "    df.to_csv(f\"{DATASET_DIR}processed_data_{framework}/{dataset}_sample.{suffix}\", sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkin_df_sample['review_id'] = range(1, len(checkin_df_sample) + 1)\n",
    "# Step 1: Group by user_id and business_id and count check-ins\n",
    "checkin_df_sample['checkin_count'] = checkin_df_sample.groupby(['user_id', 'business_id'])['business_id'].transform('count')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "business_sample = checkin_df_sample.groupby('business_id').first().reset_index()\n",
    "business_sample.rename(columns={\"latitude\":\"lat\", \"longitude\":\"lon\"}, inplace=True)\n",
    "business_sample = business_sample[[\"business_id\", \"lat\", \"lon\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_df_sample = checkin_df_sample.groupby('user_id').size().reset_index(name='review_counts:float')\n",
    "checkin_df_sample = checkin_df_sample[[\"review_id\",\"user_id\",\"business_id\",\"timestamp\", \"checkin_count\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_unix_timestamp(df, column_name):\n",
    "    \"\"\"\n",
    "    Convert a column of timestamps in a DataFrame to Unix timestamps.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The DataFrame containing the timestamp column.\n",
    "        column_name (str): The name of the column with timestamps in \"%Y-%m-%d %H:%M:%S\" format.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The DataFrame with an additional column for Unix timestamps.\n",
    "    \"\"\"\n",
    "    # Convert the column to datetime objects\n",
    "    df[column_name] = pd.to_datetime(df[column_name], format=\"mixed\")\n",
    "    \n",
    "    # Convert datetime objects to Unix timestamps\n",
    "    df[f'{column_name}'] = df[column_name].apply(lambda x: x.timestamp())\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkin_df_sample.rename(columns={\"user_id\":\"user_id:token\", \"business_id\":\"item_id:token\", \"checkin_count\":\"rating:float\", \"timestamp\":\"timestamp:float\", \"review_id\": \"review_id:token\"}, inplace=True)\n",
    "user_df_sample.rename(columns={\"user_id\":\"user_id:token\"}, inplace=True)\n",
    "business_sample.rename(columns={\"business_id\": \"item_id:token\", \"lat\" : \"lat:float\", \"lon\" : \"lon:float\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkin_df_sample = convert_to_unix_timestamp(checkin_df_sample, \"timestamp:float\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkin_df_sample = checkin_df_sample.loc[checkin_df_sample[\"rating:float\"] < 100]\n",
    "\n",
    "checkin_df_sample.sort_values(by=\"rating:float\", ascending=False)\n",
    "\n",
    "checkin_df_timestamps = checkin_df_sample.copy()\n",
    "\n",
    "checkin_df_sample = checkin_df_sample.drop_duplicates(subset=[\"user_id:token\", \"item_id:token\"], keep=\"first\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id:token</th>\n",
       "      <th>lat:float</th>\n",
       "      <th>lon:float</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4b058799f964a5208b9b22e3</td>\n",
       "      <td>35.690712</td>\n",
       "      <td>139.691119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4b058799f964a5208d9b22e3</td>\n",
       "      <td>35.672271</td>\n",
       "      <td>139.758711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4b058799f964a520929b22e3</td>\n",
       "      <td>35.687043</td>\n",
       "      <td>139.698871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4b058799f964a520959b22e3</td>\n",
       "      <td>35.670580</td>\n",
       "      <td>139.727849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4b058799f964a520979b22e3</td>\n",
       "      <td>35.690062</td>\n",
       "      <td>139.694569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7866</th>\n",
       "      <td>50dce1a4e4b0f3777e14560e</td>\n",
       "      <td>35.630669</td>\n",
       "      <td>139.795103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7867</th>\n",
       "      <td>50e137f4e4b0073eb57aeeb6</td>\n",
       "      <td>35.697748</td>\n",
       "      <td>139.564680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7868</th>\n",
       "      <td>50f351a3e4b077d65674c57d</td>\n",
       "      <td>35.650417</td>\n",
       "      <td>139.757541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7869</th>\n",
       "      <td>50f91a7fe4b0b1597b2c6f3a</td>\n",
       "      <td>35.642719</td>\n",
       "      <td>139.608459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7870</th>\n",
       "      <td>5101b557e4b0b1a795af716f</td>\n",
       "      <td>35.834554</td>\n",
       "      <td>139.579402</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7871 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 item_id:token  lat:float   lon:float\n",
       "0     4b058799f964a5208b9b22e3  35.690712  139.691119\n",
       "1     4b058799f964a5208d9b22e3  35.672271  139.758711\n",
       "2     4b058799f964a520929b22e3  35.687043  139.698871\n",
       "3     4b058799f964a520959b22e3  35.670580  139.727849\n",
       "4     4b058799f964a520979b22e3  35.690062  139.694569\n",
       "...                        ...        ...         ...\n",
       "7866  50dce1a4e4b0f3777e14560e  35.630669  139.795103\n",
       "7867  50e137f4e4b0073eb57aeeb6  35.697748  139.564680\n",
       "7868  50f351a3e4b077d65674c57d  35.650417  139.757541\n",
       "7869  50f91a7fe4b0b1597b2c6f3a  35.642719  139.608459\n",
       "7870  5101b557e4b0b1a795af716f  35.834554  139.579402\n",
       "\n",
       "[7871 rows x 3 columns]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "business_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_saver_recbole(checkin_df_sample, \"recbole\", \"inter\")\n",
    "data_saver_recbole(user_df_sample, \"recbole\", \"user\")\n",
    "data_saver_recbole(business_sample, \"recbole\", \"item\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reverting to unix timestamps and only using the necessary columns\n",
    "review_df_sample = checkin_df_sample.copy()\n",
    "checkins_capri_min = checkin_df_timestamps[[\"user_id:token\", \"item_id:token\", \"timestamp:float\"]]\n",
    "\n",
    "checkins_capri_train_test_tune = review_df_sample[[\"user_id:token\", \"item_id:token\", \"timestamp:float\", \"rating:float\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of users:  2292\n",
      "Length of POIs:  7855\n"
     ]
    }
   ],
   "source": [
    "len(checkins_capri_min[\"user_id:token\"].unique())\n",
    "len(checkins_capri_min[\"item_id:token\"].unique())\n",
    "\n",
    "print(\"Length of users: \", len(checkins_capri_min[\"user_id:token\"].unique()))\n",
    "print(\"Length of POIs: \", len(checkins_capri_min[\"item_id:token\"].unique()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FINAL 3\n",
    "datasize_capri = pd.DataFrame(data={\"num_users\" : [len(checkins_capri_min[\"user_id:token\"].unique())], \"num_items\" : [len(checkins_capri_min[\"item_id:token\"].unique())]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FINAL 4\n",
    "poi_coos_capri = business_sample.copy()\n",
    "user_df_sample = pd.concat([high_pop_user_df_sample, medium_pop_user_df_sample, low_pop_user_df_sample])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id:token</th>\n",
       "      <th>item_id:token</th>\n",
       "      <th>timestamp:float</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>114</td>\n",
       "      <td>4c16fdda96040f477cc473a5</td>\n",
       "      <td>1.333480e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>114</td>\n",
       "      <td>4b3eae5cf964a520b4a025e3</td>\n",
       "      <td>1.333482e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2033</td>\n",
       "      <td>4b5c7671f964a520083129e3</td>\n",
       "      <td>1.333483e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>589</td>\n",
       "      <td>4b5ed39cf964a520079a29e3</td>\n",
       "      <td>1.333483e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>589</td>\n",
       "      <td>4e014c11c65b896d116d480c</td>\n",
       "      <td>1.333483e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447565</th>\n",
       "      <td>2277</td>\n",
       "      <td>4b82669cf964a5209ed130e3</td>\n",
       "      <td>1.360982e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447566</th>\n",
       "      <td>2277</td>\n",
       "      <td>4b56c4c5f964a520c41a28e3</td>\n",
       "      <td>1.360982e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447567</th>\n",
       "      <td>326</td>\n",
       "      <td>4bab3456f964a5204d993ae3</td>\n",
       "      <td>1.360982e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447568</th>\n",
       "      <td>853</td>\n",
       "      <td>4b559c09f964a520efe827e3</td>\n",
       "      <td>1.360982e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447569</th>\n",
       "      <td>1050</td>\n",
       "      <td>4b5a7486f964a52027c628e3</td>\n",
       "      <td>1.360982e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>404408 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_id:token             item_id:token  timestamp:float\n",
       "0                 114  4c16fdda96040f477cc473a5     1.333480e+09\n",
       "1                 114  4b3eae5cf964a520b4a025e3     1.333482e+09\n",
       "3                2033  4b5c7671f964a520083129e3     1.333483e+09\n",
       "4                 589  4b5ed39cf964a520079a29e3     1.333483e+09\n",
       "5                 589  4e014c11c65b896d116d480c     1.333483e+09\n",
       "...               ...                       ...              ...\n",
       "447565           2277  4b82669cf964a5209ed130e3     1.360982e+09\n",
       "447566           2277  4b56c4c5f964a520c41a28e3     1.360982e+09\n",
       "447567            326  4bab3456f964a5204d993ae3     1.360982e+09\n",
       "447568            853  4b559c09f964a520efe827e3     1.360982e+09\n",
       "447569           1050  4b5a7486f964a52027c628e3     1.360982e+09\n",
       "\n",
       "[404408 rows x 3 columns]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkins_capri_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9q/p0b6nwnd5071040x3849mdvc0000gn/T/ipykernel_94972/352362220.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  checkins_capri_min['user_id_int'], user_id_map = pd.factorize(checkins_capri_min['user_id:token'])\n"
     ]
    }
   ],
   "source": [
    "checkins_capri_min['user_id_int'], user_id_map = pd.factorize(checkins_capri_min['user_id:token'])\n",
    "checkins_capri_min['business_id_int'], business_id_map = pd.factorize(checkins_capri_min['item_id:token'])\n",
    "\n",
    "# FINAL 2.0\n",
    "checkins_capri_min_int = checkins_capri_min[[\"user_id_int\", \"business_id_int\", \"timestamp:float\"]]\n",
    "# Create mapping dictionaries\n",
    "user_id_mapping = {original: i for i, original in enumerate(user_id_map)}\n",
    "business_id_mapping = {original: j for j, original in enumerate(business_id_map)}\n",
    "\n",
    "poi_coos_capri[\"business_id_int\"] = poi_coos_capri[\"item_id:token\"].map(business_id_mapping)\n",
    "# FINAL 2.0\n",
    "poi_coos_capri_int = poi_coos_capri[[\"business_id_int\", \"lat:float\", \"lon:float\"]]\n",
    "\n",
    "\n",
    "# FINAL 2.0\n",
    "\n",
    "checkins_capri_train_test_tune['user_id_int'] = checkins_capri_train_test_tune['user_id:token'].map(user_id_mapping)\n",
    "checkins_capri_train_test_tune['business_id_int'] = checkins_capri_train_test_tune['item_id:token'].map(business_id_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkins_capri_train_test_tune = checkins_capri_train_test_tune[[\"user_id_int\", \"business_id_int\", \"rating:float\", \"timestamp:float\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9q/p0b6nwnd5071040x3849mdvc0000gn/T/ipykernel_94972/2553544415.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  poi_coos_capri_int.dropna(inplace=True)\n",
      "/var/folders/9q/p0b6nwnd5071040x3849mdvc0000gn/T/ipykernel_94972/2553544415.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  poi_coos_capri_int[\"business_id_int\"] = poi_coos_capri_int[\"business_id_int\"].astype(int)\n"
     ]
    }
   ],
   "source": [
    "poi_coos_capri_int.dropna(inplace=True)\n",
    "poi_coos_capri_int[\"business_id_int\"] = poi_coos_capri_int[\"business_id_int\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "remaining_businesses = poi_coos_capri_int[\"business_id_int\"].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_remaining_businesses(df, remaining_businesses):\n",
    "    return df[df[\"business_id_int\"].isin(remaining_businesses)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Set:\n",
      "      user_id_int  business_id_int  rating:float\n",
      "0               0                0             1\n",
      "1               0                1            25\n",
      "16              0               15             1\n",
      "5686            0              116             3\n",
      "5712            0             2366             1\n",
      "\n",
      "Validation Set:\n",
      "        user_id_int  business_id_int  rating:float\n",
      "121461            0             2739             1\n",
      "121505            0              185             1\n",
      "121525            0              401             1\n",
      "121558            0               65             1\n",
      "121779            0             4120             1\n",
      "\n",
      "Test Set:\n",
      "        user_id_int  business_id_int  rating:float\n",
      "127808            0             5811             2\n",
      "138497            0              820             1\n",
      "138696            0             6765             1\n",
      "139514            0              571             1\n",
      "157393            0               67             1\n"
     ]
    }
   ],
   "source": [
    "# splitting the data into train, test, and tune\n",
    "checkins_capri_train_test_tune = checkins_capri_train_test_tune.sort_values(by=[\"user_id_int\", \"timestamp:float\"])\n",
    "checkins_capri_train_test_tune = checkins_capri_train_test_tune[[\"user_id_int\", \"business_id_int\", \"rating:float\"]]\n",
    "\n",
    "# Split the data\n",
    "train_list = []\n",
    "val_list = []\n",
    "test_list = []\n",
    "\n",
    "for user, group in checkins_capri_train_test_tune.groupby('user_id_int'):\n",
    "    n = len(group)\n",
    "    train_end = int(n * 0.65)\n",
    "    val_end = int(n * 0.80)\n",
    "    \n",
    "    train_list.append(group.iloc[:train_end])\n",
    "    val_list.append(group.iloc[train_end:val_end])\n",
    "    test_list.append(group.iloc[val_end:])\n",
    "\n",
    "# Combine lists into DataFrames\n",
    "train_df = pd.concat(train_list)\n",
    "val_df = pd.concat(val_list)\n",
    "test_df = pd.concat(test_list)\n",
    "\n",
    "\n",
    "\n",
    "# Check the splits\n",
    "\n",
    "# FINAL 6-8\n",
    "print(\"Train Set:\")\n",
    "print(train_df.head())\n",
    "print(\"\\nValidation Set:\")\n",
    "print(val_df.head())\n",
    "print(\"\\nTest Set:\")\n",
    "print(test_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id_int</th>\n",
       "      <th>business_id_int</th>\n",
       "      <th>rating:float</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5686</th>\n",
       "      <td>0</td>\n",
       "      <td>116</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5712</th>\n",
       "      <td>0</td>\n",
       "      <td>2366</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419845</th>\n",
       "      <td>2291</td>\n",
       "      <td>130</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419904</th>\n",
       "      <td>2291</td>\n",
       "      <td>1942</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420315</th>\n",
       "      <td>2291</td>\n",
       "      <td>156</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421981</th>\n",
       "      <td>2291</td>\n",
       "      <td>903</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428055</th>\n",
       "      <td>2291</td>\n",
       "      <td>888</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>77769 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_id_int  business_id_int  rating:float\n",
       "0                 0                0             1\n",
       "1                 0                1            25\n",
       "16                0               15             1\n",
       "5686              0              116             3\n",
       "5712              0             2366             1\n",
       "...             ...              ...           ...\n",
       "419845         2291              130             1\n",
       "419904         2291             1942             1\n",
       "420315         2291              156             1\n",
       "421981         2291              903             4\n",
       "428055         2291              888             1\n",
       "\n",
       "[77769 rows x 3 columns]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def datasaver_capri(df, filename):\n",
    "    \n",
    "    if not os.path.exists(DATASET_DIR + \"processed_data_capri\"):\n",
    "        os.makedirs(DATASET_DIR + \"processed_data_capri\")\n",
    "    \n",
    "    df.to_csv(DATASET_DIR + \"processed_data_capri/\" + filename + \".txt\", sep='\\t', index=False, header=False)\n",
    "    print(\"Data saved as \" + filename + \".txt\")\n",
    "    \n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id_int</th>\n",
       "      <th>business_id_int</th>\n",
       "      <th>timestamp:float</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.333480e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.333482e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.333483e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1.333483e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1.333483e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447565</th>\n",
       "      <td>2279</td>\n",
       "      <td>6492</td>\n",
       "      <td>1.360982e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447566</th>\n",
       "      <td>2279</td>\n",
       "      <td>566</td>\n",
       "      <td>1.360982e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447567</th>\n",
       "      <td>667</td>\n",
       "      <td>2102</td>\n",
       "      <td>1.360982e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447568</th>\n",
       "      <td>2276</td>\n",
       "      <td>1127</td>\n",
       "      <td>1.360982e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447569</th>\n",
       "      <td>746</td>\n",
       "      <td>3826</td>\n",
       "      <td>1.360982e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>404408 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_id_int  business_id_int  timestamp:float\n",
       "0                 0                0     1.333480e+09\n",
       "1                 0                1     1.333482e+09\n",
       "3                 1                2     1.333483e+09\n",
       "4                 2                3     1.333483e+09\n",
       "5                 2                4     1.333483e+09\n",
       "...             ...              ...              ...\n",
       "447565         2279             6492     1.360982e+09\n",
       "447566         2279              566     1.360982e+09\n",
       "447567          667             2102     1.360982e+09\n",
       "447568         2276             1127     1.360982e+09\n",
       "447569          746             3826     1.360982e+09\n",
       "\n",
       "[404408 rows x 3 columns]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkins_capri_min_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkins_capri_min_int = filter_remaining_businesses(checkins_capri_min_int, remaining_businesses)\n",
    "poi_coos_capri_int = filter_remaining_businesses(poi_coos_capri_int, remaining_businesses)\n",
    "datasize_capri = pd.DataFrame(data={\"num_users\" : [len(checkins_capri_min_int[\"user_id_int\"].unique())], \"num_items\" : [len(checkins_capri_min_int[\"business_id_int\"].unique())]})\n",
    "train_df = filter_remaining_businesses(train_df, remaining_businesses)\n",
    "val_df = filter_remaining_businesses(val_df, remaining_businesses)\n",
    "test_df = filter_remaining_businesses(test_df, remaining_businesses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved as checkins.txt\n",
      "Data saved as dataSize.txt\n",
      "Data saved as poiCoos.txt\n",
      "Data saved as train.txt\n",
      "Data saved as tune.txt\n",
      "Data saved as test.txt\n"
     ]
    }
   ],
   "source": [
    "datasaver_capri(checkins_capri_min_int, \"checkins\")\n",
    "datasaver_capri(datasize_capri, \"dataSize\")\n",
    "datasaver_capri(poi_coos_capri_int, \"poiCoos\")\n",
    "datasaver_capri(train_df, \"train\")\n",
    "datasaver_capri(val_df, \"tune\")\n",
    "datasaver_capri(test_df, \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prep_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
