{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from globals import BASE_DIR, available_datasets\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_user_events(user_events, user_groups):\n",
    "    stats = {}\n",
    "    for group in user_groups.keys():\n",
    "        stats[group] = {}\n",
    "        user_events_group = user_events.copy()\n",
    "        user_events_group = user_events_group.loc[user_events_group[\"user_id:token\"].isin(user_groups[group])]\n",
    "        user_dist = user_events_group[\"user_id:token\"].value_counts()\n",
    "        stats[group][\"num_users\"] = user_dist.shape[0]\n",
    "        stats[group][\"mean_checkins\"] = user_events_group[\"user_id:token\"].value_counts().mean()\n",
    "        stats[group][\"min_checkins\"] = user_events_group[\"user_id:token\"].value_counts().min()\n",
    "        stats[group][\"max_checkins\"] = user_events_group[\"user_id:token\"].value_counts().max()\n",
    "        item_dist = user_events_group[\"item_id:token\"].value_counts()\n",
    "        stats[group][\"num_items\"] = item_dist.shape[0]\n",
    "        stats[group][\"num_checkins\"] = user_events_group.shape[0]\n",
    "        stats[group][\"sparsity\"] = 1 - len(user_events_group) / (len(user_events_group[\"user_id:token\"].unique()) * len(user_events_group[\"item_id:token\"].unique()))\n",
    "\n",
    "    return stats\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_stats = {}\n",
    "for dataset in available_datasets:\n",
    "    train_data = pd.read_csv(f\"{BASE_DIR}{dataset}_dataset/processed_data_recbole/{dataset}_sample.train.inter\", sep=\"\\t\")\n",
    "    test_data = pd.read_csv(f\"{BASE_DIR}{dataset}_dataset/processed_data_recbole/{dataset}_sample.test.inter\", sep=\"\\t\")\n",
    "    valid_data = pd.read_csv(f\"{BASE_DIR}{dataset}_dataset/processed_data_recbole/{dataset}_sample.valid.inter\", sep=\"\\t\")\n",
    "\n",
    "    user_group_dir = f\"{BASE_DIR}{dataset}_dataset/{dataset}_user_id_popularity.json\"\n",
    "    with open(user_group_dir) as f:\n",
    "        user_groups = json.load(f)\n",
    "\n",
    "\n",
    "    all_user_ids = (\n",
    "    set(user_groups[\"high\"])\n",
    "    | set(user_groups[\"medium\"])\n",
    "    | set(user_groups[\"low\"])\n",
    "    )\n",
    "    user_groups[\"all\"] = list(all_user_ids)\n",
    "    user_events = pd.concat([train_data, valid_data, test_data])\n",
    "    user_events = user_events.drop_duplicates(subset=[\"user_id:token\", \"item_id:token\"])\n",
    "\n",
    "    full_stats[dataset] = group_user_events(user_events, user_groups)\n",
    "\n",
    "long_format_df = []\n",
    "\n",
    "for dataset, group_stats in full_stats.items():\n",
    "    for group, metrics in group_stats.items():\n",
    "        row = {\"dataset\": dataset, \"group\": group}\n",
    "        row.update(metrics)\n",
    "        long_format_df.append(row)\n",
    "\n",
    "\n",
    "long_format_df = pd.DataFrame(long_format_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>group</th>\n",
       "      <th>num_users</th>\n",
       "      <th>mean_checkins</th>\n",
       "      <th>min_checkins</th>\n",
       "      <th>max_checkins</th>\n",
       "      <th>num_items</th>\n",
       "      <th>num_checkins</th>\n",
       "      <th>sparsity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>foursquaretky</td>\n",
       "      <td>high</td>\n",
       "      <td>300</td>\n",
       "      <td>32.340000</td>\n",
       "      <td>15</td>\n",
       "      <td>69</td>\n",
       "      <td>1992</td>\n",
       "      <td>9702</td>\n",
       "      <td>0.983765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>foursquaretky</td>\n",
       "      <td>medium</td>\n",
       "      <td>900</td>\n",
       "      <td>53.182222</td>\n",
       "      <td>15</td>\n",
       "      <td>168</td>\n",
       "      <td>2803</td>\n",
       "      <td>47864</td>\n",
       "      <td>0.981027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>foursquaretky</td>\n",
       "      <td>low</td>\n",
       "      <td>300</td>\n",
       "      <td>39.450000</td>\n",
       "      <td>15</td>\n",
       "      <td>271</td>\n",
       "      <td>2608</td>\n",
       "      <td>11835</td>\n",
       "      <td>0.984873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>foursquaretky</td>\n",
       "      <td>all</td>\n",
       "      <td>1500</td>\n",
       "      <td>46.267333</td>\n",
       "      <td>15</td>\n",
       "      <td>271</td>\n",
       "      <td>2804</td>\n",
       "      <td>69401</td>\n",
       "      <td>0.983500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         dataset   group  num_users  mean_checkins  min_checkins  \\\n",
       "0  foursquaretky    high        300      32.340000            15   \n",
       "1  foursquaretky  medium        900      53.182222            15   \n",
       "2  foursquaretky     low        300      39.450000            15   \n",
       "3  foursquaretky     all       1500      46.267333            15   \n",
       "\n",
       "   max_checkins  num_items  num_checkins  sparsity  \n",
       "0            69       1992          9702  0.983765  \n",
       "1           168       2803         47864  0.981027  \n",
       "2           271       2608         11835  0.984873  \n",
       "3           271       2804         69401  0.983500  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "long_format_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_all_users = long_format_df.loc[long_format_df[\"group\"] == \"all\"]\n",
    "stats_all_users.to_csv(f\"{BASE_DIR}/descriptive_stats.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prep_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
