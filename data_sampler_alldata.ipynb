{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "from globals import BASE_DIR\n",
    "\n",
    "include_categories = False\n",
    "\n",
    "dataset = \"foursquaretky\"\n",
    "\n",
    "DATASET_DIR = f\"{BASE_DIR}{dataset}_dataset/\"\n",
    "#DATASET_DIR = f\"/Users/andreaforster/Documents/data_thesis/{dataset}_dataset/\"\n",
    "\n",
    "\n",
    "available_datasets = [\"foursquaretky\", \"yelp\", \"gowalla\", \"brightkite\", \"snowcard\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_big_json(file_path):\n",
    "    data = []\n",
    "\n",
    "    # Open the file and read it line by line\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            # Parse the JSON data and append to the list\n",
    "            data.append(json.loads(line))\n",
    "\n",
    "    # Create a DataFrame from the list of records\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_unix_timestamp(df, column_name):\n",
    "    \"\"\"\n",
    "    Convert a column of timestamps in a DataFrame to Unix timestamps.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The DataFrame containing the timestamp column.\n",
    "        column_name (str): The name of the column with timestamps in \"%Y-%m-%d %H:%M:%S\" format.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The DataFrame with an additional column for Unix timestamps.\n",
    "    \"\"\"\n",
    "    # Convert the column to datetime objects\n",
    "    df[column_name] = pd.to_datetime(df[column_name], format=\"mixed\")\n",
    "    \n",
    "    # Convert datetime objects to Unix timestamps\n",
    "    df[f'{column_name}'] = df[column_name].apply(lambda x: x.timestamp())\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dataset == \"snowcard\":\n",
    "    checkin_df = pd.read_csv(DATASET_DIR+\"TSC_EEL_EXPORT.csv\", encoding=\"latin1\", sep=\";\", header=None, names=[\"timestamp:float\", \"user_id:token\", \"category_id:token\", \"category_name:token_seq\", \"name:token_seq\", \"user_type:token_seq\"])\n",
    "    checkin_df[\"item_id:token\"], item_id = pd.factorize(checkin_df[\"name:token_seq\"])\n",
    "    user_df = checkin_df[[\"user_id:token\", \"user_type:token_seq\"]].drop_duplicates(subset=[\"user_id:token\"])\n",
    "    poi_df = checkin_df[[\"item_id:token\", \"name:token_seq\", \"category_id:token\", \"category_name:token_seq\"]].drop_duplicates(subset=[\"item_id:token\"])\n",
    "    coordinates_df = pd.read_excel(DATASET_DIR+\"snowcard_lifts.xlsx\")\n",
    "    coordinates_df[[\"lat:float\", \"lon:float\"]] = coordinates_df[\"lat_lon\"].str.split(', ', expand=True)\n",
    "    coordinates_df.drop(columns=[\"lat_lon\"], inplace=True)\n",
    "    poi_df = pd.merge(poi_df, coordinates_df[['category_name:token_seq', 'lat:float', 'lon:float']], on='category_name:token_seq', how='left')\n",
    "    checkin_df = checkin_df[[\"user_id:token\", \"item_id:token\", \"timestamp:float\"]]\n",
    "\n",
    "elif dataset == \"foursquarenyc\" or dataset == \"foursquaretky\":\n",
    "    checkin_df = pd.read_csv(DATASET_DIR + \"foursquare_data.csv\", sep=\",\")\n",
    "    checkin_df = checkin_df.drop(columns=[\"timezoneOffset\"])\n",
    "    checkin_df = checkin_df.rename(columns={\"venueId\": \"item_id:token\", \"venueCategoryId\": \"category_id:token\", \"venueCategory\": \"category_name:token_seq\", \"userId\": \"user_id:token\", \"utcTimestamp\": \"timestamp:float\", \"latitude\": \"lat:float\", \"longitude\": \"lon:float\"})\n",
    "    user_df = checkin_df[[\"user_id:token\"]].drop_duplicates()\n",
    "\n",
    "    poi_df = checkin_df[[\"item_id:token\", \"category_id:token\", \"category_name:token_seq\", \"lat:float\", \"lon:float\"]].drop_duplicates(subset=[\"item_id:token\"])\n",
    "    checkin_df = checkin_df[[\"user_id:token\", \"item_id:token\", \"timestamp:float\"]]\n",
    "\n",
    "elif dataset == \"gowalla\" or dataset == \"brightkite\":\n",
    "    checkin_df = pd.read_csv(DATASET_DIR + f\"loc-{dataset}_totalCheckins.txt\", sep=\"\\t\", header=None, names=['user_id:token', 'timestamp:float', 'lat:float', 'lon:float', 'item_id:token'])\n",
    "    checkin_df = checkin_df[~checkin_df['item_id:token'].isin([\"00000000000000000000000000000000\", \"ede07eeea22411dda0ef53e233ec57ca\"])]\n",
    "    user_df = pd.read_csv(DATASET_DIR + f\"loc-{dataset}_edges.txt\", sep=\"\\t\", header=None, names=['user_id:token', 'friends:token_seq'])\n",
    "    user_df = user_df.groupby('user_id:token')['friends:token_seq'].apply(lambda x: ','.join(map(str, x))).reset_index()\n",
    "    user_df.columns = ['user_id:token', 'friends:token_seq']\n",
    "    poi_df = checkin_df[['item_id:token', \"lat:float\", \"lon:float\"]].drop_duplicates(subset=\"item_id:token\")\n",
    "    checkin_df = checkin_df.drop(columns=[\"lat:float\", \"lon:float\"])\n",
    "\n",
    "elif dataset == \"yelp\":\n",
    "    poi_df = pd.read_json(DATASET_DIR + \"yelp_academic_dataset_business.json\", lines=True)\n",
    "    poi_df = poi_df.loc[poi_df['is_open'] == 1]\n",
    "    poi_df = poi_df.drop(columns=[\"review_count\", \"stars\", \"hours\", \"is_open\", \"city\", \"state\", \"postal_code\", \"attributes\", \"address\"])\n",
    "    poi_df = poi_df.rename(columns={\"latitude\": \"lat:float\", \"longitude\": \"lon:float\", \"business_id\": \"item_id:token\", \"name\":\"name:token_seq\", \"categories\":\"category_name:token_seq\"})\n",
    "    user_df = open_big_json(DATASET_DIR + \"yelp_academic_dataset_user.json\")\n",
    "    user_df = user_df.drop(columns=[\"review_count\", \"name\", \"yelping_since\", \"useful\", \"funny\", \"cool\", \"elite\", \"fans\", \"compliment_hot\", \"average_stars\", \"compliment_more\", \"compliment_profile\", \"compliment_cute\", \"compliment_list\", \"compliment_note\", \"compliment_plain\", \"compliment_cool\", \"compliment_funny\", \"compliment_writer\", \"compliment_photos\"])\n",
    "    user_df = user_df.rename(columns={\"user_id\": \"user_id:token\", \"friends\": \"friends:token_seq\"})\n",
    "    checkin_df = open_big_json(DATASET_DIR + \"yelp_academic_dataset_review.json\")\n",
    "    checkin_df = checkin_df.drop(columns=[\"text\", \"cool\", \"stars\", \"useful\", \"funny\", \"review_id\"])\n",
    "    checkin_df = checkin_df.rename(columns={\"user_id\": \"user_id:token\", \"business_id\": \"item_id:token\", \"date\": \"timestamp:float\"})\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkin_df.sort_values(by=\"timestamp:float\", ascending=True, inplace=True)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# checkin_df['timestamp'] = pd.to_datetime(checkin_df['timestamp:float'], errors='coerce')\n",
    "\n",
    "# # Extract the year from the 'timestamp' column\n",
    "# checkin_df['year'] = checkin_df['timestamp'].dt.year\n",
    "\n",
    "# # Plot the histogram\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# checkin_df['year'].dropna().astype(int).hist(bins=range(int(checkin_df['year'].min()), int(checkin_df['year'].max()) + 1), edgecolor='black')\n",
    "# plt.title('Histogram of Check-ins by Year')\n",
    "# plt.xlabel('Year')\n",
    "# plt.ylabel('Number of Check-ins')\n",
    "# plt.grid(False)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dataset == \"yelp\":\n",
    "    checkin_df['timestamp'] = pd.to_datetime(checkin_df['timestamp:float'], errors='coerce')\n",
    "\n",
    "    # Extract the year from the 'timestamp' column\n",
    "    checkin_df['year'] = checkin_df['timestamp'].dt.year\n",
    "    checkin_df = checkin_df[checkin_df['year'] >= 2018]\n",
    "    checkin_df = checkin_df[checkin_df['year'] < 2020]\n",
    "    checkin_df.drop(columns=[\"year\", \"timestamp\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id:token</th>\n",
       "      <th>item_id:token</th>\n",
       "      <th>timestamp:float</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5687</th>\n",
       "      <td>439</td>\n",
       "      <td>4b56ed1df964a520801f28e3</td>\n",
       "      <td>Fri Apr 06 12:52:10 +0000 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5688</th>\n",
       "      <td>435</td>\n",
       "      <td>4b5bf1b0f964a5204d1e29e3</td>\n",
       "      <td>Fri Apr 06 12:52:16 +0000 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5689</th>\n",
       "      <td>1324</td>\n",
       "      <td>4b563f2ef964a520460728e3</td>\n",
       "      <td>Fri Apr 06 12:52:34 +0000 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5690</th>\n",
       "      <td>320</td>\n",
       "      <td>4bd6b3024e32d13a50f6c280</td>\n",
       "      <td>Fri Apr 06 12:52:35 +0000 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5691</th>\n",
       "      <td>1334</td>\n",
       "      <td>4b8f2ea8f964a520a84c33e3</td>\n",
       "      <td>Fri Apr 06 12:52:45 +0000 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331786</th>\n",
       "      <td>1753</td>\n",
       "      <td>4b243a7df964a520356424e3</td>\n",
       "      <td>Wed Sep 05 23:59:02 +0000 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331787</th>\n",
       "      <td>1607</td>\n",
       "      <td>4b3eab45f964a52095a025e3</td>\n",
       "      <td>Wed Sep 05 23:59:59 +0000 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333453</th>\n",
       "      <td>140</td>\n",
       "      <td>4ba252f3f964a52046ed37e3</td>\n",
       "      <td>Wed Sep 12 17:44:35 +0000 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333454</th>\n",
       "      <td>1932</td>\n",
       "      <td>4e805241cc2103f9386caa73</td>\n",
       "      <td>Wed Sep 12 17:56:40 +0000 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333455</th>\n",
       "      <td>1932</td>\n",
       "      <td>4bdae0083904a5932eac479e</td>\n",
       "      <td>Wed Sep 12 18:45:43 +0000 2012</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>573703 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_id:token             item_id:token  \\\n",
       "5687              439  4b56ed1df964a520801f28e3   \n",
       "5688              435  4b5bf1b0f964a5204d1e29e3   \n",
       "5689             1324  4b563f2ef964a520460728e3   \n",
       "5690              320  4bd6b3024e32d13a50f6c280   \n",
       "5691             1334  4b8f2ea8f964a520a84c33e3   \n",
       "...               ...                       ...   \n",
       "331786           1753  4b243a7df964a520356424e3   \n",
       "331787           1607  4b3eab45f964a52095a025e3   \n",
       "333453            140  4ba252f3f964a52046ed37e3   \n",
       "333454           1932  4e805241cc2103f9386caa73   \n",
       "333455           1932  4bdae0083904a5932eac479e   \n",
       "\n",
       "                       timestamp:float  \n",
       "5687    Fri Apr 06 12:52:10 +0000 2012  \n",
       "5688    Fri Apr 06 12:52:16 +0000 2012  \n",
       "5689    Fri Apr 06 12:52:34 +0000 2012  \n",
       "5690    Fri Apr 06 12:52:35 +0000 2012  \n",
       "5691    Fri Apr 06 12:52:45 +0000 2012  \n",
       "...                                ...  \n",
       "331786  Wed Sep 05 23:59:02 +0000 2012  \n",
       "331787  Wed Sep 05 23:59:59 +0000 2012  \n",
       "333453  Wed Sep 12 17:44:35 +0000 2012  \n",
       "333454  Wed Sep 12 17:56:40 +0000 2012  \n",
       "333455  Wed Sep 12 18:45:43 +0000 2012  \n",
       "\n",
       "[573703 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkin_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkin_df_timestamp = checkin_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 1: Group by user_id and business_id and count check-ins\n",
    "checkin_df['checkin_count:float'] = checkin_df.groupby(['user_id:token', 'item_id:token'])['item_id:token'].transform('count')\n",
    "checkin_df = checkin_df.drop_duplicates(subset=[\"user_id:token\", \"item_id:token\"], keep=\"first\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of users, number of POIs 2293 61858\n",
      "Sparsity: 0.9985056795598015\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of users, number of POIs\", len(checkin_df[\"user_id:token\"].unique()), len(checkin_df[\"item_id:token\"].unique())\n",
    ")\n",
    "print(\"Sparsity:\", 1 - len(checkin_df) / (len(checkin_df[\"user_id:token\"].unique()) * len(checkin_df[\"item_id:token\"].unique())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_df(df, min_reviews_user=15, min_reviews_business=1):\n",
    "    while True:\n",
    "\n",
    "        # Filter users with at least min_reviews reviews\n",
    "        user_counts = df['user_id:token'].value_counts()\n",
    "        user_mask = df['user_id:token'].map(user_counts) >= min_reviews_user\n",
    "        df_filtered = df.loc[user_mask]\n",
    "\n",
    "        # Filter businesses with at least min_reviews reviews\n",
    "        business_counts = df_filtered[\"item_id:token\"].value_counts()\n",
    "        business_mask = df_filtered['item_id:token'].map(business_counts) >= min_reviews_business\n",
    "        df_filtered = df_filtered.loc[business_mask]\n",
    "\n",
    "        \n",
    "\n",
    "        # If the size of the filtered DataFrame didn't change, break the loop\n",
    "        if df_filtered.shape[0] == df.shape[0]:\n",
    "            break\n",
    "\n",
    "        # Update the DataFrame for the next iteration\n",
    "        df = df_filtered\n",
    "\n",
    "    return df_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkin_df_filtered = filter_df(checkin_df, min_reviews_business=10, min_reviews_user=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkin_df_filtered[\"user_id:token\"].value_counts().min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2110"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkin_df_filtered[\"user_id:token\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2110, 2804)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkin_df_filtered[\"user_id:token\"].nunique(), checkin_df_filtered[\"item_id:token\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Calculate the value counts of `business_id`\n",
    "value_counts = checkin_df_filtered['item_id:token'].value_counts().reset_index()\n",
    "value_counts.columns = ['item_id:token', 'count']\n",
    "\n",
    "# Step 2: Normalize the counts y dividing by the maximum value count\n",
    "max_count = value_counts['count'].max()\n",
    "value_counts['business_popularity:float'] = value_counts['count'] / max_count\n",
    " \n",
    "# Step 3: Merge the normalized counts back into the original DataFrame\n",
    "checkin_df_filtered = checkin_df_filtered.merge(value_counts[['item_id:token', 'business_popularity:float']], on = \"item_id:token\", how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_popularity_sample_calculator(checkin_df_filtered, poi_df, user_df, sep_num, checkin_df_timestamp):\n",
    "    # Calculate average popularity per user\n",
    "    average_popularity_per_user = checkin_df_filtered.groupby('user_id:token')['business_popularity:float'].mean().reset_index()\n",
    "    average_popularity_per_user.columns = ['user_id:token', 'average_popularity']\n",
    "\n",
    "    average_popularity_per_user = average_popularity_per_user.sort_values(by=\"average_popularity\", ascending=False)\n",
    "\n",
    "    \n",
    "    # Sort by average popularity\n",
    "    \n",
    "\n",
    "    # Get top 1000 users\n",
    "    high_pop_user_df_sample = average_popularity_per_user.head(sep_num)\n",
    "    \n",
    "    # Get the middle 1000 users around the median\n",
    "    median_index = len(average_popularity_per_user) // 2\n",
    "    start_med_index = max(median_index -int (sep_num/2), 0)\n",
    "    end_med_index = min(median_index + int(sep_num/2), len(average_popularity_per_user))\n",
    "    med_pop_user_df_sample = average_popularity_per_user.iloc[start_med_index:end_med_index]\n",
    "    \n",
    "    # Get the lowest 1000 users\n",
    "    low_pop_user_df_sample = average_popularity_per_user.tail(sep_num)\n",
    "\n",
    "    unique_users = list(set(high_pop_user_df_sample[\"user_id:token\"].tolist() + med_pop_user_df_sample[\"user_id:token\"].tolist() + low_pop_user_df_sample[\"user_id:token\"].tolist()))\n",
    "\n",
    "    checkin_df_sample = checkin_df_filtered[checkin_df_filtered[\"user_id:token\"].isin(unique_users)]\n",
    "    checkin_df_sample = checkin_df_sample[checkin_df_sample[\"user_id:token\"].isin(unique_users)]\n",
    "\n",
    "    # unique_items = checkin_df_sample[\"item_id:token\"].unique()\n",
    "    # print(len(unique_items))\n",
    "\n",
    "    user_df_sample = user_df[user_df[\"user_id:token\"].isin(unique_users)]\n",
    "    poi_df_sample = poi_df[poi_df[\"item_id:token\"].isin(checkin_df_sample[\"item_id:token\"])]\n",
    "\n",
    "    checkin_df_sample = checkin_df_sample[checkin_df_sample[\"item_id:token\"].isin(poi_df_sample[\"item_id:token\"])]\n",
    "\n",
    "    checkin_df_timestamp = checkin_df_timestamp[checkin_df_timestamp[\"user_id:token\"].isin(unique_users)]\n",
    "    checkin_df_timestamp = checkin_df_timestamp[checkin_df_timestamp[\"item_id:token\"].isin(poi_df_sample[\"item_id:token\"])]\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    return checkin_df_sample, high_pop_user_df_sample, med_pop_user_df_sample, low_pop_user_df_sample, user_df_sample, poi_df_sample, checkin_df_timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n"
     ]
    }
   ],
   "source": [
    "if checkin_df_filtered[\"user_id:token\"].nunique() > 1500:\n",
    "    sep_num = 500\n",
    "else:\n",
    "    sep_num = checkin_df_filtered[\"user_id:token\"].nunique() // 3\n",
    "\n",
    "print(sep_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkin_df_sample, high_pop_user_df_sample, med_pop_user_df_sample, low_pop_user_df_sample, user_df_sample, poi_df_sample, checkin_df_timestamp = user_popularity_sample_calculator(checkin_df_filtered, poi_df, user_df, sep_num, checkin_df_timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2804"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkin_df_sample[\"item_id:token\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkin_df_sample[\"user_id:token\"].value_counts().min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkin_df_sample[\"item_id:token\"].value_counts().min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2804"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkin_df_timestamp[\"item_id:token\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1500"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkin_df_sample[\"user_id:token\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1500"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkin_df_timestamp[\"user_id:token\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id:token</th>\n",
       "      <th>average_popularity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1539</th>\n",
       "      <td>1663</td>\n",
       "      <td>0.375598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1255</th>\n",
       "      <td>1355</td>\n",
       "      <td>0.320627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1688</th>\n",
       "      <td>1826</td>\n",
       "      <td>0.315125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1878</th>\n",
       "      <td>2037</td>\n",
       "      <td>0.293083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1523</th>\n",
       "      <td>1647</td>\n",
       "      <td>0.292703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>692</th>\n",
       "      <td>751</td>\n",
       "      <td>0.161415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>558</th>\n",
       "      <td>603</td>\n",
       "      <td>0.161411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>961</td>\n",
       "      <td>0.161367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1865</th>\n",
       "      <td>2020</td>\n",
       "      <td>0.161305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>314</td>\n",
       "      <td>0.161305</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      user_id:token  average_popularity\n",
       "1539           1663            0.375598\n",
       "1255           1355            0.320627\n",
       "1688           1826            0.315125\n",
       "1878           2037            0.293083\n",
       "1523           1647            0.292703\n",
       "...             ...                 ...\n",
       "692             751            0.161415\n",
       "558             603            0.161411\n",
       "887             961            0.161367\n",
       "1865           2020            0.161305\n",
       "285             314            0.161305\n",
       "\n",
       "[500 rows x 2 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "high_pop_user_df_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id:token</th>\n",
       "      <th>average_popularity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2034</th>\n",
       "      <td>2211</td>\n",
       "      <td>0.142278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>803</th>\n",
       "      <td>873</td>\n",
       "      <td>0.142158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>452</td>\n",
       "      <td>0.142158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1410</th>\n",
       "      <td>1529</td>\n",
       "      <td>0.142045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021</th>\n",
       "      <td>2198</td>\n",
       "      <td>0.141976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>65</td>\n",
       "      <td>0.116345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1803</th>\n",
       "      <td>1953</td>\n",
       "      <td>0.116162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516</th>\n",
       "      <td>558</td>\n",
       "      <td>0.116140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1404</th>\n",
       "      <td>1522</td>\n",
       "      <td>0.116065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>193</td>\n",
       "      <td>0.115789</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      user_id:token  average_popularity\n",
       "2034           2211            0.142278\n",
       "803             873            0.142158\n",
       "416             452            0.142158\n",
       "1410           1529            0.142045\n",
       "2021           2198            0.141976\n",
       "...             ...                 ...\n",
       "60               65            0.116345\n",
       "1803           1953            0.116162\n",
       "516             558            0.116140\n",
       "1404           1522            0.116065\n",
       "174             193            0.115789\n",
       "\n",
       "[500 rows x 2 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "med_pop_user_df_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id:token</th>\n",
       "      <th>average_popularity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>125</td>\n",
       "      <td>0.096929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1925</th>\n",
       "      <td>2091</td>\n",
       "      <td>0.096907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>423</td>\n",
       "      <td>0.096900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>652</th>\n",
       "      <td>708</td>\n",
       "      <td>0.096900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>427</td>\n",
       "      <td>0.096863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1033</th>\n",
       "      <td>1117</td>\n",
       "      <td>0.026903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1295</th>\n",
       "      <td>1401</td>\n",
       "      <td>0.026694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>112</td>\n",
       "      <td>0.018677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1751</th>\n",
       "      <td>1892</td>\n",
       "      <td>0.017872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1715</th>\n",
       "      <td>1855</td>\n",
       "      <td>0.016198</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      user_id:token  average_popularity\n",
       "114             125            0.096929\n",
       "1925           2091            0.096907\n",
       "389             423            0.096900\n",
       "652             708            0.096900\n",
       "393             427            0.096863\n",
       "...             ...                 ...\n",
       "1033           1117            0.026903\n",
       "1295           1401            0.026694\n",
       "103             112            0.018677\n",
       "1751           1892            0.017872\n",
       "1715           1855            0.016198\n",
       "\n",
       "[500 rows x 2 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "low_pop_user_df_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def id_factorizer(checkin_df_sample, high_pop_user_df_sample, med_pop_user_df_sample, low_pop_user_df_sample, user_df_sample, poi_df_sample, checkin_df_timestamp):\n",
    "    \"\"\"Overwriting the actual ID with a factorized ID so that we can use the same ID both in RecBole and CAPRI\"\"\"\n",
    "    checkin_df_sample['user_id:token'], user_id_map = pd.factorize(checkin_df_sample['user_id:token'])\n",
    "    checkin_df_sample['item_id:token'], business_id_map = pd.factorize(checkin_df_sample['item_id:token'])\n",
    "\n",
    "    # Create mapping dictionaries\n",
    "    user_id_mapping = {original: i for i, original in enumerate(user_id_map)}\n",
    "    business_id_mapping = {original: j for j, original in enumerate(business_id_map)}\n",
    "\n",
    "    high_pop_user_df_sample['user_id:token'] = high_pop_user_df_sample['user_id:token'].map(user_id_mapping)\n",
    "    med_pop_user_df_sample['user_id:token'] = med_pop_user_df_sample['user_id:token'].map(user_id_mapping)\n",
    "    low_pop_user_df_sample['user_id:token'] = low_pop_user_df_sample['user_id:token'].map(user_id_mapping)\n",
    "\n",
    "    checkin_df_timestamp[\"user_id:token\"] = checkin_df_timestamp[\"user_id:token\"].map(user_id_mapping)\n",
    "    checkin_df_timestamp[\"item_id:token\"] = checkin_df_timestamp[\"item_id:token\"].map(business_id_mapping)\n",
    "\n",
    "    user_df_sample['user_id:token'] = user_df_sample['user_id:token'].map(user_id_mapping)\n",
    "    poi_df_sample['item_id:token'] = poi_df_sample['item_id:token'].map(business_id_mapping)\n",
    "\n",
    "\n",
    "    return checkin_df_sample, high_pop_user_df_sample, med_pop_user_df_sample, low_pop_user_df_sample, user_df_sample, poi_df_sample, checkin_df_timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9q/p0b6nwnd5071040x3849mdvc0000gn/T/ipykernel_58945/4057195747.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  user_df_sample['user_id:token'] = user_df_sample['user_id:token'].map(user_id_mapping)\n",
      "/var/folders/9q/p0b6nwnd5071040x3849mdvc0000gn/T/ipykernel_58945/4057195747.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  poi_df_sample['item_id:token'] = poi_df_sample['item_id:token'].map(business_id_mapping)\n"
     ]
    }
   ],
   "source": [
    "checkin_df_sample, high_pop_user_df_sample, med_pop_user_df_sample, low_pop_user_df_sample, user_df_sample, poi_df_sample, checkin_df_timestamp = id_factorizer(checkin_df_sample, high_pop_user_df_sample, med_pop_user_df_sample, low_pop_user_df_sample, user_df_sample, poi_df_sample, checkin_df_timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1500"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkin_df_sample[\"user_id:token\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id:token</th>\n",
       "      <th>item_id:token</th>\n",
       "      <th>timestamp:float</th>\n",
       "      <th>checkin_count:float</th>\n",
       "      <th>business_popularity:float</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Fri Apr 06 12:52:34 +0000 2012</td>\n",
       "      <td>2</td>\n",
       "      <td>0.061404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Fri Apr 06 12:52:35 +0000 2012</td>\n",
       "      <td>1</td>\n",
       "      <td>0.026316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Fri Apr 06 12:52:49 +0000 2012</td>\n",
       "      <td>33</td>\n",
       "      <td>0.031100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Fri Apr 06 12:53:38 +0000 2012</td>\n",
       "      <td>52</td>\n",
       "      <td>0.039872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>Fri Apr 06 12:54:35 +0000 2012</td>\n",
       "      <td>11</td>\n",
       "      <td>0.009569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99680</th>\n",
       "      <td>190</td>\n",
       "      <td>1021</td>\n",
       "      <td>Wed Sep 05 23:15:07 +0000 2012</td>\n",
       "      <td>1</td>\n",
       "      <td>0.012759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99681</th>\n",
       "      <td>126</td>\n",
       "      <td>1877</td>\n",
       "      <td>Wed Sep 05 23:28:47 +0000 2012</td>\n",
       "      <td>1</td>\n",
       "      <td>0.015152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99682</th>\n",
       "      <td>1364</td>\n",
       "      <td>1051</td>\n",
       "      <td>Wed Sep 05 23:30:16 +0000 2012</td>\n",
       "      <td>2</td>\n",
       "      <td>0.018341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99683</th>\n",
       "      <td>100</td>\n",
       "      <td>471</td>\n",
       "      <td>Wed Sep 05 23:32:06 +0000 2012</td>\n",
       "      <td>1</td>\n",
       "      <td>0.028708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99684</th>\n",
       "      <td>734</td>\n",
       "      <td>2196</td>\n",
       "      <td>Wed Sep 05 23:42:32 +0000 2012</td>\n",
       "      <td>1</td>\n",
       "      <td>0.010367</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>67526 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       user_id:token  item_id:token                 timestamp:float  \\\n",
       "1                  0              0  Fri Apr 06 12:52:34 +0000 2012   \n",
       "2                  1              1  Fri Apr 06 12:52:35 +0000 2012   \n",
       "3                  2              2  Fri Apr 06 12:52:49 +0000 2012   \n",
       "4                  3              3  Fri Apr 06 12:53:38 +0000 2012   \n",
       "5                  4              4  Fri Apr 06 12:54:35 +0000 2012   \n",
       "...              ...            ...                             ...   \n",
       "99680            190           1021  Wed Sep 05 23:15:07 +0000 2012   \n",
       "99681            126           1877  Wed Sep 05 23:28:47 +0000 2012   \n",
       "99682           1364           1051  Wed Sep 05 23:30:16 +0000 2012   \n",
       "99683            100            471  Wed Sep 05 23:32:06 +0000 2012   \n",
       "99684            734           2196  Wed Sep 05 23:42:32 +0000 2012   \n",
       "\n",
       "       checkin_count:float  business_popularity:float  \n",
       "1                        2                   0.061404  \n",
       "2                        1                   0.026316  \n",
       "3                       33                   0.031100  \n",
       "4                       52                   0.039872  \n",
       "5                       11                   0.009569  \n",
       "...                    ...                        ...  \n",
       "99680                    1                   0.012759  \n",
       "99681                    1                   0.015152  \n",
       "99682                    2                   0.018341  \n",
       "99683                    1                   0.028708  \n",
       "99684                    1                   0.010367  \n",
       "\n",
       "[67526 rows x 5 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkin_df_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_id_token_adder(df, column_name_list = [\"user_id:token\", \"item_id:token\"]):\n",
    "    \"\"\" Recbole needs a token instead of a number for the user and item ID\"\"\"\n",
    "    for column_name in column_name_list:\n",
    "        try:\n",
    "            df[column_name] = df[column_name].astype(str) + \"_x\"\n",
    "        except KeyError:\n",
    "            pass\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9q/p0b6nwnd5071040x3849mdvc0000gn/T/ipykernel_58945/1404554777.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[column_name] = df[column_name].astype(str) + \"_x\"\n",
      "/var/folders/9q/p0b6nwnd5071040x3849mdvc0000gn/T/ipykernel_58945/1404554777.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[column_name] = df[column_name].astype(str) + \"_x\"\n"
     ]
    }
   ],
   "source": [
    "checkin_df_sample = user_id_token_adder(checkin_df_sample)\n",
    "high_pop_user_df_sample = user_id_token_adder(high_pop_user_df_sample)\n",
    "med_pop_user_df_sample = user_id_token_adder(med_pop_user_df_sample)\n",
    "low_pop_user_df_sample = user_id_token_adder(low_pop_user_df_sample)\n",
    "user_df_sample = user_id_token_adder(user_df_sample)\n",
    "poi_df_sample = user_id_token_adder(poi_df_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id:token</th>\n",
       "      <th>item_id:token</th>\n",
       "      <th>timestamp:float</th>\n",
       "      <th>checkin_count:float</th>\n",
       "      <th>business_popularity:float</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0_x</td>\n",
       "      <td>0_x</td>\n",
       "      <td>Fri Apr 06 12:52:34 +0000 2012</td>\n",
       "      <td>2</td>\n",
       "      <td>0.061404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1_x</td>\n",
       "      <td>1_x</td>\n",
       "      <td>Fri Apr 06 12:52:35 +0000 2012</td>\n",
       "      <td>1</td>\n",
       "      <td>0.026316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2_x</td>\n",
       "      <td>2_x</td>\n",
       "      <td>Fri Apr 06 12:52:49 +0000 2012</td>\n",
       "      <td>33</td>\n",
       "      <td>0.031100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3_x</td>\n",
       "      <td>3_x</td>\n",
       "      <td>Fri Apr 06 12:53:38 +0000 2012</td>\n",
       "      <td>52</td>\n",
       "      <td>0.039872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4_x</td>\n",
       "      <td>4_x</td>\n",
       "      <td>Fri Apr 06 12:54:35 +0000 2012</td>\n",
       "      <td>11</td>\n",
       "      <td>0.009569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99680</th>\n",
       "      <td>190_x</td>\n",
       "      <td>1021_x</td>\n",
       "      <td>Wed Sep 05 23:15:07 +0000 2012</td>\n",
       "      <td>1</td>\n",
       "      <td>0.012759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99681</th>\n",
       "      <td>126_x</td>\n",
       "      <td>1877_x</td>\n",
       "      <td>Wed Sep 05 23:28:47 +0000 2012</td>\n",
       "      <td>1</td>\n",
       "      <td>0.015152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99682</th>\n",
       "      <td>1364_x</td>\n",
       "      <td>1051_x</td>\n",
       "      <td>Wed Sep 05 23:30:16 +0000 2012</td>\n",
       "      <td>2</td>\n",
       "      <td>0.018341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99683</th>\n",
       "      <td>100_x</td>\n",
       "      <td>471_x</td>\n",
       "      <td>Wed Sep 05 23:32:06 +0000 2012</td>\n",
       "      <td>1</td>\n",
       "      <td>0.028708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99684</th>\n",
       "      <td>734_x</td>\n",
       "      <td>2196_x</td>\n",
       "      <td>Wed Sep 05 23:42:32 +0000 2012</td>\n",
       "      <td>1</td>\n",
       "      <td>0.010367</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>67526 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      user_id:token item_id:token                 timestamp:float  \\\n",
       "1               0_x           0_x  Fri Apr 06 12:52:34 +0000 2012   \n",
       "2               1_x           1_x  Fri Apr 06 12:52:35 +0000 2012   \n",
       "3               2_x           2_x  Fri Apr 06 12:52:49 +0000 2012   \n",
       "4               3_x           3_x  Fri Apr 06 12:53:38 +0000 2012   \n",
       "5               4_x           4_x  Fri Apr 06 12:54:35 +0000 2012   \n",
       "...             ...           ...                             ...   \n",
       "99680         190_x        1021_x  Wed Sep 05 23:15:07 +0000 2012   \n",
       "99681         126_x        1877_x  Wed Sep 05 23:28:47 +0000 2012   \n",
       "99682        1364_x        1051_x  Wed Sep 05 23:30:16 +0000 2012   \n",
       "99683         100_x         471_x  Wed Sep 05 23:32:06 +0000 2012   \n",
       "99684         734_x        2196_x  Wed Sep 05 23:42:32 +0000 2012   \n",
       "\n",
       "       checkin_count:float  business_popularity:float  \n",
       "1                        2                   0.061404  \n",
       "2                        1                   0.026316  \n",
       "3                       33                   0.031100  \n",
       "4                       52                   0.039872  \n",
       "5                       11                   0.009569  \n",
       "...                    ...                        ...  \n",
       "99680                    1                   0.012759  \n",
       "99681                    1                   0.015152  \n",
       "99682                    2                   0.018341  \n",
       "99683                    1                   0.028708  \n",
       "99684                    1                   0.010367  \n",
       "\n",
       "[67526 rows x 5 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkin_df_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id:token</th>\n",
       "      <th>average_popularity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2034</th>\n",
       "      <td>1129_x</td>\n",
       "      <td>0.142278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>803</th>\n",
       "      <td>1491_x</td>\n",
       "      <td>0.142158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>530_x</td>\n",
       "      <td>0.142158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1410</th>\n",
       "      <td>5_x</td>\n",
       "      <td>0.142045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021</th>\n",
       "      <td>1443_x</td>\n",
       "      <td>0.141976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>400_x</td>\n",
       "      <td>0.116345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1803</th>\n",
       "      <td>217_x</td>\n",
       "      <td>0.116162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516</th>\n",
       "      <td>625_x</td>\n",
       "      <td>0.116140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1404</th>\n",
       "      <td>1465_x</td>\n",
       "      <td>0.116065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>925_x</td>\n",
       "      <td>0.115789</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     user_id:token  average_popularity\n",
       "2034        1129_x            0.142278\n",
       "803         1491_x            0.142158\n",
       "416          530_x            0.142158\n",
       "1410           5_x            0.142045\n",
       "2021        1443_x            0.141976\n",
       "...            ...                 ...\n",
       "60           400_x            0.116345\n",
       "1803         217_x            0.116162\n",
       "516          625_x            0.116140\n",
       "1404        1465_x            0.116065\n",
       "174          925_x            0.115789\n",
       "\n",
       "[500 rows x 2 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "med_pop_user_df_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a json with the user id's of the respective popularity groups\n",
    "user_id_popularity = {}\n",
    "user_id_popularity[\"high\"] = high_pop_user_df_sample[\"user_id:token\"].tolist()\n",
    "user_id_popularity[\"medium\"] = med_pop_user_df_sample[\"user_id:token\"].tolist()\n",
    "user_id_popularity[\"low\"] = low_pop_user_df_sample[\"user_id:token\"].tolist()\n",
    "json.dump(user_id_popularity, open(f\"{DATASET_DIR}/{dataset}_user_id_popularity.json\", \"w\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_saver(df, filename, framework):\n",
    "    if not os.path.exists(DATASET_DIR + \"processed_data_\" + framework):\n",
    "        os.makedirs(DATASET_DIR + \"processed_data_\" + framework)\n",
    "    \n",
    "    df.to_csv(DATASET_DIR + \"processed_data_\" + framework + \"/\" + filename + \".csv\")\n",
    "    print(\"Data saved as \" + framework + filename + \".csv\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved as cornacuser_events.csv\n",
      "Data saved as cornachigh_pop_user_sample.csv\n",
      "Data saved as cornacmedium_pop_user_sample.csv\n",
      "Data saved as cornaclow_pop_user_sample.csv\n"
     ]
    }
   ],
   "source": [
    "# first of all saving data for cornac\n",
    "data_saver(checkin_df_sample, \"user_events\", \"cornac\")\n",
    "data_saver(high_pop_user_df_sample, \"high_pop_user_sample\", \"cornac\")\n",
    "data_saver(med_pop_user_df_sample, \"medium_pop_user_sample\", \"cornac\")\n",
    "data_saver(low_pop_user_df_sample, \"low_pop_user_sample\", \"cornac\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id:token</th>\n",
       "      <th>item_id:token</th>\n",
       "      <th>timestamp:float</th>\n",
       "      <th>checkin_count:float</th>\n",
       "      <th>business_popularity:float</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0_x</td>\n",
       "      <td>0_x</td>\n",
       "      <td>Fri Apr 06 12:52:34 +0000 2012</td>\n",
       "      <td>2</td>\n",
       "      <td>0.061404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1_x</td>\n",
       "      <td>1_x</td>\n",
       "      <td>Fri Apr 06 12:52:35 +0000 2012</td>\n",
       "      <td>1</td>\n",
       "      <td>0.026316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2_x</td>\n",
       "      <td>2_x</td>\n",
       "      <td>Fri Apr 06 12:52:49 +0000 2012</td>\n",
       "      <td>33</td>\n",
       "      <td>0.031100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3_x</td>\n",
       "      <td>3_x</td>\n",
       "      <td>Fri Apr 06 12:53:38 +0000 2012</td>\n",
       "      <td>52</td>\n",
       "      <td>0.039872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4_x</td>\n",
       "      <td>4_x</td>\n",
       "      <td>Fri Apr 06 12:54:35 +0000 2012</td>\n",
       "      <td>11</td>\n",
       "      <td>0.009569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99680</th>\n",
       "      <td>190_x</td>\n",
       "      <td>1021_x</td>\n",
       "      <td>Wed Sep 05 23:15:07 +0000 2012</td>\n",
       "      <td>1</td>\n",
       "      <td>0.012759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99681</th>\n",
       "      <td>126_x</td>\n",
       "      <td>1877_x</td>\n",
       "      <td>Wed Sep 05 23:28:47 +0000 2012</td>\n",
       "      <td>1</td>\n",
       "      <td>0.015152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99682</th>\n",
       "      <td>1364_x</td>\n",
       "      <td>1051_x</td>\n",
       "      <td>Wed Sep 05 23:30:16 +0000 2012</td>\n",
       "      <td>2</td>\n",
       "      <td>0.018341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99683</th>\n",
       "      <td>100_x</td>\n",
       "      <td>471_x</td>\n",
       "      <td>Wed Sep 05 23:32:06 +0000 2012</td>\n",
       "      <td>1</td>\n",
       "      <td>0.028708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99684</th>\n",
       "      <td>734_x</td>\n",
       "      <td>2196_x</td>\n",
       "      <td>Wed Sep 05 23:42:32 +0000 2012</td>\n",
       "      <td>1</td>\n",
       "      <td>0.010367</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>67526 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      user_id:token item_id:token                 timestamp:float  \\\n",
       "1               0_x           0_x  Fri Apr 06 12:52:34 +0000 2012   \n",
       "2               1_x           1_x  Fri Apr 06 12:52:35 +0000 2012   \n",
       "3               2_x           2_x  Fri Apr 06 12:52:49 +0000 2012   \n",
       "4               3_x           3_x  Fri Apr 06 12:53:38 +0000 2012   \n",
       "5               4_x           4_x  Fri Apr 06 12:54:35 +0000 2012   \n",
       "...             ...           ...                             ...   \n",
       "99680         190_x        1021_x  Wed Sep 05 23:15:07 +0000 2012   \n",
       "99681         126_x        1877_x  Wed Sep 05 23:28:47 +0000 2012   \n",
       "99682        1364_x        1051_x  Wed Sep 05 23:30:16 +0000 2012   \n",
       "99683         100_x         471_x  Wed Sep 05 23:32:06 +0000 2012   \n",
       "99684         734_x        2196_x  Wed Sep 05 23:42:32 +0000 2012   \n",
       "\n",
       "       checkin_count:float  business_popularity:float  \n",
       "1                        2                   0.061404  \n",
       "2                        1                   0.026316  \n",
       "3                       33                   0.031100  \n",
       "4                       52                   0.039872  \n",
       "5                       11                   0.009569  \n",
       "...                    ...                        ...  \n",
       "99680                    1                   0.012759  \n",
       "99681                    1                   0.015152  \n",
       "99682                    2                   0.018341  \n",
       "99683                    1                   0.028708  \n",
       "99684                    1                   0.010367  \n",
       "\n",
       "[67526 rows x 5 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkin_df_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_saver_recbole(df, framework, suffix):\n",
    "    \n",
    "    if not os.path.exists(DATASET_DIR + \"processed_data_\" + framework):\n",
    "        os.makedirs(DATASET_DIR + \"processed_data_\" + framework)\n",
    "\n",
    "    df.to_csv(f\"{DATASET_DIR}processed_data_{framework}/{dataset}_sample.{suffix}\", sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkin_df_sample['review_id:token'] = range(1, len(checkin_df_sample) + 1)\n",
    "# Step 1: Group by user_id and business_id and count check-ins\n",
    "#checkin_df_sample['checkin_count:float'] = checkin_df_sample.groupby(['user_id:token', 'item_id:token'])['item_id:token'].transform('count')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id:token</th>\n",
       "      <th>item_id:token</th>\n",
       "      <th>timestamp:float</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5689</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Fri Apr 06 12:52:34 +0000 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5690</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Fri Apr 06 12:52:35 +0000 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5692</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Fri Apr 06 12:52:49 +0000 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5693</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Fri Apr 06 12:53:38 +0000 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5694</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>Fri Apr 06 12:54:35 +0000 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331776</th>\n",
       "      <td>111</td>\n",
       "      <td>185</td>\n",
       "      <td>Wed Sep 05 23:55:47 +0000 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331782</th>\n",
       "      <td>379</td>\n",
       "      <td>88</td>\n",
       "      <td>Wed Sep 05 23:56:30 +0000 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331783</th>\n",
       "      <td>359</td>\n",
       "      <td>754</td>\n",
       "      <td>Wed Sep 05 23:57:37 +0000 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331784</th>\n",
       "      <td>403</td>\n",
       "      <td>148</td>\n",
       "      <td>Wed Sep 05 23:58:06 +0000 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331787</th>\n",
       "      <td>81</td>\n",
       "      <td>97</td>\n",
       "      <td>Wed Sep 05 23:59:59 +0000 2012</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>219160 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_id:token  item_id:token                 timestamp:float\n",
       "5689                0              0  Fri Apr 06 12:52:34 +0000 2012\n",
       "5690                1              1  Fri Apr 06 12:52:35 +0000 2012\n",
       "5692                2              2  Fri Apr 06 12:52:49 +0000 2012\n",
       "5693                3              3  Fri Apr 06 12:53:38 +0000 2012\n",
       "5694                4              4  Fri Apr 06 12:54:35 +0000 2012\n",
       "...               ...            ...                             ...\n",
       "331776            111            185  Wed Sep 05 23:55:47 +0000 2012\n",
       "331782            379             88  Wed Sep 05 23:56:30 +0000 2012\n",
       "331783            359            754  Wed Sep 05 23:57:37 +0000 2012\n",
       "331784            403            148  Wed Sep 05 23:58:06 +0000 2012\n",
       "331787             81             97  Wed Sep 05 23:59:59 +0000 2012\n",
       "\n",
       "[219160 rows x 3 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkin_df_timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkin_df_sample = convert_to_unix_timestamp(checkin_df_sample, \"timestamp:float\")\n",
    "checkin_df_timestamp = convert_to_unix_timestamp(checkin_df_timestamp, \"timestamp:float\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id:token</th>\n",
       "      <th>item_id:token</th>\n",
       "      <th>timestamp:float</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5689</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.333717e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5690</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.333717e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5692</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.333717e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5693</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1.333717e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5694</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1.333717e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331776</th>\n",
       "      <td>111</td>\n",
       "      <td>185</td>\n",
       "      <td>1.346889e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331782</th>\n",
       "      <td>379</td>\n",
       "      <td>88</td>\n",
       "      <td>1.346889e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331783</th>\n",
       "      <td>359</td>\n",
       "      <td>754</td>\n",
       "      <td>1.346889e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331784</th>\n",
       "      <td>403</td>\n",
       "      <td>148</td>\n",
       "      <td>1.346889e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331787</th>\n",
       "      <td>81</td>\n",
       "      <td>97</td>\n",
       "      <td>1.346890e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>219160 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_id:token  item_id:token  timestamp:float\n",
       "5689                0              0     1.333717e+09\n",
       "5690                1              1     1.333717e+09\n",
       "5692                2              2     1.333717e+09\n",
       "5693                3              3     1.333717e+09\n",
       "5694                4              4     1.333717e+09\n",
       "...               ...            ...              ...\n",
       "331776            111            185     1.346889e+09\n",
       "331782            379             88     1.346889e+09\n",
       "331783            359            754     1.346889e+09\n",
       "331784            403            148     1.346889e+09\n",
       "331787             81             97     1.346890e+09\n",
       "\n",
       "[219160 rows x 3 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkin_df_timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id:token</th>\n",
       "      <th>item_id:token</th>\n",
       "      <th>timestamp:float</th>\n",
       "      <th>checkin_count:float</th>\n",
       "      <th>business_popularity:float</th>\n",
       "      <th>review_id:token</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0_x</td>\n",
       "      <td>0_x</td>\n",
       "      <td>1.333717e+09</td>\n",
       "      <td>2</td>\n",
       "      <td>0.061404</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1_x</td>\n",
       "      <td>1_x</td>\n",
       "      <td>1.333717e+09</td>\n",
       "      <td>1</td>\n",
       "      <td>0.026316</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2_x</td>\n",
       "      <td>2_x</td>\n",
       "      <td>1.333717e+09</td>\n",
       "      <td>33</td>\n",
       "      <td>0.031100</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3_x</td>\n",
       "      <td>3_x</td>\n",
       "      <td>1.333717e+09</td>\n",
       "      <td>52</td>\n",
       "      <td>0.039872</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4_x</td>\n",
       "      <td>4_x</td>\n",
       "      <td>1.333717e+09</td>\n",
       "      <td>11</td>\n",
       "      <td>0.009569</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99680</th>\n",
       "      <td>190_x</td>\n",
       "      <td>1021_x</td>\n",
       "      <td>1.346887e+09</td>\n",
       "      <td>1</td>\n",
       "      <td>0.012759</td>\n",
       "      <td>67522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99681</th>\n",
       "      <td>126_x</td>\n",
       "      <td>1877_x</td>\n",
       "      <td>1.346888e+09</td>\n",
       "      <td>1</td>\n",
       "      <td>0.015152</td>\n",
       "      <td>67523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99682</th>\n",
       "      <td>1364_x</td>\n",
       "      <td>1051_x</td>\n",
       "      <td>1.346888e+09</td>\n",
       "      <td>2</td>\n",
       "      <td>0.018341</td>\n",
       "      <td>67524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99683</th>\n",
       "      <td>100_x</td>\n",
       "      <td>471_x</td>\n",
       "      <td>1.346888e+09</td>\n",
       "      <td>1</td>\n",
       "      <td>0.028708</td>\n",
       "      <td>67525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99684</th>\n",
       "      <td>734_x</td>\n",
       "      <td>2196_x</td>\n",
       "      <td>1.346889e+09</td>\n",
       "      <td>1</td>\n",
       "      <td>0.010367</td>\n",
       "      <td>67526</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>67526 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      user_id:token item_id:token  timestamp:float  checkin_count:float  \\\n",
       "1               0_x           0_x     1.333717e+09                    2   \n",
       "2               1_x           1_x     1.333717e+09                    1   \n",
       "3               2_x           2_x     1.333717e+09                   33   \n",
       "4               3_x           3_x     1.333717e+09                   52   \n",
       "5               4_x           4_x     1.333717e+09                   11   \n",
       "...             ...           ...              ...                  ...   \n",
       "99680         190_x        1021_x     1.346887e+09                    1   \n",
       "99681         126_x        1877_x     1.346888e+09                    1   \n",
       "99682        1364_x        1051_x     1.346888e+09                    2   \n",
       "99683         100_x         471_x     1.346888e+09                    1   \n",
       "99684         734_x        2196_x     1.346889e+09                    1   \n",
       "\n",
       "       business_popularity:float  review_id:token  \n",
       "1                       0.061404                1  \n",
       "2                       0.026316                2  \n",
       "3                       0.031100                3  \n",
       "4                       0.039872                4  \n",
       "5                       0.009569                5  \n",
       "...                          ...              ...  \n",
       "99680                   0.012759            67522  \n",
       "99681                   0.015152            67523  \n",
       "99682                   0.018341            67524  \n",
       "99683                   0.028708            67525  \n",
       "99684                   0.010367            67526  \n",
       "\n",
       "[67526 rows x 6 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkin_df_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkin_df_sample.sort_values(by=\"checkin_count:float\", ascending=False)\n",
    "# very important: keeping the duplicate check-ins for the context aware recommendation to have the timestamps saved\n",
    "\n",
    "\n",
    "# very important: dropping duplicate check-ins \n",
    "checkin_df_sample = checkin_df_sample.drop_duplicates(subset=[\"user_id:token\", \"item_id:token\"], keep=\"first\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_df_sample = user_df_sample[[\"user_id:token\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This would be the correct splits if we let recbole do the splitting\n",
    "\n",
    "# data_saver_recbole(checkin_df_sample, \"recbole\", \"inter\")\n",
    "# data_saver_recbole(user_df_sample, \"recbole\", \"user\")\n",
    "# data_saver_recbole(poi_df_sample, \"recbole\", \"item\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id:token</th>\n",
       "      <th>category_id:token</th>\n",
       "      <th>category_name:token_seq</th>\n",
       "      <th>lat:float</th>\n",
       "      <th>lon:float</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>156_x</td>\n",
       "      <td>4bf58dd8d48988d129951735</td>\n",
       "      <td>Train Station</td>\n",
       "      <td>35.700253</td>\n",
       "      <td>139.480255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>431_x</td>\n",
       "      <td>4bf58dd8d48988d1eb931735</td>\n",
       "      <td>Airport</td>\n",
       "      <td>35.548963</td>\n",
       "      <td>139.784611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1031_x</td>\n",
       "      <td>4bf58dd8d48988d1df941735</td>\n",
       "      <td>Bridge</td>\n",
       "      <td>35.609929</td>\n",
       "      <td>139.825659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1428_x</td>\n",
       "      <td>4bf58dd8d48988d129951735</td>\n",
       "      <td>Train Station</td>\n",
       "      <td>35.749538</td>\n",
       "      <td>139.586540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>184_x</td>\n",
       "      <td>4bf58dd8d48988d129951735</td>\n",
       "      <td>Train Station</td>\n",
       "      <td>35.729025</td>\n",
       "      <td>139.711096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412051</th>\n",
       "      <td>1509_x</td>\n",
       "      <td>4bf58dd8d48988d120941735</td>\n",
       "      <td>Bar</td>\n",
       "      <td>35.697700</td>\n",
       "      <td>139.770384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425285</th>\n",
       "      <td>1467_x</td>\n",
       "      <td>4bf58dd8d48988d16d941735</td>\n",
       "      <td>Café</td>\n",
       "      <td>35.702436</td>\n",
       "      <td>139.770470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450169</th>\n",
       "      <td>1440_x</td>\n",
       "      <td>4bf58dd8d48988d129951735</td>\n",
       "      <td>Train Station</td>\n",
       "      <td>35.607054</td>\n",
       "      <td>139.734894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462519</th>\n",
       "      <td>2582_x</td>\n",
       "      <td>4d954b0ea243a5684a65b473</td>\n",
       "      <td>Convenience Store</td>\n",
       "      <td>35.701178</td>\n",
       "      <td>139.771038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488554</th>\n",
       "      <td>1678_x</td>\n",
       "      <td>4eb1daf44b900d56c88a4600</td>\n",
       "      <td>Fair</td>\n",
       "      <td>35.630669</td>\n",
       "      <td>139.795103</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2804 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       item_id:token         category_id:token category_name:token_seq  \\\n",
       "7              156_x  4bf58dd8d48988d129951735           Train Station   \n",
       "10             431_x  4bf58dd8d48988d1eb931735                 Airport   \n",
       "14            1031_x  4bf58dd8d48988d1df941735                  Bridge   \n",
       "15            1428_x  4bf58dd8d48988d129951735           Train Station   \n",
       "17             184_x  4bf58dd8d48988d129951735           Train Station   \n",
       "...              ...                       ...                     ...   \n",
       "412051        1509_x  4bf58dd8d48988d120941735                     Bar   \n",
       "425285        1467_x  4bf58dd8d48988d16d941735                    Café   \n",
       "450169        1440_x  4bf58dd8d48988d129951735           Train Station   \n",
       "462519        2582_x  4d954b0ea243a5684a65b473       Convenience Store   \n",
       "488554        1678_x  4eb1daf44b900d56c88a4600                    Fair   \n",
       "\n",
       "        lat:float   lon:float  \n",
       "7       35.700253  139.480255  \n",
       "10      35.548963  139.784611  \n",
       "14      35.609929  139.825659  \n",
       "15      35.749538  139.586540  \n",
       "17      35.729025  139.711096  \n",
       "...           ...         ...  \n",
       "412051  35.697700  139.770384  \n",
       "425285  35.702436  139.770470  \n",
       "450169  35.607054  139.734894  \n",
       "462519  35.701178  139.771038  \n",
       "488554  35.630669  139.795103  \n",
       "\n",
       "[2804 rows x 5 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poi_df_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkin_df_timestamp = checkin_df_timestamp[[\"user_id:token\", \"item_id:token\", \"timestamp:float\"]] # FINAL\n",
    "checkins_capri_train_test_tune = checkin_df_sample[[\"user_id:token\", \"item_id:token\", \"timestamp:float\", \"checkin_count:float\"]]\n",
    "try:\n",
    "    poi_df_sample_capri = poi_df_sample[[\"item_id:token\", \"lat:float\", \"lon:float\"]] # FINAL\n",
    "except KeyError: # in the snowcard data the coordinates are not given\n",
    "    poi_df_sample_capri = poi_df_sample[[\"item_id:token\"]]\n",
    "datasize_capri = pd.DataFrame(data={\"num_users\" : [len(checkins_capri_train_test_tune[\"user_id:token\"].unique())], \"num_items\" : [len(checkins_capri_train_test_tune[\"item_id:token\"].unique())]}) # FINAL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating train, test and val splits (user-based temporal split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Set:\n",
      "      user_id:token item_id:token  checkin_count:float\n",
      "1               0_x           0_x                    2\n",
      "150             0_x          87_x                    1\n",
      "152             0_x          89_x                   15\n",
      "154             0_x          91_x                   13\n",
      "59655           0_x         889_x                    1\n",
      "\n",
      "Validation Set:\n",
      "      user_id:token item_id:token  checkin_count:float\n",
      "72716           0_x         126_x                    1\n",
      "72718           0_x         745_x                    2\n",
      "72828           0_x        1957_x                    1\n",
      "18048           0_x         171_x                    2\n",
      "27005        1000_x        1997_x                    1\n",
      "\n",
      "Test Set:\n",
      "      user_id:token item_id:token  checkin_count:float\n",
      "83351           0_x          68_x                    1\n",
      "73208           0_x         193_x                    1\n",
      "73209           0_x         213_x                    1\n",
      "73803           0_x         831_x                    1\n",
      "73871           0_x         390_x                    1\n"
     ]
    }
   ],
   "source": [
    "# splitting the data into train, test, and tune\n",
    "checkins_capri_train_test_tune = checkins_capri_train_test_tune.sort_values(by=[\"user_id:token\", \"timestamp:float\"])\n",
    "checkins_capri_train_test_tune = checkins_capri_train_test_tune[[\"user_id:token\", \"item_id:token\", \"checkin_count:float\"]]\n",
    "\n",
    "# Split the data\n",
    "train_list = []\n",
    "val_list = []\n",
    "test_list = []\n",
    "\n",
    "for user, group in checkins_capri_train_test_tune.groupby('user_id:token'):\n",
    "    n = len(group)\n",
    "    train_end = int(n * 0.65)\n",
    "    val_end = int(n * 0.80)\n",
    "    \n",
    "    train_list.append(group.iloc[:train_end])\n",
    "    val_list.append(group.iloc[train_end:val_end])\n",
    "    test_list.append(group.iloc[val_end:])\n",
    "\n",
    "# Combine lists into DataFrames\n",
    "train_df = pd.concat(train_list)\n",
    "val_df = pd.concat(val_list)\n",
    "test_df = pd.concat(test_list)\n",
    "\n",
    "\n",
    "\n",
    "# Check the splits\n",
    "\n",
    "# FINAL 6-8\n",
    "print(\"Train Set:\")\n",
    "print(train_df.head())\n",
    "print(\"\\nValidation Set:\")\n",
    "print(val_df.head())\n",
    "print(\"\\nTest Set:\")\n",
    "print(test_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def datasaver_capri(df, filename):\n",
    "    \n",
    "    if not os.path.exists(DATASET_DIR + \"processed_data_capri\"):\n",
    "        os.makedirs(DATASET_DIR + \"processed_data_capri\")\n",
    "    \n",
    "    df.to_csv(DATASET_DIR + \"processed_data_capri/\" + filename + \".txt\", sep='\\t', index=False, header=False)\n",
    "    print(\"Data saved as \" + filename + \".txt\")\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding a category column\n",
    "if include_categories is True:\n",
    "    if dataset == \"yelp\":\n",
    "        # Split the 'category_name' column by commas\n",
    "        poi_df_sample['category_name_unstacked:token_seq'] = poi_df_sample['category_name:token_seq'].str.split(', ')\n",
    "\n",
    "        # Unstack the categories into multiple rows\n",
    "        category_df_sample = poi_df_sample.explode('category_name_unstacked:token_seq')\n",
    "        category_counts = category_df_sample[\"category_name_unstacked:token_seq\"].value_counts()\n",
    "        category_mask = category_df_sample[\"category_name_unstacked:token_seq\"].map(category_counts) >= 25\n",
    "        category_df_sample_filtered = category_df_sample.loc[category_mask]\n",
    "        category_df_sample_filtered[\"category_id:token\"], category_id = pd.factorize(category_df_sample_filtered[\"category_name_unstacked:token_seq\"])\n",
    "        category_df_sample_filtered.dropna(inplace=True)\n",
    "        datasize_capri = pd.DataFrame(data={\"num_users\" : [len(checkins_capri_train_test_tune[\"user_id:token\"].unique())], \"num_items\" : [len(checkins_capri_train_test_tune[\"item_id:token\"].unique())], \"num_categories\" : [len(category_df_sample_filtered[\"category_id:token\"].unique())]}) # FINAL\n",
    "        datasaver_capri(category_df_sample_filtered, \"poiCategories\")\n",
    "\n",
    "\n",
    "    elif dataset == \"foursquarenyc\" or dataset == \"foursquaretky\":\n",
    "        poi_df_sample[\"category_id:token\"], category_id = pd.factorize(poi_df_sample[\"category_name:token_seq\"])\n",
    "        datasize_capri = pd.DataFrame(data={\"num_users\" : [len(checkins_capri_train_test_tune[\"user_id:token\"].unique())], \"num_items\" : [len(checkins_capri_train_test_tune[\"item_id:token\"].unique())], \"num_categories\" : [len(poi_df_sample[\"category_id:token\"].unique())]})\n",
    "        poi_df_categories = poi_df_sample[[\"item_id:token\", \"category_id:token\"]]\n",
    "        datasaver_capri(poi_df_categories, \"poiCategories\")\n",
    "\n",
    "    elif dataset == \"snowcard\":\n",
    "        datasize_capri = pd.DataFrame(data={\"num_users\" : [len(checkins_capri_train_test_tune[\"user_id:token\"].unique())], \"num_items\" : [len(checkins_capri_train_test_tune[\"item_id:token\"].unique())], \"num_categories\" : [len(poi_df_sample[\"category_id:token\"].unique())]})\n",
    "        poi_df_categories = poi_df_sample[[\"item_id:token\", \"category_id:token\"]]\n",
    "        datasaver_capri(poi_df_categories, \"poiCategories\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1500, 1500, 1500)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[\"user_id:token\"].nunique(), val_df[\"user_id:token\"].nunique(), test_df[\"user_id:token\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the correct split since we perform the splitting ourselves\n",
    "\n",
    "data_saver_recbole(train_df, \"recbole\", \"train.inter\")\n",
    "data_saver_recbole(test_df, \"recbole\", \"test.inter\")\n",
    "data_saver_recbole(val_df, \"recbole\", \"valid.inter\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make an intervened sample for RecBole debias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All user IDs are present in both subsets.\n"
     ]
    }
   ],
   "source": [
    "checkins_debias = checkins_capri_train_test_tune.copy()\n",
    "intervened_set = checkins_debias.sample(frac=0.5, random_state=10002)\n",
    "normal_set = checkins_debias.drop(intervened_set.index)\n",
    "\n",
    "original_user_ids = set(checkins_debias[\"user_id:token\"].unique())\n",
    "intervened_user_ids = set(intervened_set[\"user_id:token\"].unique())\n",
    "normal_user_ids = set(normal_set[\"user_id:token\"].unique())\n",
    "\n",
    "missing_in_intervened = original_user_ids - intervened_user_ids\n",
    "missing_in_normal = original_user_ids - normal_user_ids\n",
    "\n",
    "if not missing_in_intervened and not missing_in_normal:\n",
    "    print(\"All user IDs are present in both subsets.\")\n",
    "else:\n",
    "    print(\"Missing user IDs in intervened set:\", missing_in_intervened)\n",
    "    print(\"Missing user IDs in normal set:\", missing_in_normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOURCE: https://github.com/DavyMorgan/dps/blob/19a3e5fb2cb6932c3f093ed443760ecd3d95bfdb/data_process_service/splitter.py\n",
    "\n",
    "popularity = (\n",
    "            intervened_set[[\"item_id:token\", \"user_id:token\"]]\n",
    "            .groupby(\"item_id:token\")\n",
    "            .count()\n",
    "            .reset_index()\n",
    "            .rename(columns={\"user_id:token\": \"pop\"})\n",
    "        )\n",
    "intervened_set = intervened_set.merge(popularity, on=\"item_id:token\", how=\"left\")\n",
    "intervened_set[\"pop\"] = intervened_set[\"pop\"].apply(lambda x: 1 / x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "intervened_set.sort_values(by=[\"pop\", \"item_id:token\"], ascending=False, inplace=True)\n",
    "intervened_set.drop(columns=[\"pop\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intervened Training Set Size: 41622\n",
      "Intervened Validation Set Size: 9409\n",
      "Intervened Test Set Size: 16495\n"
     ]
    }
   ],
   "source": [
    "# Lists to collect data for each split\n",
    "train_list_intervened, val_list_intervened, test_list_intervened = [], [], []\n",
    "\n",
    "# Loop through each user's data in the sorted intervened set\n",
    "for user, group in intervened_set.groupby('user_id:token'):\n",
    "    n = len(group)\n",
    "    \n",
    "    # Calculate end indices based on the desired split ratios\n",
    "    test_end = int(n * 0.5)  # Top 50% for test\n",
    "    train_end = test_end + int(n * 0.25)  # Next 25% for train\n",
    "    \n",
    "    # Add to respective lists\n",
    "    test_list_intervened.append(group.iloc[:test_end])  # First 50% goes to test\n",
    "    train_list_intervened.append(group.iloc[test_end:train_end])  # Next 25% goes to train\n",
    "    val_list_intervened.append(group.iloc[train_end:])  # Remaining 25% goes to validation\n",
    "\n",
    "# Concatenate lists into DataFrames\n",
    "train_df_intervened = pd.concat(train_list_intervened, ignore_index=True)\n",
    "train_df_intervened = pd.concat([train_df_intervened, normal_set], ignore_index=True).sort_values(by=[\"user_id:token\"])\n",
    "val_df_intervened = pd.concat(val_list_intervened, ignore_index=True)\n",
    "test_df_intervened = pd.concat(test_list_intervened, ignore_index=True)\n",
    "\n",
    "# Output the sizes of each set\n",
    "print(\"Intervened Training Set Size:\", len(train_df_intervened))\n",
    "print(\"Intervened Validation Set Size:\", len(val_df_intervened))\n",
    "print(\"Intervened Test Set Size:\", len(test_df_intervened))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id:token</th>\n",
       "      <th>item_id:token</th>\n",
       "      <th>checkin_count:float</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0_x</td>\n",
       "      <td>775_x</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7861</th>\n",
       "      <td>0_x</td>\n",
       "      <td>89_x</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7862</th>\n",
       "      <td>0_x</td>\n",
       "      <td>7_x</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7863</th>\n",
       "      <td>0_x</td>\n",
       "      <td>31_x</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7864</th>\n",
       "      <td>0_x</td>\n",
       "      <td>50_x</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41590</th>\n",
       "      <td>9_x</td>\n",
       "      <td>674_x</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41591</th>\n",
       "      <td>9_x</td>\n",
       "      <td>146_x</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41592</th>\n",
       "      <td>9_x</td>\n",
       "      <td>2459_x</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41594</th>\n",
       "      <td>9_x</td>\n",
       "      <td>433_x</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41621</th>\n",
       "      <td>9_x</td>\n",
       "      <td>972_x</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>41622 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      user_id:token item_id:token  checkin_count:float\n",
       "0               0_x         775_x                    1\n",
       "7861            0_x          89_x                   15\n",
       "7862            0_x           7_x                    5\n",
       "7863            0_x          31_x                    1\n",
       "7864            0_x          50_x                    2\n",
       "...             ...           ...                  ...\n",
       "41590           9_x         674_x                   15\n",
       "41591           9_x         146_x                    1\n",
       "41592           9_x        2459_x                    1\n",
       "41594           9_x         433_x                    2\n",
       "41621           9_x         972_x                    1\n",
       "\n",
       "[41622 rows x 3 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_intervened"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_saver_recbole(train_df_intervened, \"recbole_debias\", \"train.inter\")\n",
    "data_saver_recbole(test_df_intervened, \"recbole_debias\", \"test.inter\")\n",
    "data_saver_recbole(val_df_intervened, \"recbole_debias\", \"valid.inter\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save for CAPRI without _x since they require integers as IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_id_cleaner(df, column_name_list = [\"user_id:token\", \"item_id:token\"]):\n",
    "    for column_name in column_name_list:\n",
    "        df[column_name] = df[column_name].str.split(\"_\")\n",
    "        df[column_name] = df[column_name].apply(lambda x: x[0])\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9q/p0b6nwnd5071040x3849mdvc0000gn/T/ipykernel_58945/2072793301.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[column_name] = df[column_name].str.split(\"_\")\n",
      "/var/folders/9q/p0b6nwnd5071040x3849mdvc0000gn/T/ipykernel_58945/2072793301.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[column_name] = df[column_name].apply(lambda x: x[0])\n"
     ]
    }
   ],
   "source": [
    "poi_df_sample_capri = user_id_cleaner(poi_df_sample_capri, [\"item_id:token\"])\n",
    "train_df = user_id_cleaner(train_df)\n",
    "val_df = user_id_cleaner(val_df)\n",
    "test_df = user_id_cleaner(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved as checkins.txt\n",
      "Data saved as dataSize.txt\n",
      "Data saved as poiCoos.txt\n",
      "Data saved as train.txt\n",
      "Data saved as tune.txt\n",
      "Data saved as test.txt\n"
     ]
    }
   ],
   "source": [
    "datasaver_capri(checkin_df_timestamp, \"checkins\")\n",
    "datasaver_capri(datasize_capri, \"dataSize\")\n",
    "datasaver_capri(poi_df_sample_capri, \"poiCoos\")\n",
    "datasaver_capri(train_df, \"train\")\n",
    "datasaver_capri(val_df, \"tune\")\n",
    "datasaver_capri(test_df, \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"item_id:token\"].nunique()\n",
    "\n",
    "train_df[\"user_id:token\"] = train_df[\"user_id:token\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2799"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[\"item_id:token\"].nunique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id:token</th>\n",
       "      <th>item_id:token</th>\n",
       "      <th>checkin_count:float</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30184</th>\n",
       "      <td>158</td>\n",
       "      <td>999</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23997</th>\n",
       "      <td>316</td>\n",
       "      <td>999</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59406</th>\n",
       "      <td>32</td>\n",
       "      <td>999</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33937</th>\n",
       "      <td>1484</td>\n",
       "      <td>999</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90836</th>\n",
       "      <td>349</td>\n",
       "      <td>999</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76823</th>\n",
       "      <td>285</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31958</th>\n",
       "      <td>496</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29880</th>\n",
       "      <td>362</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73601</th>\n",
       "      <td>485</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>43186 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       user_id:token item_id:token  checkin_count:float\n",
       "30184            158           999                    2\n",
       "23997            316           999                    1\n",
       "59406             32           999                    1\n",
       "33937           1484           999                    1\n",
       "90836            349           999                    1\n",
       "...              ...           ...                  ...\n",
       "76823            285             0                    1\n",
       "31958            496             0                    2\n",
       "29880            362             0                    1\n",
       "73601            485             0                    1\n",
       "1                  0             0                    2\n",
       "\n",
       "[43186 rows x 3 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "train_df.sort_values(by=\"item_id:token\", ascending=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
