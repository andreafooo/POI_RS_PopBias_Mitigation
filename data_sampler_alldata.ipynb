{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "from globals import BASE_DIR\n",
    "\n",
    "include_categories = False\n",
    "\n",
    "dataset = \"foursquaretky\"\n",
    "\n",
    "DATASET_DIR = f\"{BASE_DIR}{dataset}_dataset/\"\n",
    "#DATASET_DIR = f\"/Users/andreaforster/Documents/data_thesis/{dataset}_dataset/\"\n",
    "\n",
    "\n",
    "available_datasets = [\"foursquarenyc\", \"foursquaretky\", \"yelp\", \"gowalla\", \"brightkite\", \"snowcard\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_big_json(file_path):\n",
    "    data = []\n",
    "\n",
    "    # Open the file and read it line by line\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            # Parse the JSON data and append to the list\n",
    "            data.append(json.loads(line))\n",
    "\n",
    "    # Create a DataFrame from the list of records\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_unix_timestamp(df, column_name):\n",
    "    \"\"\"\n",
    "    Convert a column of timestamps in a DataFrame to Unix timestamps.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The DataFrame containing the timestamp column.\n",
    "        column_name (str): The name of the column with timestamps in \"%Y-%m-%d %H:%M:%S\" format.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The DataFrame with an additional column for Unix timestamps.\n",
    "    \"\"\"\n",
    "    # Convert the column to datetime objects\n",
    "    df[column_name] = pd.to_datetime(df[column_name], format=\"mixed\")\n",
    "    \n",
    "    # Convert datetime objects to Unix timestamps\n",
    "    df[f'{column_name}'] = df[column_name].apply(lambda x: x.timestamp())\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dataset == \"snowcard\":\n",
    "    checkin_df = pd.read_csv(DATASET_DIR+\"TSC_EEL_EXPORT.csv\", encoding=\"latin1\", sep=\";\", header=None, names=[\"timestamp:float\", \"user_id:token\", \"category_id:token\", \"category_name:token_seq\", \"name:token_seq\", \"user_type:token_seq\"])\n",
    "    checkin_df[\"item_id:token\"], item_id = pd.factorize(checkin_df[\"name:token_seq\"])\n",
    "    user_df = checkin_df[[\"user_id:token\", \"user_type:token_seq\"]].drop_duplicates(subset=[\"user_id:token\"])\n",
    "    poi_df = checkin_df[[\"item_id:token\", \"name:token_seq\", \"category_id:token\", \"category_name:token_seq\"]].drop_duplicates(subset=[\"item_id:token\"])\n",
    "    checkin_df = checkin_df[[\"user_id:token\", \"item_id:token\", \"timestamp:float\"]]\n",
    "\n",
    "elif dataset == \"foursquarenyc\" or dataset == \"foursquaretky\":\n",
    "    checkin_df = pd.read_csv(DATASET_DIR + \"foursquare_data.csv\", sep=\",\")\n",
    "    checkin_df = checkin_df.drop(columns=[\"timezoneOffset\"])\n",
    "    checkin_df = checkin_df.rename(columns={\"venueId\": \"item_id:token\", \"venueCategoryId\": \"category_id:token\", \"venueCategory\": \"category_name:token_seq\", \"userId\": \"user_id:token\", \"utcTimestamp\": \"timestamp:float\", \"latitude\": \"lat:float\", \"longitude\": \"lon:float\"})\n",
    "    user_df = checkin_df[[\"user_id:token\"]].drop_duplicates()\n",
    "\n",
    "    poi_df = checkin_df[[\"item_id:token\", \"category_id:token\", \"category_name:token_seq\", \"lat:float\", \"lon:float\"]].drop_duplicates(subset=[\"item_id:token\"])\n",
    "    checkin_df = checkin_df[[\"user_id:token\", \"item_id:token\", \"timestamp:float\"]]\n",
    "\n",
    "elif dataset == \"gowalla\" or dataset == \"brightkite\":\n",
    "    checkin_df = pd.read_csv(DATASET_DIR + f\"loc-{dataset}_totalCheckins.txt\", sep=\"\\t\", header=None, names=['user_id:token', 'timestamp:float', 'lat:float', 'lon:float', 'item_id:token'])\n",
    "    checkin_df = checkin_df[~checkin_df['item_id:token'].isin([\"00000000000000000000000000000000\", \"ede07eeea22411dda0ef53e233ec57ca\"])]\n",
    "    user_df = pd.read_csv(DATASET_DIR + f\"loc-{dataset}_edges.txt\", sep=\"\\t\", header=None, names=['user_id:token', 'friends:token_seq'])\n",
    "    user_df = user_df.groupby('user_id:token')['friends:token_seq'].apply(lambda x: ','.join(map(str, x))).reset_index()\n",
    "    user_df.columns = ['user_id:token', 'friends:token_seq']\n",
    "    poi_df = checkin_df[['item_id:token', \"lat:float\", \"lon:float\"]].drop_duplicates(subset=\"item_id:token\")\n",
    "    checkin_df = checkin_df.drop(columns=[\"lat:float\", \"lon:float\"])\n",
    "\n",
    "elif dataset == \"yelp\":\n",
    "    poi_df = pd.read_json(DATASET_DIR + \"yelp_academic_dataset_business.json\", lines=True)\n",
    "    poi_df = poi_df.loc[poi_df['is_open'] == 1]\n",
    "    poi_df = poi_df.drop(columns=[\"review_count\", \"stars\", \"hours\", \"is_open\", \"city\", \"state\", \"postal_code\", \"attributes\", \"address\"])\n",
    "    poi_df = poi_df.rename(columns={\"latitude\": \"lat:float\", \"longitude\": \"lon:float\", \"business_id\": \"item_id:token\", \"name\":\"name:token_seq\", \"categories\":\"category_name:token_seq\"})\n",
    "    user_df = open_big_json(DATASET_DIR + \"yelp_academic_dataset_user.json\")\n",
    "    user_df = user_df.drop(columns=[\"review_count\", \"name\", \"yelping_since\", \"useful\", \"funny\", \"cool\", \"elite\", \"fans\", \"compliment_hot\", \"average_stars\", \"compliment_more\", \"compliment_profile\", \"compliment_cute\", \"compliment_list\", \"compliment_note\", \"compliment_plain\", \"compliment_cool\", \"compliment_funny\", \"compliment_writer\", \"compliment_photos\"])\n",
    "    user_df = user_df.rename(columns={\"user_id\": \"user_id:token\", \"friends\": \"friends:token_seq\"})\n",
    "    checkin_df = open_big_json(DATASET_DIR + \"yelp_academic_dataset_review.json\")\n",
    "    checkin_df = checkin_df.drop(columns=[\"text\", \"cool\", \"stars\", \"useful\", \"funny\", \"review_id\"])\n",
    "    checkin_df = checkin_df.rename(columns={\"user_id\": \"user_id:token\", \"business_id\": \"item_id:token\", \"date\": \"timestamp:float\"})\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkin_df_timestamp = checkin_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 1: Group by user_id and business_id and count check-ins\n",
    "checkin_df['checkin_count:float'] = checkin_df.groupby(['user_id:token', 'item_id:token'])['item_id:token'].transform('count')\n",
    "checkin_df = checkin_df.drop_duplicates(subset=[\"user_id:token\", \"item_id:token\"], keep=\"first\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id:token</th>\n",
       "      <th>item_id:token</th>\n",
       "      <th>timestamp:float</th>\n",
       "      <th>checkin_count:float</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1541</td>\n",
       "      <td>4f0fd5a8e4b03856eeb6c8cb</td>\n",
       "      <td>Tue Apr 03 18:17:18 +0000 2012</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>868</td>\n",
       "      <td>4b7b884ff964a5207d662fe3</td>\n",
       "      <td>Tue Apr 03 18:22:04 +0000 2012</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>114</td>\n",
       "      <td>4c16fdda96040f477cc473a5</td>\n",
       "      <td>Tue Apr 03 19:12:07 +0000 2012</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>868</td>\n",
       "      <td>4c178638c2dfc928651ea869</td>\n",
       "      <td>Tue Apr 03 19:12:13 +0000 2012</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1458</td>\n",
       "      <td>4f568309e4b071452e447afe</td>\n",
       "      <td>Tue Apr 03 19:18:23 +0000 2012</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>573691</th>\n",
       "      <td>390</td>\n",
       "      <td>50ada82ce4b0d4508a244756</td>\n",
       "      <td>Sat Feb 16 02:31:44 +0000 2013</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>573698</th>\n",
       "      <td>326</td>\n",
       "      <td>4bab3456f964a5204d993ae3</td>\n",
       "      <td>Sat Feb 16 02:34:35 +0000 2013</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>573699</th>\n",
       "      <td>853</td>\n",
       "      <td>4b559c09f964a520efe827e3</td>\n",
       "      <td>Sat Feb 16 02:34:53 +0000 2013</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>573700</th>\n",
       "      <td>1502</td>\n",
       "      <td>5101e81ee4b020384100b0a5</td>\n",
       "      <td>Sat Feb 16 02:34:55 +0000 2013</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>573701</th>\n",
       "      <td>408</td>\n",
       "      <td>4bbc5648afe1b7134743304b</td>\n",
       "      <td>Sat Feb 16 02:35:17 +0000 2013</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>211955 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_id:token             item_id:token  \\\n",
       "0                1541  4f0fd5a8e4b03856eeb6c8cb   \n",
       "1                 868  4b7b884ff964a5207d662fe3   \n",
       "2                 114  4c16fdda96040f477cc473a5   \n",
       "3                 868  4c178638c2dfc928651ea869   \n",
       "4                1458  4f568309e4b071452e447afe   \n",
       "...               ...                       ...   \n",
       "573691            390  50ada82ce4b0d4508a244756   \n",
       "573698            326  4bab3456f964a5204d993ae3   \n",
       "573699            853  4b559c09f964a520efe827e3   \n",
       "573700           1502  5101e81ee4b020384100b0a5   \n",
       "573701            408  4bbc5648afe1b7134743304b   \n",
       "\n",
       "                       timestamp:float  checkin_count:float  \n",
       "0       Tue Apr 03 18:17:18 +0000 2012                    8  \n",
       "1       Tue Apr 03 18:22:04 +0000 2012                    1  \n",
       "2       Tue Apr 03 19:12:07 +0000 2012                    1  \n",
       "3       Tue Apr 03 19:12:13 +0000 2012                    5  \n",
       "4       Tue Apr 03 19:18:23 +0000 2012                    3  \n",
       "...                                ...                  ...  \n",
       "573691  Sat Feb 16 02:31:44 +0000 2013                    1  \n",
       "573698  Sat Feb 16 02:34:35 +0000 2013                    1  \n",
       "573699  Sat Feb 16 02:34:53 +0000 2013                    1  \n",
       "573700  Sat Feb 16 02:34:55 +0000 2013                    1  \n",
       "573701  Sat Feb 16 02:35:17 +0000 2013                    1  \n",
       "\n",
       "[211955 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkin_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of users, number of POIs 2293 61858\n",
      "Sparsity: 0.9985056795598015\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of users, number of POIs\", len(checkin_df[\"user_id:token\"].unique()), len(checkin_df[\"item_id:token\"].unique())\n",
    ")\n",
    "print(\"Sparsity:\", 1 - len(checkin_df) / (len(checkin_df[\"user_id:token\"].unique()) * len(checkin_df[\"item_id:token\"].unique())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_df(df, min_reviews_user=15, min_reviews_business=10):\n",
    "    while True:\n",
    "        # Filter businesses with at least min_reviews reviews\n",
    "        business_counts = df[\"item_id:token\"].value_counts()\n",
    "        business_mask = df['item_id:token'].map(business_counts) >= min_reviews_business\n",
    "        df_filtered = df.loc[business_mask]\n",
    "\n",
    "        # Filter users with at least min_reviews reviews\n",
    "        user_counts = df_filtered['user_id:token'].value_counts()\n",
    "        user_mask = df_filtered['user_id:token'].map(user_counts) >= min_reviews_user\n",
    "        df_filtered = df_filtered.loc[user_mask]\n",
    "\n",
    "        # If the size of the filtered DataFrame didn't change, break the loop\n",
    "        if df_filtered.shape[0] == df.shape[0]:\n",
    "            break\n",
    "\n",
    "        # Update the DataFrame for the next iteration\n",
    "        df = df_filtered\n",
    "\n",
    "    return df_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkin_df_filtered = filter_df(checkin_df, min_reviews_business=10, min_reviews_user=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2110, 2804)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkin_df_filtered[\"user_id:token\"].nunique(), checkin_df_filtered[\"item_id:token\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Calculate the value counts of `business_id`\n",
    "value_counts = checkin_df_filtered['item_id:token'].value_counts().reset_index()\n",
    "value_counts.columns = ['item_id:token', 'count']\n",
    "\n",
    "# Step 2: Normalize the counts y dividing by the maximum value count\n",
    "max_count = value_counts['count'].max()\n",
    "value_counts['business_popularity:float'] = value_counts['count'] / max_count\n",
    "\n",
    "# Step 3: Merge the normalized counts back into the original DataFrame\n",
    "checkin_df_filtered = checkin_df_filtered.merge(value_counts[['item_id:token', 'business_popularity:float']], on = \"item_id:token\", how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_popularity_sample_calculator(checkin_df_filtered, poi_df, user_df, sep_num, checkin_df_timestamp):\n",
    "    # Calculate average popularity per user\n",
    "    average_popularity_per_user = checkin_df_filtered.groupby('user_id:token')['business_popularity:float'].mean().reset_index()\n",
    "    average_popularity_per_user.columns = ['user_id:token', 'average_popularity']\n",
    "\n",
    "    average_popularity_per_user = average_popularity_per_user.sort_values(by=\"average_popularity\", ascending=False)\n",
    "\n",
    "    \n",
    "    # Sort by average popularity\n",
    "    \n",
    "\n",
    "    # Get top 1000 users\n",
    "    high_pop_user_df_sample = average_popularity_per_user.head(sep_num)\n",
    "    \n",
    "    # Get the middle 1000 users around the median\n",
    "    median_index = len(average_popularity_per_user) // 2\n",
    "    start_med_index = max(median_index -int (sep_num/2), 0)\n",
    "    end_med_index = min(median_index + int(sep_num/2), len(average_popularity_per_user))\n",
    "    med_pop_user_df_sample = average_popularity_per_user.iloc[start_med_index:end_med_index]\n",
    "    \n",
    "    # Get the lowest 1000 users\n",
    "    low_pop_user_df_sample = average_popularity_per_user.tail(sep_num)\n",
    "\n",
    "    unique_users = list(set(high_pop_user_df_sample[\"user_id:token\"].tolist() + med_pop_user_df_sample[\"user_id:token\"].tolist() + low_pop_user_df_sample[\"user_id:token\"].tolist()))\n",
    "\n",
    "    checkin_df_sample = checkin_df_filtered[checkin_df_filtered[\"user_id:token\"].isin(unique_users)]\n",
    "    checkin_df_sample = checkin_df_sample[checkin_df_sample[\"user_id:token\"].isin(unique_users)]\n",
    "\n",
    "    # unique_items = checkin_df_sample[\"item_id:token\"].unique()\n",
    "    # print(len(unique_items))\n",
    "\n",
    "    user_df_sample = user_df[user_df[\"user_id:token\"].isin(unique_users)]\n",
    "    poi_df_sample = poi_df[poi_df[\"item_id:token\"].isin(checkin_df_sample[\"item_id:token\"])]\n",
    "\n",
    "    checkin_df_sample = checkin_df_sample[checkin_df_sample[\"item_id:token\"].isin(poi_df_sample[\"item_id:token\"])]\n",
    "\n",
    "    checkin_df_timestamp = checkin_df_timestamp[checkin_df_timestamp[\"user_id:token\"].isin(unique_users)]\n",
    "    checkin_df_timestamp = checkin_df_timestamp[checkin_df_timestamp[\"item_id:token\"].isin(poi_df_sample[\"item_id:token\"])]\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    return checkin_df_sample, high_pop_user_df_sample, med_pop_user_df_sample, low_pop_user_df_sample, user_df_sample, poi_df_sample, checkin_df_timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n"
     ]
    }
   ],
   "source": [
    "if checkin_df_filtered[\"user_id:token\"].nunique() > 1500:\n",
    "    sep_num = 500\n",
    "else:\n",
    "    sep_num = checkin_df_filtered[\"user_id:token\"].nunique() // 3\n",
    "\n",
    "print(sep_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkin_df_sample, high_pop_user_df_sample, med_pop_user_df_sample, low_pop_user_df_sample, user_df_sample, poi_df_sample, checkin_df_timestamp = user_popularity_sample_calculator(checkin_df_filtered, poi_df, user_df, sep_num, checkin_df_timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2804"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkin_df_sample[\"item_id:token\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2804"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkin_df_timestamp[\"item_id:token\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1500"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkin_df_sample[\"user_id:token\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1500"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkin_df_timestamp[\"user_id:token\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id:token</th>\n",
       "      <th>average_popularity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1539</th>\n",
       "      <td>1663</td>\n",
       "      <td>0.375598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1255</th>\n",
       "      <td>1355</td>\n",
       "      <td>0.320627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1688</th>\n",
       "      <td>1826</td>\n",
       "      <td>0.315125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1878</th>\n",
       "      <td>2037</td>\n",
       "      <td>0.293083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1523</th>\n",
       "      <td>1647</td>\n",
       "      <td>0.292703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>692</th>\n",
       "      <td>751</td>\n",
       "      <td>0.161415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>558</th>\n",
       "      <td>603</td>\n",
       "      <td>0.161411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>961</td>\n",
       "      <td>0.161367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1865</th>\n",
       "      <td>2020</td>\n",
       "      <td>0.161305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>314</td>\n",
       "      <td>0.161305</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      user_id:token  average_popularity\n",
       "1539           1663            0.375598\n",
       "1255           1355            0.320627\n",
       "1688           1826            0.315125\n",
       "1878           2037            0.293083\n",
       "1523           1647            0.292703\n",
       "...             ...                 ...\n",
       "692             751            0.161415\n",
       "558             603            0.161411\n",
       "887             961            0.161367\n",
       "1865           2020            0.161305\n",
       "285             314            0.161305\n",
       "\n",
       "[500 rows x 2 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "high_pop_user_df_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id:token</th>\n",
       "      <th>average_popularity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2034</th>\n",
       "      <td>2211</td>\n",
       "      <td>0.142278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>803</th>\n",
       "      <td>873</td>\n",
       "      <td>0.142158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>452</td>\n",
       "      <td>0.142158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1410</th>\n",
       "      <td>1529</td>\n",
       "      <td>0.142045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021</th>\n",
       "      <td>2198</td>\n",
       "      <td>0.141976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>65</td>\n",
       "      <td>0.116345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1803</th>\n",
       "      <td>1953</td>\n",
       "      <td>0.116162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516</th>\n",
       "      <td>558</td>\n",
       "      <td>0.116140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1404</th>\n",
       "      <td>1522</td>\n",
       "      <td>0.116065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>193</td>\n",
       "      <td>0.115789</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      user_id:token  average_popularity\n",
       "2034           2211            0.142278\n",
       "803             873            0.142158\n",
       "416             452            0.142158\n",
       "1410           1529            0.142045\n",
       "2021           2198            0.141976\n",
       "...             ...                 ...\n",
       "60               65            0.116345\n",
       "1803           1953            0.116162\n",
       "516             558            0.116140\n",
       "1404           1522            0.116065\n",
       "174             193            0.115789\n",
       "\n",
       "[500 rows x 2 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "med_pop_user_df_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id:token</th>\n",
       "      <th>average_popularity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>125</td>\n",
       "      <td>0.096929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1925</th>\n",
       "      <td>2091</td>\n",
       "      <td>0.096907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>423</td>\n",
       "      <td>0.096900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>652</th>\n",
       "      <td>708</td>\n",
       "      <td>0.096900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>427</td>\n",
       "      <td>0.096863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1033</th>\n",
       "      <td>1117</td>\n",
       "      <td>0.026903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1295</th>\n",
       "      <td>1401</td>\n",
       "      <td>0.026694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>112</td>\n",
       "      <td>0.018677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1751</th>\n",
       "      <td>1892</td>\n",
       "      <td>0.017872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1715</th>\n",
       "      <td>1855</td>\n",
       "      <td>0.016198</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      user_id:token  average_popularity\n",
       "114             125            0.096929\n",
       "1925           2091            0.096907\n",
       "389             423            0.096900\n",
       "652             708            0.096900\n",
       "393             427            0.096863\n",
       "...             ...                 ...\n",
       "1033           1117            0.026903\n",
       "1295           1401            0.026694\n",
       "103             112            0.018677\n",
       "1751           1892            0.017872\n",
       "1715           1855            0.016198\n",
       "\n",
       "[500 rows x 2 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "low_pop_user_df_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def id_factorizer(checkin_df_sample, high_pop_user_df_sample, med_pop_user_df_sample, low_pop_user_df_sample, user_df_sample, poi_df_sample):\n",
    "    \"\"\"Overwriting the actual ID with a factorized ID so that we can use the same ID both in RecBole and CAPRI\"\"\"\n",
    "    checkin_df_sample['user_id:token'], user_id_map = pd.factorize(checkin_df_sample['user_id:token'])\n",
    "    checkin_df_sample['item_id:token'], business_id_map = pd.factorize(checkin_df_sample['item_id:token'])\n",
    "\n",
    "    # Create mapping dictionaries\n",
    "    user_id_mapping = {original: i for i, original in enumerate(user_id_map)}\n",
    "    business_id_mapping = {original: j for j, original in enumerate(business_id_map)}\n",
    "\n",
    "    high_pop_user_df_sample['user_id:token'] = high_pop_user_df_sample['user_id:token'].map(user_id_mapping)\n",
    "    med_pop_user_df_sample['user_id:token'] = med_pop_user_df_sample['user_id:token'].map(user_id_mapping)\n",
    "    low_pop_user_df_sample['user_id:token'] = low_pop_user_df_sample['user_id:token'].map(user_id_mapping)\n",
    "\n",
    "    user_df_sample['user_id:token'] = user_df_sample['user_id:token'].map(user_id_mapping)\n",
    "    poi_df_sample['item_id:token'] = poi_df_sample['item_id:token'].map(business_id_mapping)\n",
    "\n",
    "\n",
    "    return checkin_df_sample, high_pop_user_df_sample, med_pop_user_df_sample, low_pop_user_df_sample, user_df_sample, poi_df_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9q/p0b6nwnd5071040x3849mdvc0000gn/T/ipykernel_66772/1053926560.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  user_df_sample['user_id:token'] = user_df_sample['user_id:token'].map(user_id_mapping)\n",
      "/var/folders/9q/p0b6nwnd5071040x3849mdvc0000gn/T/ipykernel_66772/1053926560.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  poi_df_sample['item_id:token'] = poi_df_sample['item_id:token'].map(business_id_mapping)\n"
     ]
    }
   ],
   "source": [
    "checkin_df_sample, high_pop_user_df_sample, med_pop_user_df_sample, low_pop_user_df_sample, user_df_sample, poi_df_sample = id_factorizer(checkin_df_sample, high_pop_user_df_sample, med_pop_user_df_sample, low_pop_user_df_sample, user_df_sample, poi_df_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_id_token_adder(df, column_name_list = [\"user_id:token\", \"item_id:token\"]):\n",
    "    \"\"\" Recbole needs a token instead of a number for the user and item ID\"\"\"\n",
    "    for column_name in column_name_list:\n",
    "        try:\n",
    "            df[column_name] = df[column_name].astype(str) + \"_x\"\n",
    "        except KeyError:\n",
    "            pass\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9q/p0b6nwnd5071040x3849mdvc0000gn/T/ipykernel_66772/1404554777.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[column_name] = df[column_name].astype(str) + \"_x\"\n",
      "/var/folders/9q/p0b6nwnd5071040x3849mdvc0000gn/T/ipykernel_66772/1404554777.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[column_name] = df[column_name].astype(str) + \"_x\"\n"
     ]
    }
   ],
   "source": [
    "checkin_df_sample = user_id_token_adder(checkin_df_sample)\n",
    "high_pop_user_df_sample = user_id_token_adder(high_pop_user_df_sample)\n",
    "med_pop_user_df_sample = user_id_token_adder(med_pop_user_df_sample)\n",
    "low_pop_user_df_sample = user_id_token_adder(low_pop_user_df_sample)\n",
    "user_df_sample = user_id_token_adder(user_df_sample)\n",
    "poi_df_sample = user_id_token_adder(poi_df_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id:token</th>\n",
       "      <th>average_popularity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2034</th>\n",
       "      <td>326_x</td>\n",
       "      <td>0.142278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>803</th>\n",
       "      <td>1488_x</td>\n",
       "      <td>0.142158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>657_x</td>\n",
       "      <td>0.142158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1410</th>\n",
       "      <td>246_x</td>\n",
       "      <td>0.142045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021</th>\n",
       "      <td>581_x</td>\n",
       "      <td>0.141976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>397_x</td>\n",
       "      <td>0.116345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1803</th>\n",
       "      <td>448_x</td>\n",
       "      <td>0.116162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516</th>\n",
       "      <td>766_x</td>\n",
       "      <td>0.116140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1404</th>\n",
       "      <td>1166_x</td>\n",
       "      <td>0.116065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>1197_x</td>\n",
       "      <td>0.115789</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     user_id:token  average_popularity\n",
       "2034         326_x            0.142278\n",
       "803         1488_x            0.142158\n",
       "416          657_x            0.142158\n",
       "1410         246_x            0.142045\n",
       "2021         581_x            0.141976\n",
       "...            ...                 ...\n",
       "60           397_x            0.116345\n",
       "1803         448_x            0.116162\n",
       "516          766_x            0.116140\n",
       "1404        1166_x            0.116065\n",
       "174         1197_x            0.115789\n",
       "\n",
       "[500 rows x 2 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "med_pop_user_df_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a json with the user id's of the respective popularity groups\n",
    "user_id_popularity = {}\n",
    "user_id_popularity[\"high\"] = high_pop_user_df_sample[\"user_id:token\"].tolist()\n",
    "user_id_popularity[\"medium\"] = med_pop_user_df_sample[\"user_id:token\"].tolist()\n",
    "user_id_popularity[\"low\"] = low_pop_user_df_sample[\"user_id:token\"].tolist()\n",
    "json.dump(user_id_popularity, open(f\"{DATASET_DIR}/{dataset}_user_id_popularity.json\", \"w\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_saver(df, filename, framework):\n",
    "    if not os.path.exists(DATASET_DIR + \"processed_data_\" + framework):\n",
    "        os.makedirs(DATASET_DIR + \"processed_data_\" + framework)\n",
    "    \n",
    "    df.to_csv(DATASET_DIR + \"processed_data_\" + framework + \"/\" + filename + \".csv\")\n",
    "    print(\"Data saved as \" + framework + filename + \".csv\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved as cornacuser_events.csv\n",
      "Data saved as cornachigh_pop_user_sample.csv\n",
      "Data saved as cornacmedium_pop_user_sample.csv\n",
      "Data saved as cornaclow_pop_user_sample.csv\n"
     ]
    }
   ],
   "source": [
    "# first of all saving data for cornac\n",
    "data_saver(checkin_df_sample, \"user_events\", \"cornac\")\n",
    "data_saver(high_pop_user_df_sample, \"high_pop_user_sample\", \"cornac\")\n",
    "data_saver(med_pop_user_df_sample, \"medium_pop_user_sample\", \"cornac\")\n",
    "data_saver(low_pop_user_df_sample, \"low_pop_user_sample\", \"cornac\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_saver_recbole(df, framework, suffix):\n",
    "    \n",
    "    if not os.path.exists(DATASET_DIR + \"processed_data_\" + framework):\n",
    "        os.makedirs(DATASET_DIR + \"processed_data_\" + framework)\n",
    "\n",
    "    df.to_csv(f\"{DATASET_DIR}processed_data_{framework}/{dataset}_sample.{suffix}\", sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkin_df_sample['review_id:token'] = range(1, len(checkin_df_sample) + 1)\n",
    "# Step 1: Group by user_id and business_id and count check-ins\n",
    "checkin_df_sample['checkin_count:float'] = checkin_df_sample.groupby(['user_id:token', 'item_id:token'])['item_id:token'].transform('count')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id:token</th>\n",
       "      <th>item_id:token</th>\n",
       "      <th>timestamp:float</th>\n",
       "      <th>checkin_count:float</th>\n",
       "      <th>business_popularity:float</th>\n",
       "      <th>review_id:token</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0_x</td>\n",
       "      <td>0_x</td>\n",
       "      <td>Tue Apr 03 19:35:36 +0000 2012</td>\n",
       "      <td>1</td>\n",
       "      <td>0.104466</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1_x</td>\n",
       "      <td>1_x</td>\n",
       "      <td>Tue Apr 03 19:59:06 +0000 2012</td>\n",
       "      <td>1</td>\n",
       "      <td>0.173844</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1_x</td>\n",
       "      <td>2_x</td>\n",
       "      <td>Tue Apr 03 20:09:41 +0000 2012</td>\n",
       "      <td>1</td>\n",
       "      <td>0.053429</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2_x</td>\n",
       "      <td>3_x</td>\n",
       "      <td>Tue Apr 03 20:14:18 +0000 2012</td>\n",
       "      <td>1</td>\n",
       "      <td>0.039075</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2_x</td>\n",
       "      <td>4_x</td>\n",
       "      <td>Tue Apr 03 20:28:32 +0000 2012</td>\n",
       "      <td>1</td>\n",
       "      <td>0.086124</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99678</th>\n",
       "      <td>321_x</td>\n",
       "      <td>911_x</td>\n",
       "      <td>Sat Feb 16 02:15:32 +0000 2013</td>\n",
       "      <td>1</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>67522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99681</th>\n",
       "      <td>1309_x</td>\n",
       "      <td>966_x</td>\n",
       "      <td>Sat Feb 16 02:27:43 +0000 2013</td>\n",
       "      <td>1</td>\n",
       "      <td>0.048644</td>\n",
       "      <td>67523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99683</th>\n",
       "      <td>789_x</td>\n",
       "      <td>1498_x</td>\n",
       "      <td>Sat Feb 16 02:28:47 +0000 2013</td>\n",
       "      <td>1</td>\n",
       "      <td>0.012759</td>\n",
       "      <td>67524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99684</th>\n",
       "      <td>383_x</td>\n",
       "      <td>1129_x</td>\n",
       "      <td>Sat Feb 16 02:34:35 +0000 2013</td>\n",
       "      <td>1</td>\n",
       "      <td>0.015949</td>\n",
       "      <td>67525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99685</th>\n",
       "      <td>1487_x</td>\n",
       "      <td>509_x</td>\n",
       "      <td>Sat Feb 16 02:34:53 +0000 2013</td>\n",
       "      <td>1</td>\n",
       "      <td>0.088517</td>\n",
       "      <td>67526</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>67526 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      user_id:token item_id:token                 timestamp:float  \\\n",
       "0               0_x           0_x  Tue Apr 03 19:35:36 +0000 2012   \n",
       "1               1_x           1_x  Tue Apr 03 19:59:06 +0000 2012   \n",
       "2               1_x           2_x  Tue Apr 03 20:09:41 +0000 2012   \n",
       "3               2_x           3_x  Tue Apr 03 20:14:18 +0000 2012   \n",
       "4               2_x           4_x  Tue Apr 03 20:28:32 +0000 2012   \n",
       "...             ...           ...                             ...   \n",
       "99678         321_x         911_x  Sat Feb 16 02:15:32 +0000 2013   \n",
       "99681        1309_x         966_x  Sat Feb 16 02:27:43 +0000 2013   \n",
       "99683         789_x        1498_x  Sat Feb 16 02:28:47 +0000 2013   \n",
       "99684         383_x        1129_x  Sat Feb 16 02:34:35 +0000 2013   \n",
       "99685        1487_x         509_x  Sat Feb 16 02:34:53 +0000 2013   \n",
       "\n",
       "       checkin_count:float  business_popularity:float  review_id:token  \n",
       "0                        1                   0.104466                1  \n",
       "1                        1                   0.173844                2  \n",
       "2                        1                   0.053429                3  \n",
       "3                        1                   0.039075                4  \n",
       "4                        1                   0.086124                5  \n",
       "...                    ...                        ...              ...  \n",
       "99678                    1                   0.157895            67522  \n",
       "99681                    1                   0.048644            67523  \n",
       "99683                    1                   0.012759            67524  \n",
       "99684                    1                   0.015949            67525  \n",
       "99685                    1                   0.088517            67526  \n",
       "\n",
       "[67526 rows x 6 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkin_df_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkin_df_sample = convert_to_unix_timestamp(checkin_df_sample, \"timestamp:float\")\n",
    "checkin_df_timestamp = convert_to_unix_timestamp(checkin_df_timestamp, \"timestamp:float\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id:token</th>\n",
       "      <th>item_id:token</th>\n",
       "      <th>timestamp:float</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>114</td>\n",
       "      <td>4b3eae5cf964a520b4a025e3</td>\n",
       "      <td>1.333482e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>589</td>\n",
       "      <td>4b5ed39cf964a520079a29e3</td>\n",
       "      <td>1.333483e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>589</td>\n",
       "      <td>4d69a46cde28224b27ff45be</td>\n",
       "      <td>1.333484e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2290</td>\n",
       "      <td>4b53b05ef964a520e8a727e3</td>\n",
       "      <td>1.333484e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2290</td>\n",
       "      <td>4b6e3e46f964a520e2b32ce3</td>\n",
       "      <td>1.333485e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>573689</th>\n",
       "      <td>1718</td>\n",
       "      <td>4b0587a6f964a5203d9e22e3</td>\n",
       "      <td>1.360982e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>573692</th>\n",
       "      <td>2200</td>\n",
       "      <td>4b0587a6f964a5203d9e22e3</td>\n",
       "      <td>1.360982e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>573697</th>\n",
       "      <td>2277</td>\n",
       "      <td>4b56c4c5f964a520c41a28e3</td>\n",
       "      <td>1.360982e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>573698</th>\n",
       "      <td>326</td>\n",
       "      <td>4bab3456f964a5204d993ae3</td>\n",
       "      <td>1.360982e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>573699</th>\n",
       "      <td>853</td>\n",
       "      <td>4b559c09f964a520efe827e3</td>\n",
       "      <td>1.360982e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>219160 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_id:token             item_id:token  timestamp:float\n",
       "7                 114  4b3eae5cf964a520b4a025e3     1.333482e+09\n",
       "10                589  4b5ed39cf964a520079a29e3     1.333483e+09\n",
       "14                589  4d69a46cde28224b27ff45be     1.333484e+09\n",
       "15               2290  4b53b05ef964a520e8a727e3     1.333484e+09\n",
       "17               2290  4b6e3e46f964a520e2b32ce3     1.333485e+09\n",
       "...               ...                       ...              ...\n",
       "573689           1718  4b0587a6f964a5203d9e22e3     1.360982e+09\n",
       "573692           2200  4b0587a6f964a5203d9e22e3     1.360982e+09\n",
       "573697           2277  4b56c4c5f964a520c41a28e3     1.360982e+09\n",
       "573698            326  4bab3456f964a5204d993ae3     1.360982e+09\n",
       "573699            853  4b559c09f964a520efe827e3     1.360982e+09\n",
       "\n",
       "[219160 rows x 3 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkin_df_timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id:token</th>\n",
       "      <th>item_id:token</th>\n",
       "      <th>timestamp:float</th>\n",
       "      <th>checkin_count:float</th>\n",
       "      <th>business_popularity:float</th>\n",
       "      <th>review_id:token</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0_x</td>\n",
       "      <td>0_x</td>\n",
       "      <td>1.333482e+09</td>\n",
       "      <td>1</td>\n",
       "      <td>0.104466</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1_x</td>\n",
       "      <td>1_x</td>\n",
       "      <td>1.333483e+09</td>\n",
       "      <td>1</td>\n",
       "      <td>0.173844</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1_x</td>\n",
       "      <td>2_x</td>\n",
       "      <td>1.333484e+09</td>\n",
       "      <td>1</td>\n",
       "      <td>0.053429</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2_x</td>\n",
       "      <td>3_x</td>\n",
       "      <td>1.333484e+09</td>\n",
       "      <td>1</td>\n",
       "      <td>0.039075</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2_x</td>\n",
       "      <td>4_x</td>\n",
       "      <td>1.333485e+09</td>\n",
       "      <td>1</td>\n",
       "      <td>0.086124</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99678</th>\n",
       "      <td>321_x</td>\n",
       "      <td>911_x</td>\n",
       "      <td>1.360981e+09</td>\n",
       "      <td>1</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>67522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99681</th>\n",
       "      <td>1309_x</td>\n",
       "      <td>966_x</td>\n",
       "      <td>1.360982e+09</td>\n",
       "      <td>1</td>\n",
       "      <td>0.048644</td>\n",
       "      <td>67523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99683</th>\n",
       "      <td>789_x</td>\n",
       "      <td>1498_x</td>\n",
       "      <td>1.360982e+09</td>\n",
       "      <td>1</td>\n",
       "      <td>0.012759</td>\n",
       "      <td>67524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99684</th>\n",
       "      <td>383_x</td>\n",
       "      <td>1129_x</td>\n",
       "      <td>1.360982e+09</td>\n",
       "      <td>1</td>\n",
       "      <td>0.015949</td>\n",
       "      <td>67525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99685</th>\n",
       "      <td>1487_x</td>\n",
       "      <td>509_x</td>\n",
       "      <td>1.360982e+09</td>\n",
       "      <td>1</td>\n",
       "      <td>0.088517</td>\n",
       "      <td>67526</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>67526 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      user_id:token item_id:token  timestamp:float  checkin_count:float  \\\n",
       "0               0_x           0_x     1.333482e+09                    1   \n",
       "1               1_x           1_x     1.333483e+09                    1   \n",
       "2               1_x           2_x     1.333484e+09                    1   \n",
       "3               2_x           3_x     1.333484e+09                    1   \n",
       "4               2_x           4_x     1.333485e+09                    1   \n",
       "...             ...           ...              ...                  ...   \n",
       "99678         321_x         911_x     1.360981e+09                    1   \n",
       "99681        1309_x         966_x     1.360982e+09                    1   \n",
       "99683         789_x        1498_x     1.360982e+09                    1   \n",
       "99684         383_x        1129_x     1.360982e+09                    1   \n",
       "99685        1487_x         509_x     1.360982e+09                    1   \n",
       "\n",
       "       business_popularity:float  review_id:token  \n",
       "0                       0.104466                1  \n",
       "1                       0.173844                2  \n",
       "2                       0.053429                3  \n",
       "3                       0.039075                4  \n",
       "4                       0.086124                5  \n",
       "...                          ...              ...  \n",
       "99678                   0.157895            67522  \n",
       "99681                   0.048644            67523  \n",
       "99683                   0.012759            67524  \n",
       "99684                   0.015949            67525  \n",
       "99685                   0.088517            67526  \n",
       "\n",
       "[67526 rows x 6 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkin_df_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkin_df_sample.sort_values(by=\"checkin_count:float\", ascending=False)\n",
    "# very important: keeping the duplicate check-ins for the context aware recommendation to have the timestamps saved\n",
    "\n",
    "\n",
    "# very important: dropping duplicate check-ins \n",
    "checkin_df_sample = checkin_df_sample.drop_duplicates(subset=[\"user_id:token\", \"item_id:token\"], keep=\"first\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_df_sample = user_df_sample[[\"user_id:token\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_saver_recbole(checkin_df_sample, \"recbole\", \"inter\")\n",
    "data_saver_recbole(user_df_sample, \"recbole\", \"user\")\n",
    "data_saver_recbole(poi_df_sample, \"recbole\", \"item\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id:token</th>\n",
       "      <th>category_id:token</th>\n",
       "      <th>category_name:token_seq</th>\n",
       "      <th>lat:float</th>\n",
       "      <th>lon:float</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0_x</td>\n",
       "      <td>4bf58dd8d48988d129951735</td>\n",
       "      <td>Train Station</td>\n",
       "      <td>35.700253</td>\n",
       "      <td>139.480255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1_x</td>\n",
       "      <td>4bf58dd8d48988d1eb931735</td>\n",
       "      <td>Airport</td>\n",
       "      <td>35.548963</td>\n",
       "      <td>139.784611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2_x</td>\n",
       "      <td>4bf58dd8d48988d1df941735</td>\n",
       "      <td>Bridge</td>\n",
       "      <td>35.609929</td>\n",
       "      <td>139.825659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>3_x</td>\n",
       "      <td>4bf58dd8d48988d129951735</td>\n",
       "      <td>Train Station</td>\n",
       "      <td>35.749538</td>\n",
       "      <td>139.586540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>4_x</td>\n",
       "      <td>4bf58dd8d48988d129951735</td>\n",
       "      <td>Train Station</td>\n",
       "      <td>35.729025</td>\n",
       "      <td>139.711096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412051</th>\n",
       "      <td>2797_x</td>\n",
       "      <td>4bf58dd8d48988d120941735</td>\n",
       "      <td>Bar</td>\n",
       "      <td>35.697700</td>\n",
       "      <td>139.770384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425285</th>\n",
       "      <td>2799_x</td>\n",
       "      <td>4bf58dd8d48988d16d941735</td>\n",
       "      <td>Café</td>\n",
       "      <td>35.702436</td>\n",
       "      <td>139.770470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450169</th>\n",
       "      <td>2800_x</td>\n",
       "      <td>4bf58dd8d48988d129951735</td>\n",
       "      <td>Train Station</td>\n",
       "      <td>35.607054</td>\n",
       "      <td>139.734894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462519</th>\n",
       "      <td>2801_x</td>\n",
       "      <td>4d954b0ea243a5684a65b473</td>\n",
       "      <td>Convenience Store</td>\n",
       "      <td>35.701178</td>\n",
       "      <td>139.771038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488554</th>\n",
       "      <td>2803_x</td>\n",
       "      <td>4eb1daf44b900d56c88a4600</td>\n",
       "      <td>Fair</td>\n",
       "      <td>35.630669</td>\n",
       "      <td>139.795103</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2804 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       item_id:token         category_id:token category_name:token_seq  \\\n",
       "7                0_x  4bf58dd8d48988d129951735           Train Station   \n",
       "10               1_x  4bf58dd8d48988d1eb931735                 Airport   \n",
       "14               2_x  4bf58dd8d48988d1df941735                  Bridge   \n",
       "15               3_x  4bf58dd8d48988d129951735           Train Station   \n",
       "17               4_x  4bf58dd8d48988d129951735           Train Station   \n",
       "...              ...                       ...                     ...   \n",
       "412051        2797_x  4bf58dd8d48988d120941735                     Bar   \n",
       "425285        2799_x  4bf58dd8d48988d16d941735                    Café   \n",
       "450169        2800_x  4bf58dd8d48988d129951735           Train Station   \n",
       "462519        2801_x  4d954b0ea243a5684a65b473       Convenience Store   \n",
       "488554        2803_x  4eb1daf44b900d56c88a4600                    Fair   \n",
       "\n",
       "        lat:float   lon:float  \n",
       "7       35.700253  139.480255  \n",
       "10      35.548963  139.784611  \n",
       "14      35.609929  139.825659  \n",
       "15      35.749538  139.586540  \n",
       "17      35.729025  139.711096  \n",
       "...           ...         ...  \n",
       "412051  35.697700  139.770384  \n",
       "425285  35.702436  139.770470  \n",
       "450169  35.607054  139.734894  \n",
       "462519  35.701178  139.771038  \n",
       "488554  35.630669  139.795103  \n",
       "\n",
       "[2804 rows x 5 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poi_df_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkin_df_timestamp = checkin_df_timestamp[[\"user_id:token\", \"item_id:token\", \"timestamp:float\"]] # FINAL\n",
    "checkins_capri_train_test_tune = checkin_df_sample[[\"user_id:token\", \"item_id:token\", \"timestamp:float\", \"checkin_count:float\"]]\n",
    "try:\n",
    "    poi_df_sample_capri = poi_df_sample[[\"item_id:token\", \"lat:float\", \"lon:float\"]] # FINAL\n",
    "except KeyError: # in the snowcard data the coordinates are not given\n",
    "    poi_df_sample_capri = poi_df_sample[[\"item_id:token\"]]\n",
    "datasize_capri = pd.DataFrame(data={\"num_users\" : [len(checkins_capri_train_test_tune[\"user_id:token\"].unique())], \"num_items\" : [len(checkins_capri_train_test_tune[\"item_id:token\"].unique())]}) # FINAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Set:\n",
      "     user_id:token item_id:token  checkin_count:float\n",
      "0              0_x           0_x                    1\n",
      "9              0_x           9_x                    1\n",
      "2998           0_x          56_x                    1\n",
      "4963           0_x        1318_x                    1\n",
      "4983           0_x         406_x                    1\n",
      "\n",
      "Validation Set:\n",
      "      user_id:token item_id:token  checkin_count:float\n",
      "34388           0_x          93_x                    1\n",
      "34397           0_x        1933_x                    1\n",
      "34416           0_x          33_x                    1\n",
      "34504           0_x        2384_x                    1\n",
      "34543           0_x        1345_x                    1\n",
      "\n",
      "Test Set:\n",
      "      user_id:token item_id:token  checkin_count:float\n",
      "38256           0_x        1220_x                    1\n",
      "38335           0_x        2599_x                    1\n",
      "38650           0_x         296_x                    1\n",
      "41874           0_x          23_x                    1\n",
      "42233           0_x         206_x                    1\n"
     ]
    }
   ],
   "source": [
    "# splitting the data into train, test, and tune\n",
    "checkins_capri_train_test_tune = checkins_capri_train_test_tune.sort_values(by=[\"user_id:token\", \"timestamp:float\"])\n",
    "checkins_capri_train_test_tune = checkins_capri_train_test_tune[[\"user_id:token\", \"item_id:token\", \"checkin_count:float\"]]\n",
    "\n",
    "# Split the data\n",
    "train_list = []\n",
    "val_list = []\n",
    "test_list = []\n",
    "\n",
    "for user, group in checkins_capri_train_test_tune.groupby('user_id:token'):\n",
    "    n = len(group)\n",
    "    train_end = int(n * 0.65)\n",
    "    val_end = int(n * 0.80)\n",
    "    \n",
    "    train_list.append(group.iloc[:train_end])\n",
    "    val_list.append(group.iloc[train_end:val_end])\n",
    "    test_list.append(group.iloc[val_end:])\n",
    "\n",
    "# Combine lists into DataFrames\n",
    "train_df = pd.concat(train_list)\n",
    "val_df = pd.concat(val_list)\n",
    "test_df = pd.concat(test_list)\n",
    "\n",
    "\n",
    "\n",
    "# Check the splits\n",
    "\n",
    "# FINAL 6-8\n",
    "print(\"Train Set:\")\n",
    "print(train_df.head())\n",
    "print(\"\\nValidation Set:\")\n",
    "print(val_df.head())\n",
    "print(\"\\nTest Set:\")\n",
    "print(test_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def datasaver_capri(df, filename):\n",
    "    \n",
    "    if not os.path.exists(DATASET_DIR + \"processed_data_capri\"):\n",
    "        os.makedirs(DATASET_DIR + \"processed_data_capri\")\n",
    "    \n",
    "    df.to_csv(DATASET_DIR + \"processed_data_capri/\" + filename + \".txt\", sep='\\t', index=False, header=False)\n",
    "    print(\"Data saved as \" + filename + \".txt\")\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding a category column\n",
    "if include_categories is True:\n",
    "    if dataset == \"yelp\":\n",
    "        # Split the 'category_name' column by commas\n",
    "        poi_df_sample['category_name_unstacked:token_seq'] = poi_df_sample['category_name:token_seq'].str.split(', ')\n",
    "\n",
    "        # Unstack the categories into multiple rows\n",
    "        category_df_sample = poi_df_sample.explode('category_name_unstacked:token_seq')\n",
    "        category_counts = category_df_sample[\"category_name_unstacked:token_seq\"].value_counts()\n",
    "        category_mask = category_df_sample[\"category_name_unstacked:token_seq\"].map(category_counts) >= 25\n",
    "        category_df_sample_filtered = category_df_sample.loc[category_mask]\n",
    "        category_df_sample_filtered[\"category_id:token\"], category_id = pd.factorize(category_df_sample_filtered[\"category_name_unstacked:token_seq\"])\n",
    "        category_df_sample_filtered.dropna(inplace=True)\n",
    "        datasize_capri = pd.DataFrame(data={\"num_users\" : [len(checkins_capri_train_test_tune[\"user_id:token\"].unique())], \"num_items\" : [len(checkins_capri_train_test_tune[\"item_id:token\"].unique())], \"num_categories\" : [len(category_df_sample_filtered[\"category_id:token\"].unique())]}) # FINAL\n",
    "        datasaver_capri(category_df_sample_filtered, \"poiCategories\")\n",
    "\n",
    "\n",
    "    elif dataset == \"foursquarenyc\" or dataset == \"foursquaretky\":\n",
    "        poi_df_sample[\"category_id:token\"], category_id = pd.factorize(poi_df_sample[\"category_name:token_seq\"])\n",
    "        datasize_capri = pd.DataFrame(data={\"num_users\" : [len(checkins_capri_train_test_tune[\"user_id:token\"].unique())], \"num_items\" : [len(checkins_capri_train_test_tune[\"item_id:token\"].unique())], \"num_categories\" : [len(poi_df_sample[\"category_id:token\"].unique())]})\n",
    "        poi_df_categories = poi_df_sample[[\"item_id:token\", \"category_id:token\"]]\n",
    "        datasaver_capri(poi_df_categories, \"poiCategories\")\n",
    "\n",
    "    elif dataset == \"snowcard\":\n",
    "        datasize_capri = pd.DataFrame(data={\"num_users\" : [len(checkins_capri_train_test_tune[\"user_id:token\"].unique())], \"num_items\" : [len(checkins_capri_train_test_tune[\"item_id:token\"].unique())], \"num_categories\" : [len(poi_df_sample[\"category_id:token\"].unique())]})\n",
    "        poi_df_categories = poi_df_sample[[\"item_id:token\", \"category_id:token\"]]\n",
    "        datasaver_capri(poi_df_categories, \"poiCategories\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id:token</th>\n",
       "      <th>item_id:token</th>\n",
       "      <th>checkin_count:float</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0_x</td>\n",
       "      <td>0_x</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0_x</td>\n",
       "      <td>9_x</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>0_x</td>\n",
       "      <td>56_x</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4963</th>\n",
       "      <td>0_x</td>\n",
       "      <td>1318_x</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4983</th>\n",
       "      <td>0_x</td>\n",
       "      <td>406_x</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15808</th>\n",
       "      <td>9_x</td>\n",
       "      <td>1324_x</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33365</th>\n",
       "      <td>9_x</td>\n",
       "      <td>1818_x</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42277</th>\n",
       "      <td>9_x</td>\n",
       "      <td>679_x</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45786</th>\n",
       "      <td>9_x</td>\n",
       "      <td>1206_x</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48283</th>\n",
       "      <td>9_x</td>\n",
       "      <td>2518_x</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>43186 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      user_id:token item_id:token  checkin_count:float\n",
       "0               0_x           0_x                    1\n",
       "9               0_x           9_x                    1\n",
       "2998            0_x          56_x                    1\n",
       "4963            0_x        1318_x                    1\n",
       "4983            0_x         406_x                    1\n",
       "...             ...           ...                  ...\n",
       "15808           9_x        1324_x                    1\n",
       "33365           9_x        1818_x                    1\n",
       "42277           9_x         679_x                    1\n",
       "45786           9_x        1206_x                    1\n",
       "48283           9_x        2518_x                    1\n",
       "\n",
       "[43186 rows x 3 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_saver_recbole(train_df, \"recbole_debias\", \"train.inter\")\n",
    "data_saver_recbole(test_df, \"recbole_debias\", \"test.inter\")\n",
    "data_saver_recbole(val_df, \"recbole_debias\", \"valid.inter\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_id_cleaner(df, column_name_list = [\"user_id:token\", \"item_id:token\"]):\n",
    "    for column_name in column_name_list:\n",
    "        df[column_name] = df[column_name].str.split(\"_\")\n",
    "        df[column_name] = df[column_name].apply(lambda x: x[0])\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9q/p0b6nwnd5071040x3849mdvc0000gn/T/ipykernel_66772/2072793301.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[column_name] = df[column_name].str.split(\"_\")\n",
      "/var/folders/9q/p0b6nwnd5071040x3849mdvc0000gn/T/ipykernel_66772/2072793301.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[column_name] = df[column_name].apply(lambda x: x[0])\n"
     ]
    }
   ],
   "source": [
    "poi_df_sample_capri = user_id_cleaner(poi_df_sample_capri, [\"item_id:token\"])\n",
    "train_df = user_id_cleaner(train_df)\n",
    "val_df = user_id_cleaner(val_df)\n",
    "test_df = user_id_cleaner(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved as checkins.txt\n",
      "Data saved as dataSize.txt\n",
      "Data saved as poiCoos.txt\n",
      "Data saved as train.txt\n",
      "Data saved as tune.txt\n",
      "Data saved as test.txt\n"
     ]
    }
   ],
   "source": [
    "datasaver_capri(checkin_df_timestamp, \"checkins\")\n",
    "datasaver_capri(datasize_capri, \"dataSize\")\n",
    "datasaver_capri(poi_df_sample_capri, \"poiCoos\")\n",
    "datasaver_capri(train_df, \"train\")\n",
    "datasaver_capri(val_df, \"tune\")\n",
    "datasaver_capri(test_df, \"test\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prep_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
