{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "from globals import BASE_DIR\n",
    "\n",
    "include_categories = True\n",
    "\n",
    "dataset = \"yelp\"\n",
    "\n",
    "DATASET_DIR = f\"{BASE_DIR}{dataset}_dataset/\"\n",
    "#DATASET_DIR = f\"/Users/andreaforster/Documents/data_thesis/{dataset}_dataset/\"\n",
    "\n",
    "\n",
    "available_datasets = [\"foursquaretky\", \"yelp\", \"gowalla\", \"brightkite\", \"snowcard\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_big_json(file_path):\n",
    "    data = []\n",
    "\n",
    "    # Open the file and read it line by line\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            # Parse the JSON data and append to the list\n",
    "            data.append(json.loads(line))\n",
    "\n",
    "    # Create a DataFrame from the list of records\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_unix_timestamp(df, column_name):\n",
    "    \"\"\"\n",
    "    Convert a column of timestamps in a DataFrame to Unix timestamps.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The DataFrame containing the timestamp column.\n",
    "        column_name (str): The name of the column with timestamps in \"%Y-%m-%d %H:%M:%S\" format.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The DataFrame with an additional column for Unix timestamps.\n",
    "    \"\"\"\n",
    "    # Convert the column to datetime objects\n",
    "    df[column_name] = pd.to_datetime(df[column_name], format=\"mixed\")\n",
    "    \n",
    "    # Convert datetime objects to Unix timestamps\n",
    "    df[f'{column_name}'] = df[column_name].apply(lambda x: x.timestamp())\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dataset == \"snowcard\":\n",
    "    checkin_df = pd.read_csv(DATASET_DIR+\"TSC_EEL_EXPORT.csv\", encoding=\"latin1\", sep=\";\", header=None, names=[\"timestamp:float\", \"user_id:token\", \"category_id:token\", \"category_name:token_seq\", \"name:token_seq\", \"user_type:token_seq\"])\n",
    "    checkin_df[\"item_id:token\"], item_id = pd.factorize(checkin_df[\"name:token_seq\"])\n",
    "    user_df = checkin_df[[\"user_id:token\", \"user_type:token_seq\"]].drop_duplicates(subset=[\"user_id:token\"])\n",
    "    poi_df = checkin_df[[\"item_id:token\", \"name:token_seq\", \"category_id:token\", \"category_name:token_seq\"]].drop_duplicates(subset=[\"item_id:token\"])\n",
    "    coordinates_df = pd.read_excel(DATASET_DIR+\"snowcard_lifts.xlsx\")\n",
    "    coordinates_df[[\"lat:float\", \"lon:float\"]] = coordinates_df[\"lat_lon\"].str.split(', ', expand=True)\n",
    "    coordinates_df.drop(columns=[\"lat_lon\"], inplace=True)\n",
    "    poi_df = pd.merge(poi_df, coordinates_df[['category_name:token_seq', 'lat:float', 'lon:float']], on='category_name:token_seq', how='left')\n",
    "    checkin_df = checkin_df[[\"user_id:token\", \"item_id:token\", \"timestamp:float\"]]\n",
    "\n",
    "elif dataset == \"foursquarenyc\" or dataset == \"foursquaretky\":\n",
    "    checkin_df = pd.read_csv(DATASET_DIR + \"foursquare_data.csv\", sep=\",\")\n",
    "    checkin_df = checkin_df.drop(columns=[\"timezoneOffset\"])\n",
    "    checkin_df = checkin_df.rename(columns={\"venueId\": \"item_id:token\", \"venueCategoryId\": \"category_id:token\", \"venueCategory\": \"category_name:token_seq\", \"userId\": \"user_id:token\", \"utcTimestamp\": \"timestamp:float\", \"latitude\": \"lat:float\", \"longitude\": \"lon:float\"})\n",
    "    user_df = checkin_df[[\"user_id:token\"]].drop_duplicates()\n",
    "\n",
    "    poi_df = checkin_df[[\"item_id:token\", \"category_id:token\", \"category_name:token_seq\", \"lat:float\", \"lon:float\"]].drop_duplicates(subset=[\"item_id:token\"])\n",
    "    checkin_df = checkin_df[[\"user_id:token\", \"item_id:token\", \"timestamp:float\"]]\n",
    "\n",
    "elif dataset == \"gowalla\" or dataset == \"brightkite\":\n",
    "    checkin_df = pd.read_csv(DATASET_DIR + f\"loc-{dataset}_totalCheckins.txt\", sep=\"\\t\", header=None, names=['user_id:token', 'timestamp:float', 'lat:float', 'lon:float', 'item_id:token'])\n",
    "    checkin_df = checkin_df[~checkin_df['item_id:token'].isin([\"00000000000000000000000000000000\", \"ede07eeea22411dda0ef53e233ec57ca\"])]\n",
    "    user_df = pd.read_csv(DATASET_DIR + f\"loc-{dataset}_edges.txt\", sep=\"\\t\", header=None, names=['user_id:token', 'friends:token_seq'])\n",
    "    user_df = user_df.groupby('user_id:token')['friends:token_seq'].apply(lambda x: ','.join(map(str, x))).reset_index()\n",
    "    user_df.columns = ['user_id:token', 'friends:token_seq']\n",
    "    poi_df = checkin_df[['item_id:token', \"lat:float\", \"lon:float\"]].drop_duplicates(subset=\"item_id:token\")\n",
    "    checkin_df = checkin_df.drop(columns=[\"lat:float\", \"lon:float\"])\n",
    "\n",
    "elif dataset == \"yelp\":\n",
    "    poi_df = pd.read_json(DATASET_DIR + \"yelp_academic_dataset_business.json\", lines=True)\n",
    "    poi_df = poi_df.loc[poi_df['is_open'] == 1]\n",
    "    poi_df = poi_df.drop(columns=[\"review_count\", \"stars\", \"hours\", \"is_open\", \"city\", \"state\", \"postal_code\", \"attributes\", \"address\"])\n",
    "    poi_df = poi_df.rename(columns={\"latitude\": \"lat:float\", \"longitude\": \"lon:float\", \"business_id\": \"item_id:token\", \"name\":\"name:token_seq\", \"categories\":\"category_name:token_seq\"})\n",
    "    user_df = open_big_json(DATASET_DIR + \"yelp_academic_dataset_user.json\")\n",
    "    user_df = user_df.drop(columns=[\"review_count\", \"name\", \"yelping_since\", \"useful\", \"funny\", \"cool\", \"elite\", \"fans\", \"compliment_hot\", \"average_stars\", \"compliment_more\", \"compliment_profile\", \"compliment_cute\", \"compliment_list\", \"compliment_note\", \"compliment_plain\", \"compliment_cool\", \"compliment_funny\", \"compliment_writer\", \"compliment_photos\"])\n",
    "    user_df = user_df.rename(columns={\"user_id\": \"user_id:token\", \"friends\": \"friends:token_seq\"})\n",
    "    checkin_df = open_big_json(DATASET_DIR + \"yelp_academic_dataset_review.json\")\n",
    "    checkin_df = checkin_df.drop(columns=[\"text\", \"cool\", \"stars\", \"useful\", \"funny\", \"review_id\"])\n",
    "    checkin_df = checkin_df.rename(columns={\"user_id\": \"user_id:token\", \"business_id\": \"item_id:token\", \"date\": \"timestamp:float\"})\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkin_df.sort_values(by=\"timestamp:float\", ascending=True, inplace=True)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id:token</th>\n",
       "      <th>name:token_seq</th>\n",
       "      <th>lat:float</th>\n",
       "      <th>lon:float</th>\n",
       "      <th>category_name:token_seq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mpf3x-BjTdTEA3yCZrAYPw</td>\n",
       "      <td>The UPS Store</td>\n",
       "      <td>38.551126</td>\n",
       "      <td>-90.335695</td>\n",
       "      <td>Shipping Centers, Local Services, Notaries, Ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MTSW4McQd7CbVtyjqoe9mw</td>\n",
       "      <td>St Honore Pastries</td>\n",
       "      <td>39.955505</td>\n",
       "      <td>-75.155564</td>\n",
       "      <td>Restaurants, Food, Bubble Tea, Coffee &amp; Tea, B...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mWMc6_wTdE0EUBKIGXDVfA</td>\n",
       "      <td>Perkiomen Valley Brewery</td>\n",
       "      <td>40.338183</td>\n",
       "      <td>-75.471659</td>\n",
       "      <td>Brewpubs, Breweries, Food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CF33F8-E6oudUQ46HnavjQ</td>\n",
       "      <td>Sonic Drive-In</td>\n",
       "      <td>36.269593</td>\n",
       "      <td>-87.058943</td>\n",
       "      <td>Burgers, Fast Food, Sandwiches, Food, Ice Crea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>n_0UpQx1hsNbnPUSlodU8w</td>\n",
       "      <td>Famous Footwear</td>\n",
       "      <td>38.627695</td>\n",
       "      <td>-90.340465</td>\n",
       "      <td>Sporting Goods, Fashion, Shoe Stores, Shopping...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150341</th>\n",
       "      <td>IUQopTMmYQG-qRtBk-8QnA</td>\n",
       "      <td>Binh's Nails</td>\n",
       "      <td>53.468419</td>\n",
       "      <td>-113.492054</td>\n",
       "      <td>Nail Salons, Beauty &amp; Spas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150342</th>\n",
       "      <td>c8GjPIOTGVmIemT7j5_SyQ</td>\n",
       "      <td>Wild Birds Unlimited</td>\n",
       "      <td>36.115118</td>\n",
       "      <td>-86.766925</td>\n",
       "      <td>Pets, Nurseries &amp; Gardening, Pet Stores, Hobby...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150343</th>\n",
       "      <td>_QAMST-NrQobXduilWEqSw</td>\n",
       "      <td>Claire's Boutique</td>\n",
       "      <td>39.908707</td>\n",
       "      <td>-86.065088</td>\n",
       "      <td>Shopping, Jewelry, Piercing, Toy Stores, Beaut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150344</th>\n",
       "      <td>mtGm22y5c2UHNXDFAjaPNw</td>\n",
       "      <td>Cyclery &amp; Fitness Center</td>\n",
       "      <td>38.782351</td>\n",
       "      <td>-89.950558</td>\n",
       "      <td>Fitness/Exercise Equipment, Eyewear &amp; Optician...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150345</th>\n",
       "      <td>jV_XOycEzSlTx-65W906pg</td>\n",
       "      <td>Sic Ink</td>\n",
       "      <td>27.771002</td>\n",
       "      <td>-82.394910</td>\n",
       "      <td>Beauty &amp; Spas, Permanent Makeup, Piercing, Tattoo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>119698 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 item_id:token            name:token_seq  lat:float  \\\n",
       "1       mpf3x-BjTdTEA3yCZrAYPw             The UPS Store  38.551126   \n",
       "3       MTSW4McQd7CbVtyjqoe9mw        St Honore Pastries  39.955505   \n",
       "4       mWMc6_wTdE0EUBKIGXDVfA  Perkiomen Valley Brewery  40.338183   \n",
       "5       CF33F8-E6oudUQ46HnavjQ            Sonic Drive-In  36.269593   \n",
       "6       n_0UpQx1hsNbnPUSlodU8w           Famous Footwear  38.627695   \n",
       "...                        ...                       ...        ...   \n",
       "150341  IUQopTMmYQG-qRtBk-8QnA              Binh's Nails  53.468419   \n",
       "150342  c8GjPIOTGVmIemT7j5_SyQ      Wild Birds Unlimited  36.115118   \n",
       "150343  _QAMST-NrQobXduilWEqSw         Claire's Boutique  39.908707   \n",
       "150344  mtGm22y5c2UHNXDFAjaPNw  Cyclery & Fitness Center  38.782351   \n",
       "150345  jV_XOycEzSlTx-65W906pg                   Sic Ink  27.771002   \n",
       "\n",
       "         lon:float                            category_name:token_seq  \n",
       "1       -90.335695  Shipping Centers, Local Services, Notaries, Ma...  \n",
       "3       -75.155564  Restaurants, Food, Bubble Tea, Coffee & Tea, B...  \n",
       "4       -75.471659                          Brewpubs, Breweries, Food  \n",
       "5       -87.058943  Burgers, Fast Food, Sandwiches, Food, Ice Crea...  \n",
       "6       -90.340465  Sporting Goods, Fashion, Shoe Stores, Shopping...  \n",
       "...            ...                                                ...  \n",
       "150341 -113.492054                         Nail Salons, Beauty & Spas  \n",
       "150342  -86.766925  Pets, Nurseries & Gardening, Pet Stores, Hobby...  \n",
       "150343  -86.065088  Shopping, Jewelry, Piercing, Toy Stores, Beaut...  \n",
       "150344  -89.950558  Fitness/Exercise Equipment, Eyewear & Optician...  \n",
       "150345  -82.394910  Beauty & Spas, Permanent Makeup, Piercing, Tattoo  \n",
       "\n",
       "[119698 rows x 5 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poi_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id:token</th>\n",
       "      <th>friends:token_seq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>qVc8ODYU5SZjKXVBgXdI7w</td>\n",
       "      <td>NSCy54eWehBJyZdG2iE84w, pe42u7DcCH2QmI81NX-8qA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>j14WgRoU_-2ZE1aw1dXrJg</td>\n",
       "      <td>ueRPE0CX75ePGMqOFVj6IQ, 52oH4DrRvzzl8wh5UXyU0A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2WnXYQFK0hXEoTxPtV2zvg</td>\n",
       "      <td>LuO3Bn4f3rlhyHIaNfTlnA, j9B4XdHUhDfTKVecyWQgyA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SZDeASXq7o05mMNLshsdIA</td>\n",
       "      <td>enx1vVPnfdNUdPho6PH_wg, 4wOcvMLtU6a9Lslggq74Vg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hA5lMy-EnncsH4JoR-hFGQ</td>\n",
       "      <td>PBK4q9KEEBHhFvSXCUirIw, 3FWPpM7KU1gXeOM_ZbYMbA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1987892</th>\n",
       "      <td>fB3jbHi3m0L2KgGOxBv6uw</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1987893</th>\n",
       "      <td>68czcr4BxJyMQ9cJBm6C7Q</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1987894</th>\n",
       "      <td>1x3KMskYxOuJCjRz70xOqQ</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1987895</th>\n",
       "      <td>ulfGl4tdbrH05xKzh5lnog</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1987896</th>\n",
       "      <td>wL5jPrLRVCK_Pmo4lM1zpA</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1987897 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  user_id:token  \\\n",
       "0        qVc8ODYU5SZjKXVBgXdI7w   \n",
       "1        j14WgRoU_-2ZE1aw1dXrJg   \n",
       "2        2WnXYQFK0hXEoTxPtV2zvg   \n",
       "3        SZDeASXq7o05mMNLshsdIA   \n",
       "4        hA5lMy-EnncsH4JoR-hFGQ   \n",
       "...                         ...   \n",
       "1987892  fB3jbHi3m0L2KgGOxBv6uw   \n",
       "1987893  68czcr4BxJyMQ9cJBm6C7Q   \n",
       "1987894  1x3KMskYxOuJCjRz70xOqQ   \n",
       "1987895  ulfGl4tdbrH05xKzh5lnog   \n",
       "1987896  wL5jPrLRVCK_Pmo4lM1zpA   \n",
       "\n",
       "                                         friends:token_seq  \n",
       "0        NSCy54eWehBJyZdG2iE84w, pe42u7DcCH2QmI81NX-8qA...  \n",
       "1        ueRPE0CX75ePGMqOFVj6IQ, 52oH4DrRvzzl8wh5UXyU0A...  \n",
       "2        LuO3Bn4f3rlhyHIaNfTlnA, j9B4XdHUhDfTKVecyWQgyA...  \n",
       "3        enx1vVPnfdNUdPho6PH_wg, 4wOcvMLtU6a9Lslggq74Vg...  \n",
       "4        PBK4q9KEEBHhFvSXCUirIw, 3FWPpM7KU1gXeOM_ZbYMbA...  \n",
       "...                                                    ...  \n",
       "1987892                                               None  \n",
       "1987893                                               None  \n",
       "1987894                                               None  \n",
       "1987895                                               None  \n",
       "1987896                                               None  \n",
       "\n",
       "[1987897 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id:token</th>\n",
       "      <th>item_id:token</th>\n",
       "      <th>timestamp:float</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4179799</th>\n",
       "      <td>3zBJUlWtPNoZ0uN83ODbyg</td>\n",
       "      <td>2bXm0SynOfxDzfrdrCyXqg</td>\n",
       "      <td>2005-02-16 03:23:22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6295220</th>\n",
       "      <td>3zBJUlWtPNoZ0uN83ODbyg</td>\n",
       "      <td>3g6XqkBikTTbZmTukbeGnw</td>\n",
       "      <td>2005-02-16 03:29:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4887456</th>\n",
       "      <td>3zBJUlWtPNoZ0uN83ODbyg</td>\n",
       "      <td>PP3BBaVxZLcJU54uP_wL6Q</td>\n",
       "      <td>2005-02-16 04:06:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1423159</th>\n",
       "      <td>XCsZ3hWa_6oP1WkWvK7pmg</td>\n",
       "      <td>U3grYFIeu6RgAAQgdriHww</td>\n",
       "      <td>2005-03-01 16:57:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4884223</th>\n",
       "      <td>XCsZ3hWa_6oP1WkWvK7pmg</td>\n",
       "      <td>Aes-0Q_guDeYewMapFs_vg</td>\n",
       "      <td>2005-03-01 16:59:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4878781</th>\n",
       "      <td>lmiiFd9KC15fs4xtEoXRvw</td>\n",
       "      <td>XDMno4l95AXgYOd0yDtHZA</td>\n",
       "      <td>2022-01-19 19:48:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2710116</th>\n",
       "      <td>2Mb0st9WVyccaz6sKNLHWw</td>\n",
       "      <td>M88FFZZ2o_7QKpCFA_8RtA</td>\n",
       "      <td>2022-01-19 19:48:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6251618</th>\n",
       "      <td>3TQKP7KlNRdrI2gOkG7slg</td>\n",
       "      <td>jVg-KTXEFIeAq47DTp4Hrw</td>\n",
       "      <td>2022-01-19 19:48:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5476035</th>\n",
       "      <td>i1PMqye40QWNkJ0MYGHuzg</td>\n",
       "      <td>J0joPXxmN-_9Lzafspqdbw</td>\n",
       "      <td>2022-01-19 19:48:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4863327</th>\n",
       "      <td>IH0ToaZ8hJXO2pVieN7dpQ</td>\n",
       "      <td>VItkA7pL82rCZdxHH8vBGA</td>\n",
       "      <td>2022-01-19 19:48:45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6990280 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  user_id:token           item_id:token      timestamp:float\n",
       "4179799  3zBJUlWtPNoZ0uN83ODbyg  2bXm0SynOfxDzfrdrCyXqg  2005-02-16 03:23:22\n",
       "6295220  3zBJUlWtPNoZ0uN83ODbyg  3g6XqkBikTTbZmTukbeGnw  2005-02-16 03:29:39\n",
       "4887456  3zBJUlWtPNoZ0uN83ODbyg  PP3BBaVxZLcJU54uP_wL6Q  2005-02-16 04:06:26\n",
       "1423159  XCsZ3hWa_6oP1WkWvK7pmg  U3grYFIeu6RgAAQgdriHww  2005-03-01 16:57:17\n",
       "4884223  XCsZ3hWa_6oP1WkWvK7pmg  Aes-0Q_guDeYewMapFs_vg  2005-03-01 16:59:37\n",
       "...                         ...                     ...                  ...\n",
       "4878781  lmiiFd9KC15fs4xtEoXRvw  XDMno4l95AXgYOd0yDtHZA  2022-01-19 19:48:13\n",
       "2710116  2Mb0st9WVyccaz6sKNLHWw  M88FFZZ2o_7QKpCFA_8RtA  2022-01-19 19:48:16\n",
       "6251618  3TQKP7KlNRdrI2gOkG7slg  jVg-KTXEFIeAq47DTp4Hrw  2022-01-19 19:48:19\n",
       "5476035  i1PMqye40QWNkJ0MYGHuzg  J0joPXxmN-_9Lzafspqdbw  2022-01-19 19:48:25\n",
       "4863327  IH0ToaZ8hJXO2pVieN7dpQ  VItkA7pL82rCZdxHH8vBGA  2022-01-19 19:48:45\n",
       "\n",
       "[6990280 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkin_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# checkin_df['timestamp'] = pd.to_datetime(checkin_df['timestamp:float'], errors='coerce')\n",
    "\n",
    "# # Extract the year from the 'timestamp' column\n",
    "# checkin_df['year'] = checkin_df['timestamp'].dt.year\n",
    "\n",
    "# # Plot the histogram\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# checkin_df['year'].dropna().astype(int).hist(bins=range(int(checkin_df['year'].min()), int(checkin_df['year'].max()) + 1), edgecolor='black')\n",
    "# plt.title('Histogram of Check-ins by Year')\n",
    "# plt.xlabel('Year')\n",
    "# plt.ylabel('Number of Check-ins')\n",
    "# plt.grid(False)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dataset == \"yelp\":\n",
    "    checkin_df['timestamp'] = pd.to_datetime(checkin_df['timestamp:float'], errors='coerce')\n",
    "\n",
    "    # Extract the year from the 'timestamp' column\n",
    "    checkin_df['year'] = checkin_df['timestamp'].dt.year\n",
    "    checkin_df = checkin_df[checkin_df['year'] >= 2018]\n",
    "    checkin_df = checkin_df[checkin_df['year'] < 2020]\n",
    "    checkin_df.drop(columns=[\"year\", \"timestamp\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id:token</th>\n",
       "      <th>item_id:token</th>\n",
       "      <th>timestamp:float</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6664443</th>\n",
       "      <td>vYPvl2ngX8UdDB8Pf0JCPA</td>\n",
       "      <td>THJ0i8yRyx1OfvzLsJXgng</td>\n",
       "      <td>2018-01-01 00:00:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2542113</th>\n",
       "      <td>PcgyHvdduilIJ-O-z_05Sw</td>\n",
       "      <td>HhZDu-IEC7owaHCeEXSf1g</td>\n",
       "      <td>2018-01-01 00:00:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4742901</th>\n",
       "      <td>SsL2nYQGx-l_MVOKoJExJw</td>\n",
       "      <td>D8UM3J3mx2cyYPy84yU9ag</td>\n",
       "      <td>2018-01-01 00:00:52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4240067</th>\n",
       "      <td>1T-Y8oA4Frv3eRmGO3ciew</td>\n",
       "      <td>Sf9E4E8yo8actSXHFvrZbQ</td>\n",
       "      <td>2018-01-01 00:02:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4947842</th>\n",
       "      <td>unekdBHjTsiBVtOX5UwbZg</td>\n",
       "      <td>rDr7zhYBOmC3NzJXcZd1BQ</td>\n",
       "      <td>2018-01-01 00:02:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2636555</th>\n",
       "      <td>Yy5uYBI7PH5fVtfQjYI76Q</td>\n",
       "      <td>l4uH-6afJzbm0NFRp7lKog</td>\n",
       "      <td>2019-12-31 23:58:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2677248</th>\n",
       "      <td>IlGYj_XAMG3v75rfmtBs_Q</td>\n",
       "      <td>EagkHaaC-kUozD3MPzbRIw</td>\n",
       "      <td>2019-12-31 23:58:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1252247</th>\n",
       "      <td>FhBHx01UWFh3_R_sphucMA</td>\n",
       "      <td>gWJSE8CNWsHS_sUG_sVoRw</td>\n",
       "      <td>2019-12-31 23:58:52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2728567</th>\n",
       "      <td>U4iKsl_nFscRfNDxNvdZ8Q</td>\n",
       "      <td>xG9oeXDZldT5_CZLLzABsw</td>\n",
       "      <td>2019-12-31 23:59:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6749016</th>\n",
       "      <td>QRVbQqLnx2hjypOMFGAuTA</td>\n",
       "      <td>oWZklx8pWXVx8Fcp67th4w</td>\n",
       "      <td>2019-12-31 23:59:55</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1813646 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  user_id:token           item_id:token      timestamp:float\n",
       "6664443  vYPvl2ngX8UdDB8Pf0JCPA  THJ0i8yRyx1OfvzLsJXgng  2018-01-01 00:00:11\n",
       "2542113  PcgyHvdduilIJ-O-z_05Sw  HhZDu-IEC7owaHCeEXSf1g  2018-01-01 00:00:28\n",
       "4742901  SsL2nYQGx-l_MVOKoJExJw  D8UM3J3mx2cyYPy84yU9ag  2018-01-01 00:00:52\n",
       "4240067  1T-Y8oA4Frv3eRmGO3ciew  Sf9E4E8yo8actSXHFvrZbQ  2018-01-01 00:02:05\n",
       "4947842  unekdBHjTsiBVtOX5UwbZg  rDr7zhYBOmC3NzJXcZd1BQ  2018-01-01 00:02:12\n",
       "...                         ...                     ...                  ...\n",
       "2636555  Yy5uYBI7PH5fVtfQjYI76Q  l4uH-6afJzbm0NFRp7lKog  2019-12-31 23:58:17\n",
       "2677248  IlGYj_XAMG3v75rfmtBs_Q  EagkHaaC-kUozD3MPzbRIw  2019-12-31 23:58:18\n",
       "1252247  FhBHx01UWFh3_R_sphucMA  gWJSE8CNWsHS_sUG_sVoRw  2019-12-31 23:58:52\n",
       "2728567  U4iKsl_nFscRfNDxNvdZ8Q  xG9oeXDZldT5_CZLLzABsw  2019-12-31 23:59:11\n",
       "6749016  QRVbQqLnx2hjypOMFGAuTA  oWZklx8pWXVx8Fcp67th4w  2019-12-31 23:59:55\n",
       "\n",
       "[1813646 rows x 3 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkin_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkin_df_timestamp = checkin_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 1: Group by user_id and business_id and count check-ins\n",
    "checkin_df['checkin_count:float'] = checkin_df.groupby(['user_id:token', 'item_id:token'])['item_id:token'].transform('count')\n",
    "checkin_df = checkin_df.drop_duplicates(subset=[\"user_id:token\", \"item_id:token\"], keep=\"first\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of users, number of POIs 747847 119726\n",
      "Sparsity: 0.9999802560021843\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of users, number of POIs\", len(checkin_df[\"user_id:token\"].unique()), len(checkin_df[\"item_id:token\"].unique())\n",
    ")\n",
    "print(\"Sparsity:\", 1 - len(checkin_df) / (len(checkin_df[\"user_id:token\"].unique()) * len(checkin_df[\"item_id:token\"].unique())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_df(df, min_reviews_user=15, min_reviews_business=10):\n",
    "    while True:\n",
    "\n",
    "        # Filter users with at least min_reviews reviews\n",
    "        user_counts = df['user_id:token'].value_counts()\n",
    "        user_mask = df['user_id:token'].map(user_counts) >= min_reviews_user\n",
    "        df_filtered = df.loc[user_mask]\n",
    "\n",
    "        # Filter businesses with at least min_reviews reviews\n",
    "        business_counts = df_filtered[\"item_id:token\"].value_counts()\n",
    "        business_mask = df_filtered['item_id:token'].map(business_counts) >= min_reviews_business\n",
    "        df_filtered = df_filtered.loc[business_mask]\n",
    "\n",
    "        \n",
    "\n",
    "        # If the size of the filtered DataFrame didn't change, break the loop\n",
    "        if df_filtered.shape[0] == df.shape[0]:\n",
    "            break\n",
    "\n",
    "        # Update the DataFrame for the next iteration\n",
    "        df = df_filtered\n",
    "\n",
    "    return df_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkin_df_filtered = filter_df(checkin_df, min_reviews_business=10, min_reviews_user=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkin_df_filtered[\"user_id:token\"].value_counts().min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4150"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkin_df_filtered[\"user_id:token\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4150, 5259)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkin_df_filtered[\"user_id:token\"].nunique(), checkin_df_filtered[\"item_id:token\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Calculate the value counts of `business_id`\n",
    "value_counts = checkin_df_filtered['item_id:token'].value_counts().reset_index()\n",
    "value_counts.columns = ['item_id:token', 'count']\n",
    "\n",
    "# Step 2: Normalize the counts y dividing by the maximum value count\n",
    "max_count = value_counts['count'].max()\n",
    "value_counts['business_popularity:float'] = value_counts['count'] / max_count\n",
    " \n",
    "# Step 3: Merge the normalized counts back into the original DataFrame\n",
    "checkin_df_filtered = checkin_df_filtered.merge(value_counts[['item_id:token', 'business_popularity:float']], on = \"item_id:token\", how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_popularity_sample_calculator(checkin_df_filtered, poi_df, user_df, sep_num, checkin_df_timestamp):\n",
    "    # Calculate average popularity per user\n",
    "    average_popularity_per_user = checkin_df_filtered.groupby('user_id:token')['business_popularity:float'].mean().reset_index()\n",
    "    average_popularity_per_user.columns = ['user_id:token', 'average_popularity']\n",
    "\n",
    "    average_popularity_per_user = average_popularity_per_user.sort_values(by=\"average_popularity\", ascending=False)\n",
    "\n",
    "    \n",
    "    # Sort by average popularity\n",
    "    \n",
    "\n",
    "    # Get top 1000 users\n",
    "    high_pop_user_df_sample = average_popularity_per_user.head(sep_num)\n",
    "    \n",
    "    # Get the middle 1000 users around the median\n",
    "    median_index = len(average_popularity_per_user) // 2\n",
    "    start_med_index = max(median_index -int (sep_num/2), 0)\n",
    "    end_med_index = min(median_index + int(sep_num/2), len(average_popularity_per_user))\n",
    "    med_pop_user_df_sample = average_popularity_per_user.iloc[start_med_index:end_med_index]\n",
    "    \n",
    "    # Get the lowest 1000 users\n",
    "    low_pop_user_df_sample = average_popularity_per_user.tail(sep_num)\n",
    "\n",
    "    unique_users = list(set(high_pop_user_df_sample[\"user_id:token\"].tolist() + med_pop_user_df_sample[\"user_id:token\"].tolist() + low_pop_user_df_sample[\"user_id:token\"].tolist()))\n",
    "\n",
    "    checkin_df_sample = checkin_df_filtered[checkin_df_filtered[\"user_id:token\"].isin(unique_users)]\n",
    "    checkin_df_sample = checkin_df_sample[checkin_df_sample[\"user_id:token\"].isin(unique_users)]\n",
    "\n",
    "    # unique_items = checkin_df_sample[\"item_id:token\"].unique()\n",
    "    # print(len(unique_items))\n",
    "\n",
    "    user_df_sample = user_df[user_df[\"user_id:token\"].isin(unique_users)]\n",
    "    poi_df_sample = poi_df[poi_df[\"item_id:token\"].isin(checkin_df_sample[\"item_id:token\"])]\n",
    "\n",
    "    checkin_df_sample = checkin_df_sample[checkin_df_sample[\"item_id:token\"].isin(poi_df_sample[\"item_id:token\"])]\n",
    "\n",
    "    checkin_df_timestamp = checkin_df_timestamp[checkin_df_timestamp[\"user_id:token\"].isin(unique_users)]\n",
    "    checkin_df_timestamp = checkin_df_timestamp[checkin_df_timestamp[\"item_id:token\"].isin(poi_df_sample[\"item_id:token\"])]\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    return checkin_df_sample, high_pop_user_df_sample, med_pop_user_df_sample, low_pop_user_df_sample, user_df_sample, poi_df_sample, checkin_df_timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n"
     ]
    }
   ],
   "source": [
    "if checkin_df_filtered[\"user_id:token\"].nunique() > 1500:\n",
    "    sep_num = 500\n",
    "else:\n",
    "    sep_num = checkin_df_filtered[\"user_id:token\"].nunique() // 3\n",
    "\n",
    "print(sep_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkin_df_sample, high_pop_user_df_sample, med_pop_user_df_sample, low_pop_user_df_sample, user_df_sample, poi_df_sample, checkin_df_timestamp = user_popularity_sample_calculator(checkin_df_filtered, poi_df, user_df, sep_num, checkin_df_timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4510"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkin_df_sample[\"item_id:token\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkin_df_sample[\"user_id:token\"].value_counts().min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkin_df_sample[\"item_id:token\"].value_counts().min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4510"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkin_df_timestamp[\"item_id:token\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def id_factorizer(checkin_df_sample, high_pop_user_df_sample, med_pop_user_df_sample, low_pop_user_df_sample, user_df_sample, poi_df_sample, checkin_df_timestamp):\n",
    "    \"\"\"Overwriting the actual ID with a factorized ID so that we can use the same ID both in RecBole and CAPRI\"\"\"\n",
    "    checkin_df_sample['user_id:token'], user_id_map = pd.factorize(checkin_df_sample['user_id:token'])\n",
    "    checkin_df_sample['item_id:token'], business_id_map = pd.factorize(checkin_df_sample['item_id:token'])\n",
    "\n",
    "    # Create mapping dictionaries\n",
    "    user_id_mapping = {original: i for i, original in enumerate(user_id_map)}\n",
    "    business_id_mapping = {original: j for j, original in enumerate(business_id_map)}\n",
    "\n",
    "    high_pop_user_df_sample['user_id:token'] = high_pop_user_df_sample['user_id:token'].map(user_id_mapping)\n",
    "    med_pop_user_df_sample['user_id:token'] = med_pop_user_df_sample['user_id:token'].map(user_id_mapping)\n",
    "    low_pop_user_df_sample['user_id:token'] = low_pop_user_df_sample['user_id:token'].map(user_id_mapping)\n",
    "\n",
    "    checkin_df_timestamp[\"user_id:token\"] = checkin_df_timestamp[\"user_id:token\"].map(user_id_mapping)\n",
    "    checkin_df_timestamp[\"item_id:token\"] = checkin_df_timestamp[\"item_id:token\"].map(business_id_mapping)\n",
    "\n",
    "    user_df_sample['user_id:token'] = user_df_sample['user_id:token'].map(user_id_mapping)\n",
    "    poi_df_sample['item_id:token'] = poi_df_sample['item_id:token'].map(business_id_mapping)\n",
    "\n",
    "\n",
    "    return checkin_df_sample, high_pop_user_df_sample, med_pop_user_df_sample, low_pop_user_df_sample, user_df_sample, poi_df_sample, checkin_df_timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9q/p0b6nwnd5071040x3849mdvc0000gn/T/ipykernel_58945/4057195747.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  user_df_sample['user_id:token'] = user_df_sample['user_id:token'].map(user_id_mapping)\n",
      "/var/folders/9q/p0b6nwnd5071040x3849mdvc0000gn/T/ipykernel_58945/4057195747.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  poi_df_sample['item_id:token'] = poi_df_sample['item_id:token'].map(business_id_mapping)\n"
     ]
    }
   ],
   "source": [
    "checkin_df_sample, high_pop_user_df_sample, med_pop_user_df_sample, low_pop_user_df_sample, user_df_sample, poi_df_sample, checkin_df_timestamp = id_factorizer(checkin_df_sample, high_pop_user_df_sample, med_pop_user_df_sample, low_pop_user_df_sample, user_df_sample, poi_df_sample, checkin_df_timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1500"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkin_df_sample[\"user_id:token\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id:token</th>\n",
       "      <th>item_id:token</th>\n",
       "      <th>timestamp:float</th>\n",
       "      <th>checkin_count:float</th>\n",
       "      <th>business_popularity:float</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Fri Apr 06 12:52:34 +0000 2012</td>\n",
       "      <td>2</td>\n",
       "      <td>0.061404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Fri Apr 06 12:52:35 +0000 2012</td>\n",
       "      <td>1</td>\n",
       "      <td>0.026316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Fri Apr 06 12:52:49 +0000 2012</td>\n",
       "      <td>33</td>\n",
       "      <td>0.031100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Fri Apr 06 12:53:38 +0000 2012</td>\n",
       "      <td>52</td>\n",
       "      <td>0.039872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>Fri Apr 06 12:54:35 +0000 2012</td>\n",
       "      <td>11</td>\n",
       "      <td>0.009569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99680</th>\n",
       "      <td>190</td>\n",
       "      <td>1021</td>\n",
       "      <td>Wed Sep 05 23:15:07 +0000 2012</td>\n",
       "      <td>1</td>\n",
       "      <td>0.012759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99681</th>\n",
       "      <td>126</td>\n",
       "      <td>1877</td>\n",
       "      <td>Wed Sep 05 23:28:47 +0000 2012</td>\n",
       "      <td>1</td>\n",
       "      <td>0.015152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99682</th>\n",
       "      <td>1364</td>\n",
       "      <td>1051</td>\n",
       "      <td>Wed Sep 05 23:30:16 +0000 2012</td>\n",
       "      <td>2</td>\n",
       "      <td>0.018341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99683</th>\n",
       "      <td>100</td>\n",
       "      <td>471</td>\n",
       "      <td>Wed Sep 05 23:32:06 +0000 2012</td>\n",
       "      <td>1</td>\n",
       "      <td>0.028708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99684</th>\n",
       "      <td>734</td>\n",
       "      <td>2196</td>\n",
       "      <td>Wed Sep 05 23:42:32 +0000 2012</td>\n",
       "      <td>1</td>\n",
       "      <td>0.010367</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>67526 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       user_id:token  item_id:token                 timestamp:float  \\\n",
       "1                  0              0  Fri Apr 06 12:52:34 +0000 2012   \n",
       "2                  1              1  Fri Apr 06 12:52:35 +0000 2012   \n",
       "3                  2              2  Fri Apr 06 12:52:49 +0000 2012   \n",
       "4                  3              3  Fri Apr 06 12:53:38 +0000 2012   \n",
       "5                  4              4  Fri Apr 06 12:54:35 +0000 2012   \n",
       "...              ...            ...                             ...   \n",
       "99680            190           1021  Wed Sep 05 23:15:07 +0000 2012   \n",
       "99681            126           1877  Wed Sep 05 23:28:47 +0000 2012   \n",
       "99682           1364           1051  Wed Sep 05 23:30:16 +0000 2012   \n",
       "99683            100            471  Wed Sep 05 23:32:06 +0000 2012   \n",
       "99684            734           2196  Wed Sep 05 23:42:32 +0000 2012   \n",
       "\n",
       "       checkin_count:float  business_popularity:float  \n",
       "1                        2                   0.061404  \n",
       "2                        1                   0.026316  \n",
       "3                       33                   0.031100  \n",
       "4                       52                   0.039872  \n",
       "5                       11                   0.009569  \n",
       "...                    ...                        ...  \n",
       "99680                    1                   0.012759  \n",
       "99681                    1                   0.015152  \n",
       "99682                    2                   0.018341  \n",
       "99683                    1                   0.028708  \n",
       "99684                    1                   0.010367  \n",
       "\n",
       "[67526 rows x 5 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkin_df_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_id_token_adder(df, column_name_list = [\"user_id:token\", \"item_id:token\"]):\n",
    "    \"\"\" Recbole needs a token instead of a number for the user and item ID\"\"\"\n",
    "    for column_name in column_name_list:\n",
    "        try:\n",
    "            df[column_name] = df[column_name].astype(str) + \"_x\"\n",
    "        except KeyError:\n",
    "            pass\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9q/p0b6nwnd5071040x3849mdvc0000gn/T/ipykernel_58945/1404554777.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[column_name] = df[column_name].astype(str) + \"_x\"\n",
      "/var/folders/9q/p0b6nwnd5071040x3849mdvc0000gn/T/ipykernel_58945/1404554777.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[column_name] = df[column_name].astype(str) + \"_x\"\n"
     ]
    }
   ],
   "source": [
    "checkin_df_sample = user_id_token_adder(checkin_df_sample)\n",
    "high_pop_user_df_sample = user_id_token_adder(high_pop_user_df_sample)\n",
    "med_pop_user_df_sample = user_id_token_adder(med_pop_user_df_sample)\n",
    "low_pop_user_df_sample = user_id_token_adder(low_pop_user_df_sample)\n",
    "user_df_sample = user_id_token_adder(user_df_sample)\n",
    "poi_df_sample = user_id_token_adder(poi_df_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id:token</th>\n",
       "      <th>item_id:token</th>\n",
       "      <th>timestamp:float</th>\n",
       "      <th>checkin_count:float</th>\n",
       "      <th>business_popularity:float</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0_x</td>\n",
       "      <td>0_x</td>\n",
       "      <td>Fri Apr 06 12:52:34 +0000 2012</td>\n",
       "      <td>2</td>\n",
       "      <td>0.061404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1_x</td>\n",
       "      <td>1_x</td>\n",
       "      <td>Fri Apr 06 12:52:35 +0000 2012</td>\n",
       "      <td>1</td>\n",
       "      <td>0.026316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2_x</td>\n",
       "      <td>2_x</td>\n",
       "      <td>Fri Apr 06 12:52:49 +0000 2012</td>\n",
       "      <td>33</td>\n",
       "      <td>0.031100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3_x</td>\n",
       "      <td>3_x</td>\n",
       "      <td>Fri Apr 06 12:53:38 +0000 2012</td>\n",
       "      <td>52</td>\n",
       "      <td>0.039872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4_x</td>\n",
       "      <td>4_x</td>\n",
       "      <td>Fri Apr 06 12:54:35 +0000 2012</td>\n",
       "      <td>11</td>\n",
       "      <td>0.009569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99680</th>\n",
       "      <td>190_x</td>\n",
       "      <td>1021_x</td>\n",
       "      <td>Wed Sep 05 23:15:07 +0000 2012</td>\n",
       "      <td>1</td>\n",
       "      <td>0.012759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99681</th>\n",
       "      <td>126_x</td>\n",
       "      <td>1877_x</td>\n",
       "      <td>Wed Sep 05 23:28:47 +0000 2012</td>\n",
       "      <td>1</td>\n",
       "      <td>0.015152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99682</th>\n",
       "      <td>1364_x</td>\n",
       "      <td>1051_x</td>\n",
       "      <td>Wed Sep 05 23:30:16 +0000 2012</td>\n",
       "      <td>2</td>\n",
       "      <td>0.018341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99683</th>\n",
       "      <td>100_x</td>\n",
       "      <td>471_x</td>\n",
       "      <td>Wed Sep 05 23:32:06 +0000 2012</td>\n",
       "      <td>1</td>\n",
       "      <td>0.028708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99684</th>\n",
       "      <td>734_x</td>\n",
       "      <td>2196_x</td>\n",
       "      <td>Wed Sep 05 23:42:32 +0000 2012</td>\n",
       "      <td>1</td>\n",
       "      <td>0.010367</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>67526 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      user_id:token item_id:token                 timestamp:float  \\\n",
       "1               0_x           0_x  Fri Apr 06 12:52:34 +0000 2012   \n",
       "2               1_x           1_x  Fri Apr 06 12:52:35 +0000 2012   \n",
       "3               2_x           2_x  Fri Apr 06 12:52:49 +0000 2012   \n",
       "4               3_x           3_x  Fri Apr 06 12:53:38 +0000 2012   \n",
       "5               4_x           4_x  Fri Apr 06 12:54:35 +0000 2012   \n",
       "...             ...           ...                             ...   \n",
       "99680         190_x        1021_x  Wed Sep 05 23:15:07 +0000 2012   \n",
       "99681         126_x        1877_x  Wed Sep 05 23:28:47 +0000 2012   \n",
       "99682        1364_x        1051_x  Wed Sep 05 23:30:16 +0000 2012   \n",
       "99683         100_x         471_x  Wed Sep 05 23:32:06 +0000 2012   \n",
       "99684         734_x        2196_x  Wed Sep 05 23:42:32 +0000 2012   \n",
       "\n",
       "       checkin_count:float  business_popularity:float  \n",
       "1                        2                   0.061404  \n",
       "2                        1                   0.026316  \n",
       "3                       33                   0.031100  \n",
       "4                       52                   0.039872  \n",
       "5                       11                   0.009569  \n",
       "...                    ...                        ...  \n",
       "99680                    1                   0.012759  \n",
       "99681                    1                   0.015152  \n",
       "99682                    2                   0.018341  \n",
       "99683                    1                   0.028708  \n",
       "99684                    1                   0.010367  \n",
       "\n",
       "[67526 rows x 5 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkin_df_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id:token</th>\n",
       "      <th>average_popularity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2034</th>\n",
       "      <td>1129_x</td>\n",
       "      <td>0.142278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>803</th>\n",
       "      <td>1491_x</td>\n",
       "      <td>0.142158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>530_x</td>\n",
       "      <td>0.142158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1410</th>\n",
       "      <td>5_x</td>\n",
       "      <td>0.142045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021</th>\n",
       "      <td>1443_x</td>\n",
       "      <td>0.141976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>400_x</td>\n",
       "      <td>0.116345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1803</th>\n",
       "      <td>217_x</td>\n",
       "      <td>0.116162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516</th>\n",
       "      <td>625_x</td>\n",
       "      <td>0.116140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1404</th>\n",
       "      <td>1465_x</td>\n",
       "      <td>0.116065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>925_x</td>\n",
       "      <td>0.115789</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     user_id:token  average_popularity\n",
       "2034        1129_x            0.142278\n",
       "803         1491_x            0.142158\n",
       "416          530_x            0.142158\n",
       "1410           5_x            0.142045\n",
       "2021        1443_x            0.141976\n",
       "...            ...                 ...\n",
       "60           400_x            0.116345\n",
       "1803         217_x            0.116162\n",
       "516          625_x            0.116140\n",
       "1404        1465_x            0.116065\n",
       "174          925_x            0.115789\n",
       "\n",
       "[500 rows x 2 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "med_pop_user_df_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a json with the user id's of the respective popularity groups\n",
    "user_id_popularity = {}\n",
    "user_id_popularity[\"high\"] = high_pop_user_df_sample[\"user_id:token\"].tolist()\n",
    "user_id_popularity[\"medium\"] = med_pop_user_df_sample[\"user_id:token\"].tolist()\n",
    "user_id_popularity[\"low\"] = low_pop_user_df_sample[\"user_id:token\"].tolist()\n",
    "json.dump(user_id_popularity, open(f\"{DATASET_DIR}/{dataset}_user_id_popularity.json\", \"w\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_saver(df, filename, framework):\n",
    "    if not os.path.exists(DATASET_DIR + \"processed_data_\" + framework):\n",
    "        os.makedirs(DATASET_DIR + \"processed_data_\" + framework)\n",
    "    \n",
    "    df.to_csv(DATASET_DIR + \"processed_data_\" + framework + \"/\" + filename + \".csv\")\n",
    "    print(\"Data saved as \" + framework + filename + \".csv\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved as cornacuser_events.csv\n",
      "Data saved as cornachigh_pop_user_sample.csv\n",
      "Data saved as cornacmedium_pop_user_sample.csv\n",
      "Data saved as cornaclow_pop_user_sample.csv\n"
     ]
    }
   ],
   "source": [
    "# first of all saving data for cornac\n",
    "data_saver(checkin_df_sample, \"user_events\", \"cornac\")\n",
    "data_saver(high_pop_user_df_sample, \"high_pop_user_sample\", \"cornac\")\n",
    "data_saver(med_pop_user_df_sample, \"medium_pop_user_sample\", \"cornac\")\n",
    "data_saver(low_pop_user_df_sample, \"low_pop_user_sample\", \"cornac\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id:token</th>\n",
       "      <th>item_id:token</th>\n",
       "      <th>timestamp:float</th>\n",
       "      <th>checkin_count:float</th>\n",
       "      <th>business_popularity:float</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0_x</td>\n",
       "      <td>0_x</td>\n",
       "      <td>Fri Apr 06 12:52:34 +0000 2012</td>\n",
       "      <td>2</td>\n",
       "      <td>0.061404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1_x</td>\n",
       "      <td>1_x</td>\n",
       "      <td>Fri Apr 06 12:52:35 +0000 2012</td>\n",
       "      <td>1</td>\n",
       "      <td>0.026316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2_x</td>\n",
       "      <td>2_x</td>\n",
       "      <td>Fri Apr 06 12:52:49 +0000 2012</td>\n",
       "      <td>33</td>\n",
       "      <td>0.031100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3_x</td>\n",
       "      <td>3_x</td>\n",
       "      <td>Fri Apr 06 12:53:38 +0000 2012</td>\n",
       "      <td>52</td>\n",
       "      <td>0.039872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4_x</td>\n",
       "      <td>4_x</td>\n",
       "      <td>Fri Apr 06 12:54:35 +0000 2012</td>\n",
       "      <td>11</td>\n",
       "      <td>0.009569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99680</th>\n",
       "      <td>190_x</td>\n",
       "      <td>1021_x</td>\n",
       "      <td>Wed Sep 05 23:15:07 +0000 2012</td>\n",
       "      <td>1</td>\n",
       "      <td>0.012759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99681</th>\n",
       "      <td>126_x</td>\n",
       "      <td>1877_x</td>\n",
       "      <td>Wed Sep 05 23:28:47 +0000 2012</td>\n",
       "      <td>1</td>\n",
       "      <td>0.015152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99682</th>\n",
       "      <td>1364_x</td>\n",
       "      <td>1051_x</td>\n",
       "      <td>Wed Sep 05 23:30:16 +0000 2012</td>\n",
       "      <td>2</td>\n",
       "      <td>0.018341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99683</th>\n",
       "      <td>100_x</td>\n",
       "      <td>471_x</td>\n",
       "      <td>Wed Sep 05 23:32:06 +0000 2012</td>\n",
       "      <td>1</td>\n",
       "      <td>0.028708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99684</th>\n",
       "      <td>734_x</td>\n",
       "      <td>2196_x</td>\n",
       "      <td>Wed Sep 05 23:42:32 +0000 2012</td>\n",
       "      <td>1</td>\n",
       "      <td>0.010367</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>67526 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      user_id:token item_id:token                 timestamp:float  \\\n",
       "1               0_x           0_x  Fri Apr 06 12:52:34 +0000 2012   \n",
       "2               1_x           1_x  Fri Apr 06 12:52:35 +0000 2012   \n",
       "3               2_x           2_x  Fri Apr 06 12:52:49 +0000 2012   \n",
       "4               3_x           3_x  Fri Apr 06 12:53:38 +0000 2012   \n",
       "5               4_x           4_x  Fri Apr 06 12:54:35 +0000 2012   \n",
       "...             ...           ...                             ...   \n",
       "99680         190_x        1021_x  Wed Sep 05 23:15:07 +0000 2012   \n",
       "99681         126_x        1877_x  Wed Sep 05 23:28:47 +0000 2012   \n",
       "99682        1364_x        1051_x  Wed Sep 05 23:30:16 +0000 2012   \n",
       "99683         100_x         471_x  Wed Sep 05 23:32:06 +0000 2012   \n",
       "99684         734_x        2196_x  Wed Sep 05 23:42:32 +0000 2012   \n",
       "\n",
       "       checkin_count:float  business_popularity:float  \n",
       "1                        2                   0.061404  \n",
       "2                        1                   0.026316  \n",
       "3                       33                   0.031100  \n",
       "4                       52                   0.039872  \n",
       "5                       11                   0.009569  \n",
       "...                    ...                        ...  \n",
       "99680                    1                   0.012759  \n",
       "99681                    1                   0.015152  \n",
       "99682                    2                   0.018341  \n",
       "99683                    1                   0.028708  \n",
       "99684                    1                   0.010367  \n",
       "\n",
       "[67526 rows x 5 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkin_df_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_saver_recbole(df, framework, suffix):\n",
    "    \n",
    "    if not os.path.exists(DATASET_DIR + \"processed_data_\" + framework):\n",
    "        os.makedirs(DATASET_DIR + \"processed_data_\" + framework)\n",
    "\n",
    "    df.to_csv(f\"{DATASET_DIR}processed_data_{framework}/{dataset}_sample.{suffix}\", sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkin_df_sample['review_id:token'] = range(1, len(checkin_df_sample) + 1)\n",
    "# Step 1: Group by user_id and business_id and count check-ins\n",
    "#checkin_df_sample['checkin_count:float'] = checkin_df_sample.groupby(['user_id:token', 'item_id:token'])['item_id:token'].transform('count')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id:token</th>\n",
       "      <th>item_id:token</th>\n",
       "      <th>timestamp:float</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5689</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Fri Apr 06 12:52:34 +0000 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5690</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Fri Apr 06 12:52:35 +0000 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5692</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Fri Apr 06 12:52:49 +0000 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5693</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Fri Apr 06 12:53:38 +0000 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5694</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>Fri Apr 06 12:54:35 +0000 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331776</th>\n",
       "      <td>111</td>\n",
       "      <td>185</td>\n",
       "      <td>Wed Sep 05 23:55:47 +0000 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331782</th>\n",
       "      <td>379</td>\n",
       "      <td>88</td>\n",
       "      <td>Wed Sep 05 23:56:30 +0000 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331783</th>\n",
       "      <td>359</td>\n",
       "      <td>754</td>\n",
       "      <td>Wed Sep 05 23:57:37 +0000 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331784</th>\n",
       "      <td>403</td>\n",
       "      <td>148</td>\n",
       "      <td>Wed Sep 05 23:58:06 +0000 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331787</th>\n",
       "      <td>81</td>\n",
       "      <td>97</td>\n",
       "      <td>Wed Sep 05 23:59:59 +0000 2012</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>219160 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_id:token  item_id:token                 timestamp:float\n",
       "5689                0              0  Fri Apr 06 12:52:34 +0000 2012\n",
       "5690                1              1  Fri Apr 06 12:52:35 +0000 2012\n",
       "5692                2              2  Fri Apr 06 12:52:49 +0000 2012\n",
       "5693                3              3  Fri Apr 06 12:53:38 +0000 2012\n",
       "5694                4              4  Fri Apr 06 12:54:35 +0000 2012\n",
       "...               ...            ...                             ...\n",
       "331776            111            185  Wed Sep 05 23:55:47 +0000 2012\n",
       "331782            379             88  Wed Sep 05 23:56:30 +0000 2012\n",
       "331783            359            754  Wed Sep 05 23:57:37 +0000 2012\n",
       "331784            403            148  Wed Sep 05 23:58:06 +0000 2012\n",
       "331787             81             97  Wed Sep 05 23:59:59 +0000 2012\n",
       "\n",
       "[219160 rows x 3 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkin_df_timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkin_df_sample = convert_to_unix_timestamp(checkin_df_sample, \"timestamp:float\")\n",
    "checkin_df_timestamp = convert_to_unix_timestamp(checkin_df_timestamp, \"timestamp:float\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id:token</th>\n",
       "      <th>item_id:token</th>\n",
       "      <th>timestamp:float</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5689</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.333717e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5690</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.333717e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5692</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.333717e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5693</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1.333717e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5694</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1.333717e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331776</th>\n",
       "      <td>111</td>\n",
       "      <td>185</td>\n",
       "      <td>1.346889e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331782</th>\n",
       "      <td>379</td>\n",
       "      <td>88</td>\n",
       "      <td>1.346889e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331783</th>\n",
       "      <td>359</td>\n",
       "      <td>754</td>\n",
       "      <td>1.346889e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331784</th>\n",
       "      <td>403</td>\n",
       "      <td>148</td>\n",
       "      <td>1.346889e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331787</th>\n",
       "      <td>81</td>\n",
       "      <td>97</td>\n",
       "      <td>1.346890e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>219160 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_id:token  item_id:token  timestamp:float\n",
       "5689                0              0     1.333717e+09\n",
       "5690                1              1     1.333717e+09\n",
       "5692                2              2     1.333717e+09\n",
       "5693                3              3     1.333717e+09\n",
       "5694                4              4     1.333717e+09\n",
       "...               ...            ...              ...\n",
       "331776            111            185     1.346889e+09\n",
       "331782            379             88     1.346889e+09\n",
       "331783            359            754     1.346889e+09\n",
       "331784            403            148     1.346889e+09\n",
       "331787             81             97     1.346890e+09\n",
       "\n",
       "[219160 rows x 3 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkin_df_timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id:token</th>\n",
       "      <th>item_id:token</th>\n",
       "      <th>timestamp:float</th>\n",
       "      <th>checkin_count:float</th>\n",
       "      <th>business_popularity:float</th>\n",
       "      <th>review_id:token</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0_x</td>\n",
       "      <td>0_x</td>\n",
       "      <td>1.333717e+09</td>\n",
       "      <td>2</td>\n",
       "      <td>0.061404</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1_x</td>\n",
       "      <td>1_x</td>\n",
       "      <td>1.333717e+09</td>\n",
       "      <td>1</td>\n",
       "      <td>0.026316</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2_x</td>\n",
       "      <td>2_x</td>\n",
       "      <td>1.333717e+09</td>\n",
       "      <td>33</td>\n",
       "      <td>0.031100</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3_x</td>\n",
       "      <td>3_x</td>\n",
       "      <td>1.333717e+09</td>\n",
       "      <td>52</td>\n",
       "      <td>0.039872</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4_x</td>\n",
       "      <td>4_x</td>\n",
       "      <td>1.333717e+09</td>\n",
       "      <td>11</td>\n",
       "      <td>0.009569</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99680</th>\n",
       "      <td>190_x</td>\n",
       "      <td>1021_x</td>\n",
       "      <td>1.346887e+09</td>\n",
       "      <td>1</td>\n",
       "      <td>0.012759</td>\n",
       "      <td>67522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99681</th>\n",
       "      <td>126_x</td>\n",
       "      <td>1877_x</td>\n",
       "      <td>1.346888e+09</td>\n",
       "      <td>1</td>\n",
       "      <td>0.015152</td>\n",
       "      <td>67523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99682</th>\n",
       "      <td>1364_x</td>\n",
       "      <td>1051_x</td>\n",
       "      <td>1.346888e+09</td>\n",
       "      <td>2</td>\n",
       "      <td>0.018341</td>\n",
       "      <td>67524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99683</th>\n",
       "      <td>100_x</td>\n",
       "      <td>471_x</td>\n",
       "      <td>1.346888e+09</td>\n",
       "      <td>1</td>\n",
       "      <td>0.028708</td>\n",
       "      <td>67525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99684</th>\n",
       "      <td>734_x</td>\n",
       "      <td>2196_x</td>\n",
       "      <td>1.346889e+09</td>\n",
       "      <td>1</td>\n",
       "      <td>0.010367</td>\n",
       "      <td>67526</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>67526 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      user_id:token item_id:token  timestamp:float  checkin_count:float  \\\n",
       "1               0_x           0_x     1.333717e+09                    2   \n",
       "2               1_x           1_x     1.333717e+09                    1   \n",
       "3               2_x           2_x     1.333717e+09                   33   \n",
       "4               3_x           3_x     1.333717e+09                   52   \n",
       "5               4_x           4_x     1.333717e+09                   11   \n",
       "...             ...           ...              ...                  ...   \n",
       "99680         190_x        1021_x     1.346887e+09                    1   \n",
       "99681         126_x        1877_x     1.346888e+09                    1   \n",
       "99682        1364_x        1051_x     1.346888e+09                    2   \n",
       "99683         100_x         471_x     1.346888e+09                    1   \n",
       "99684         734_x        2196_x     1.346889e+09                    1   \n",
       "\n",
       "       business_popularity:float  review_id:token  \n",
       "1                       0.061404                1  \n",
       "2                       0.026316                2  \n",
       "3                       0.031100                3  \n",
       "4                       0.039872                4  \n",
       "5                       0.009569                5  \n",
       "...                          ...              ...  \n",
       "99680                   0.012759            67522  \n",
       "99681                   0.015152            67523  \n",
       "99682                   0.018341            67524  \n",
       "99683                   0.028708            67525  \n",
       "99684                   0.010367            67526  \n",
       "\n",
       "[67526 rows x 6 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkin_df_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkin_df_sample.sort_values(by=\"checkin_count:float\", ascending=False)\n",
    "# very important: keeping the duplicate check-ins for the context aware recommendation to have the timestamps saved\n",
    "\n",
    "\n",
    "# very important: dropping duplicate check-ins \n",
    "checkin_df_sample = checkin_df_sample.drop_duplicates(subset=[\"user_id:token\", \"item_id:token\"], keep=\"first\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_df_sample = user_df_sample[[\"user_id:token\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This would be the correct splits if we let recbole do the splitting\n",
    "\n",
    "# data_saver_recbole(checkin_df_sample, \"recbole\", \"inter\")\n",
    "# data_saver_recbole(user_df_sample, \"recbole\", \"user\")\n",
    "# data_saver_recbole(poi_df_sample, \"recbole\", \"item\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id:token</th>\n",
       "      <th>category_id:token</th>\n",
       "      <th>category_name:token_seq</th>\n",
       "      <th>lat:float</th>\n",
       "      <th>lon:float</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>156_x</td>\n",
       "      <td>4bf58dd8d48988d129951735</td>\n",
       "      <td>Train Station</td>\n",
       "      <td>35.700253</td>\n",
       "      <td>139.480255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>431_x</td>\n",
       "      <td>4bf58dd8d48988d1eb931735</td>\n",
       "      <td>Airport</td>\n",
       "      <td>35.548963</td>\n",
       "      <td>139.784611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1031_x</td>\n",
       "      <td>4bf58dd8d48988d1df941735</td>\n",
       "      <td>Bridge</td>\n",
       "      <td>35.609929</td>\n",
       "      <td>139.825659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1428_x</td>\n",
       "      <td>4bf58dd8d48988d129951735</td>\n",
       "      <td>Train Station</td>\n",
       "      <td>35.749538</td>\n",
       "      <td>139.586540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>184_x</td>\n",
       "      <td>4bf58dd8d48988d129951735</td>\n",
       "      <td>Train Station</td>\n",
       "      <td>35.729025</td>\n",
       "      <td>139.711096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412051</th>\n",
       "      <td>1509_x</td>\n",
       "      <td>4bf58dd8d48988d120941735</td>\n",
       "      <td>Bar</td>\n",
       "      <td>35.697700</td>\n",
       "      <td>139.770384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425285</th>\n",
       "      <td>1467_x</td>\n",
       "      <td>4bf58dd8d48988d16d941735</td>\n",
       "      <td>Café</td>\n",
       "      <td>35.702436</td>\n",
       "      <td>139.770470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450169</th>\n",
       "      <td>1440_x</td>\n",
       "      <td>4bf58dd8d48988d129951735</td>\n",
       "      <td>Train Station</td>\n",
       "      <td>35.607054</td>\n",
       "      <td>139.734894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462519</th>\n",
       "      <td>2582_x</td>\n",
       "      <td>4d954b0ea243a5684a65b473</td>\n",
       "      <td>Convenience Store</td>\n",
       "      <td>35.701178</td>\n",
       "      <td>139.771038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488554</th>\n",
       "      <td>1678_x</td>\n",
       "      <td>4eb1daf44b900d56c88a4600</td>\n",
       "      <td>Fair</td>\n",
       "      <td>35.630669</td>\n",
       "      <td>139.795103</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2804 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       item_id:token         category_id:token category_name:token_seq  \\\n",
       "7              156_x  4bf58dd8d48988d129951735           Train Station   \n",
       "10             431_x  4bf58dd8d48988d1eb931735                 Airport   \n",
       "14            1031_x  4bf58dd8d48988d1df941735                  Bridge   \n",
       "15            1428_x  4bf58dd8d48988d129951735           Train Station   \n",
       "17             184_x  4bf58dd8d48988d129951735           Train Station   \n",
       "...              ...                       ...                     ...   \n",
       "412051        1509_x  4bf58dd8d48988d120941735                     Bar   \n",
       "425285        1467_x  4bf58dd8d48988d16d941735                    Café   \n",
       "450169        1440_x  4bf58dd8d48988d129951735           Train Station   \n",
       "462519        2582_x  4d954b0ea243a5684a65b473       Convenience Store   \n",
       "488554        1678_x  4eb1daf44b900d56c88a4600                    Fair   \n",
       "\n",
       "        lat:float   lon:float  \n",
       "7       35.700253  139.480255  \n",
       "10      35.548963  139.784611  \n",
       "14      35.609929  139.825659  \n",
       "15      35.749538  139.586540  \n",
       "17      35.729025  139.711096  \n",
       "...           ...         ...  \n",
       "412051  35.697700  139.770384  \n",
       "425285  35.702436  139.770470  \n",
       "450169  35.607054  139.734894  \n",
       "462519  35.701178  139.771038  \n",
       "488554  35.630669  139.795103  \n",
       "\n",
       "[2804 rows x 5 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poi_df_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkin_df_timestamp = checkin_df_timestamp[[\"user_id:token\", \"item_id:token\", \"timestamp:float\"]] # FINAL\n",
    "checkins_capri_train_test_tune = checkin_df_sample[[\"user_id:token\", \"item_id:token\", \"timestamp:float\", \"checkin_count:float\"]]\n",
    "try:\n",
    "    poi_df_sample_capri = poi_df_sample[[\"item_id:token\", \"lat:float\", \"lon:float\"]] # FINAL\n",
    "except KeyError: # in the snowcard data the coordinates are not given\n",
    "    poi_df_sample_capri = poi_df_sample[[\"item_id:token\"]]\n",
    "datasize_capri = pd.DataFrame(data={\"num_users\" : [len(checkins_capri_train_test_tune[\"user_id:token\"].unique())], \"num_items\" : [len(checkins_capri_train_test_tune[\"item_id:token\"].unique())]}) # FINAL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating train, test and val splits (user-based temporal split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Set:\n",
      "      user_id:token item_id:token  checkin_count:float\n",
      "1               0_x           0_x                    2\n",
      "150             0_x          87_x                    1\n",
      "152             0_x          89_x                   15\n",
      "154             0_x          91_x                   13\n",
      "59655           0_x         889_x                    1\n",
      "\n",
      "Validation Set:\n",
      "      user_id:token item_id:token  checkin_count:float\n",
      "72716           0_x         126_x                    1\n",
      "72718           0_x         745_x                    2\n",
      "72828           0_x        1957_x                    1\n",
      "18048           0_x         171_x                    2\n",
      "27005        1000_x        1997_x                    1\n",
      "\n",
      "Test Set:\n",
      "      user_id:token item_id:token  checkin_count:float\n",
      "83351           0_x          68_x                    1\n",
      "73208           0_x         193_x                    1\n",
      "73209           0_x         213_x                    1\n",
      "73803           0_x         831_x                    1\n",
      "73871           0_x         390_x                    1\n"
     ]
    }
   ],
   "source": [
    "# splitting the data into train, test, and tune\n",
    "checkins_capri_train_test_tune = checkins_capri_train_test_tune.sort_values(by=[\"user_id:token\", \"timestamp:float\"])\n",
    "checkins_capri_train_test_tune = checkins_capri_train_test_tune[[\"user_id:token\", \"item_id:token\", \"checkin_count:float\"]]\n",
    "\n",
    "# Split the data\n",
    "train_list = []\n",
    "val_list = []\n",
    "test_list = []\n",
    "\n",
    "for user, group in checkins_capri_train_test_tune.groupby('user_id:token'):\n",
    "    n = len(group)\n",
    "    train_end = int(n * 0.65)\n",
    "    val_end = int(n * 0.80)\n",
    "    \n",
    "    train_list.append(group.iloc[:train_end])\n",
    "    val_list.append(group.iloc[train_end:val_end])\n",
    "    test_list.append(group.iloc[val_end:])\n",
    "\n",
    "# Combine lists into DataFrames\n",
    "train_df = pd.concat(train_list)\n",
    "val_df = pd.concat(val_list)\n",
    "test_df = pd.concat(test_list)\n",
    "\n",
    "\n",
    "\n",
    "# Check the splits\n",
    "\n",
    "# FINAL 6-8\n",
    "print(\"Train Set:\")\n",
    "print(train_df.head())\n",
    "print(\"\\nValidation Set:\")\n",
    "print(val_df.head())\n",
    "print(\"\\nTest Set:\")\n",
    "print(test_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def datasaver_capri(df, filename):\n",
    "    \n",
    "    if not os.path.exists(DATASET_DIR + \"processed_data_capri\"):\n",
    "        os.makedirs(DATASET_DIR + \"processed_data_capri\")\n",
    "    \n",
    "    df.to_csv(DATASET_DIR + \"processed_data_capri/\" + filename + \".txt\", sep='\\t', index=False, header=False)\n",
    "    print(\"Data saved as \" + filename + \".txt\")\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding a category column\n",
    "if include_categories is True:\n",
    "    if dataset == \"yelp\":\n",
    "        # Split the 'category_name' column by commas\n",
    "        poi_df_sample['category_name_unstacked:token_seq'] = poi_df_sample['category_name:token_seq'].str.split(', ')\n",
    "\n",
    "        # Unstack the categories into multiple rows\n",
    "        category_df_sample = poi_df_sample.explode('category_name_unstacked:token_seq')\n",
    "        category_counts = category_df_sample[\"category_name_unstacked:token_seq\"].value_counts()\n",
    "        category_mask = category_df_sample[\"category_name_unstacked:token_seq\"].map(category_counts) >= 25\n",
    "        category_df_sample_filtered = category_df_sample.loc[category_mask]\n",
    "        category_df_sample_filtered[\"category_id:token\"], category_id = pd.factorize(category_df_sample_filtered[\"category_name_unstacked:token_seq\"])\n",
    "        category_df_sample_filtered.dropna(inplace=True)\n",
    "        datasize_capri = pd.DataFrame(data={\"num_users\" : [len(checkins_capri_train_test_tune[\"user_id:token\"].unique())], \"num_items\" : [len(checkins_capri_train_test_tune[\"item_id:token\"].unique())], \"num_categories\" : [len(category_df_sample_filtered[\"category_id:token\"].unique())]}) # FINAL\n",
    "        datasaver_capri(category_df_sample_filtered, \"poiCategories\")\n",
    "\n",
    "\n",
    "    elif dataset == \"foursquarenyc\" or dataset == \"foursquaretky\":\n",
    "        poi_df_sample[\"category_id:token\"], category_id = pd.factorize(poi_df_sample[\"category_name:token_seq\"])\n",
    "        datasize_capri = pd.DataFrame(data={\"num_users\" : [len(checkins_capri_train_test_tune[\"user_id:token\"].unique())], \"num_items\" : [len(checkins_capri_train_test_tune[\"item_id:token\"].unique())], \"num_categories\" : [len(poi_df_sample[\"category_id:token\"].unique())]})\n",
    "        poi_df_categories = poi_df_sample[[\"item_id:token\", \"category_id:token\"]]\n",
    "        datasaver_capri(poi_df_categories, \"poiCategories\")\n",
    "\n",
    "    elif dataset == \"snowcard\":\n",
    "        datasize_capri = pd.DataFrame(data={\"num_users\" : [len(checkins_capri_train_test_tune[\"user_id:token\"].unique())], \"num_items\" : [len(checkins_capri_train_test_tune[\"item_id:token\"].unique())], \"num_categories\" : [len(poi_df_sample[\"category_id:token\"].unique())]})\n",
    "        poi_df_categories = poi_df_sample[[\"item_id:token\", \"category_id:token\"]]\n",
    "        datasaver_capri(poi_df_categories, \"poiCategories\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1500, 1500, 1500)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[\"user_id:token\"].nunique(), val_df[\"user_id:token\"].nunique(), test_df[\"user_id:token\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the correct split since we perform the splitting ourselves\n",
    "\n",
    "data_saver_recbole(train_df, \"recbole\", \"train.inter\")\n",
    "data_saver_recbole(test_df, \"recbole\", \"test.inter\")\n",
    "data_saver_recbole(val_df, \"recbole\", \"valid.inter\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make an intervened sample for RecBole debias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All user IDs are present in both subsets.\n"
     ]
    }
   ],
   "source": [
    "checkins_debias = checkins_capri_train_test_tune.copy()\n",
    "intervened_set = checkins_debias.sample(frac=0.5, random_state=10002)\n",
    "normal_set = checkins_debias.drop(intervened_set.index)\n",
    "\n",
    "original_user_ids = set(checkins_debias[\"user_id:token\"].unique())\n",
    "intervened_user_ids = set(intervened_set[\"user_id:token\"].unique())\n",
    "normal_user_ids = set(normal_set[\"user_id:token\"].unique())\n",
    "\n",
    "missing_in_intervened = original_user_ids - intervened_user_ids\n",
    "missing_in_normal = original_user_ids - normal_user_ids\n",
    "\n",
    "if not missing_in_intervened and not missing_in_normal:\n",
    "    print(\"All user IDs are present in both subsets.\")\n",
    "else:\n",
    "    print(\"Missing user IDs in intervened set:\", missing_in_intervened)\n",
    "    print(\"Missing user IDs in normal set:\", missing_in_normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOURCE: https://github.com/DavyMorgan/dps/blob/19a3e5fb2cb6932c3f093ed443760ecd3d95bfdb/data_process_service/splitter.py\n",
    "\n",
    "popularity = (\n",
    "            intervened_set[[\"item_id:token\", \"user_id:token\"]]\n",
    "            .groupby(\"item_id:token\")\n",
    "            .count()\n",
    "            .reset_index()\n",
    "            .rename(columns={\"user_id:token\": \"pop\"})\n",
    "        )\n",
    "intervened_set = intervened_set.merge(popularity, on=\"item_id:token\", how=\"left\")\n",
    "intervened_set[\"pop\"] = intervened_set[\"pop\"].apply(lambda x: 1 / x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "intervened_set.sort_values(by=[\"pop\", \"item_id:token\"], ascending=False, inplace=True)\n",
    "intervened_set.drop(columns=[\"pop\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intervened Training Set Size: 41622\n",
      "Intervened Validation Set Size: 9409\n",
      "Intervened Test Set Size: 16495\n"
     ]
    }
   ],
   "source": [
    "# Lists to collect data for each split\n",
    "train_list_intervened, val_list_intervened, test_list_intervened = [], [], []\n",
    "\n",
    "# Loop through each user's data in the sorted intervened set\n",
    "for user, group in intervened_set.groupby('user_id:token'):\n",
    "    n = len(group)\n",
    "    \n",
    "    # Calculate end indices based on the desired split ratios\n",
    "    test_end = int(n * 0.5)  # Top 50% for test\n",
    "    train_end = test_end + int(n * 0.25)  # Next 25% for train\n",
    "    \n",
    "    # Add to respective lists\n",
    "    test_list_intervened.append(group.iloc[:test_end])  # First 50% goes to test\n",
    "    train_list_intervened.append(group.iloc[test_end:train_end])  # Next 25% goes to train\n",
    "    val_list_intervened.append(group.iloc[train_end:])  # Remaining 25% goes to validation\n",
    "\n",
    "# Concatenate lists into DataFrames\n",
    "train_df_intervened = pd.concat(train_list_intervened, ignore_index=True)\n",
    "train_df_intervened = pd.concat([train_df_intervened, normal_set], ignore_index=True).sort_values(by=[\"user_id:token\"])\n",
    "val_df_intervened = pd.concat(val_list_intervened, ignore_index=True)\n",
    "test_df_intervened = pd.concat(test_list_intervened, ignore_index=True)\n",
    "\n",
    "# Output the sizes of each set\n",
    "print(\"Intervened Training Set Size:\", len(train_df_intervened))\n",
    "print(\"Intervened Validation Set Size:\", len(val_df_intervened))\n",
    "print(\"Intervened Test Set Size:\", len(test_df_intervened))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id:token</th>\n",
       "      <th>item_id:token</th>\n",
       "      <th>checkin_count:float</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0_x</td>\n",
       "      <td>775_x</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7861</th>\n",
       "      <td>0_x</td>\n",
       "      <td>89_x</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7862</th>\n",
       "      <td>0_x</td>\n",
       "      <td>7_x</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7863</th>\n",
       "      <td>0_x</td>\n",
       "      <td>31_x</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7864</th>\n",
       "      <td>0_x</td>\n",
       "      <td>50_x</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41590</th>\n",
       "      <td>9_x</td>\n",
       "      <td>674_x</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41591</th>\n",
       "      <td>9_x</td>\n",
       "      <td>146_x</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41592</th>\n",
       "      <td>9_x</td>\n",
       "      <td>2459_x</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41594</th>\n",
       "      <td>9_x</td>\n",
       "      <td>433_x</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41621</th>\n",
       "      <td>9_x</td>\n",
       "      <td>972_x</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>41622 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      user_id:token item_id:token  checkin_count:float\n",
       "0               0_x         775_x                    1\n",
       "7861            0_x          89_x                   15\n",
       "7862            0_x           7_x                    5\n",
       "7863            0_x          31_x                    1\n",
       "7864            0_x          50_x                    2\n",
       "...             ...           ...                  ...\n",
       "41590           9_x         674_x                   15\n",
       "41591           9_x         146_x                    1\n",
       "41592           9_x        2459_x                    1\n",
       "41594           9_x         433_x                    2\n",
       "41621           9_x         972_x                    1\n",
       "\n",
       "[41622 rows x 3 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_intervened"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_saver_recbole(train_df_intervened, \"recbole_debias\", \"train.inter\")\n",
    "data_saver_recbole(test_df_intervened, \"recbole_debias\", \"test.inter\")\n",
    "data_saver_recbole(val_df_intervened, \"recbole_debias\", \"valid.inter\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save for CAPRI without _x since they require integers as IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_id_cleaner(df, column_name_list = [\"user_id:token\", \"item_id:token\"]):\n",
    "    for column_name in column_name_list:\n",
    "        df[column_name] = df[column_name].str.split(\"_\")\n",
    "        df[column_name] = df[column_name].apply(lambda x: x[0])\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9q/p0b6nwnd5071040x3849mdvc0000gn/T/ipykernel_58945/2072793301.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[column_name] = df[column_name].str.split(\"_\")\n",
      "/var/folders/9q/p0b6nwnd5071040x3849mdvc0000gn/T/ipykernel_58945/2072793301.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[column_name] = df[column_name].apply(lambda x: x[0])\n"
     ]
    }
   ],
   "source": [
    "poi_df_sample_capri = user_id_cleaner(poi_df_sample_capri, [\"item_id:token\"])\n",
    "train_df = user_id_cleaner(train_df)\n",
    "val_df = user_id_cleaner(val_df)\n",
    "test_df = user_id_cleaner(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved as checkins.txt\n",
      "Data saved as dataSize.txt\n",
      "Data saved as poiCoos.txt\n",
      "Data saved as train.txt\n",
      "Data saved as tune.txt\n",
      "Data saved as test.txt\n"
     ]
    }
   ],
   "source": [
    "datasaver_capri(checkin_df_timestamp, \"checkins\")\n",
    "datasaver_capri(datasize_capri, \"dataSize\")\n",
    "datasaver_capri(poi_df_sample_capri, \"poiCoos\")\n",
    "datasaver_capri(train_df, \"train\")\n",
    "datasaver_capri(val_df, \"tune\")\n",
    "datasaver_capri(test_df, \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"item_id:token\"].nunique()\n",
    "\n",
    "train_df[\"user_id:token\"] = train_df[\"user_id:token\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2799"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[\"item_id:token\"].nunique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id:token</th>\n",
       "      <th>item_id:token</th>\n",
       "      <th>checkin_count:float</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30184</th>\n",
       "      <td>158</td>\n",
       "      <td>999</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23997</th>\n",
       "      <td>316</td>\n",
       "      <td>999</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59406</th>\n",
       "      <td>32</td>\n",
       "      <td>999</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33937</th>\n",
       "      <td>1484</td>\n",
       "      <td>999</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90836</th>\n",
       "      <td>349</td>\n",
       "      <td>999</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76823</th>\n",
       "      <td>285</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31958</th>\n",
       "      <td>496</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29880</th>\n",
       "      <td>362</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73601</th>\n",
       "      <td>485</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>43186 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       user_id:token item_id:token  checkin_count:float\n",
       "30184            158           999                    2\n",
       "23997            316           999                    1\n",
       "59406             32           999                    1\n",
       "33937           1484           999                    1\n",
       "90836            349           999                    1\n",
       "...              ...           ...                  ...\n",
       "76823            285             0                    1\n",
       "31958            496             0                    2\n",
       "29880            362             0                    1\n",
       "73601            485             0                    1\n",
       "1                  0             0                    2\n",
       "\n",
       "[43186 rows x 3 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "train_df.sort_values(by=\"item_id:token\", ascending=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
