{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "from globals import BASE_DIR\n",
    "\n",
    "available_datasets = [\"foursquaretky\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for foursquaretky_sample-contextpoi-LORE-Oct-28-2024_09-00-00: {'precision': 0.0118, 'recall': 0.01479, 'ndcg': 0.01352, 'map': 0.00555}\n",
      "Saved general_evaluation.json to /Volumes/Forster Neu/Masterarbeit Data/foursquaretky_dataset/recommendations/foursquaretky_sample-contextpoi-LORE-Oct-28-2024_09-00-00/general_evaluation.json\n",
      "Saved top_k_recommendations.json to /Volumes/Forster Neu/Masterarbeit Data/foursquaretky_dataset/recommendations/foursquaretky_sample-contextpoi-LORE-Oct-28-2024_09-00-00/top_k_recommendations.json\n",
      "Metrics for foursquaretky_sample-contextpoi-LORE-Sep-16-2024_09-00-00: {'precision': 0.01133, 'recall': 0.01374, 'ndcg': 0.01354, 'map': 0.00595}\n",
      "Saved general_evaluation.json to /Volumes/Forster Neu/Masterarbeit Data/foursquaretky_dataset/recommendations/foursquaretky_sample-contextpoi-LORE-Sep-16-2024_09-00-00/general_evaluation.json\n",
      "Saved top_k_recommendations.json to /Volumes/Forster Neu/Masterarbeit Data/foursquaretky_dataset/recommendations/foursquaretky_sample-contextpoi-LORE-Sep-16-2024_09-00-00/top_k_recommendations.json\n",
      "Metrics for foursquaretky_sample-contextpoi-USG-Oct-28-2024_09-00-00: {'precision': 0.09967, 'recall': 0.11087, 'ndcg': 0.13243, 'map': 0.07276}\n",
      "Saved general_evaluation.json to /Volumes/Forster Neu/Masterarbeit Data/foursquaretky_dataset/recommendations/foursquaretky_sample-contextpoi-USG-Oct-28-2024_09-00-00/general_evaluation.json\n",
      "Saved top_k_recommendations.json to /Volumes/Forster Neu/Masterarbeit Data/foursquaretky_dataset/recommendations/foursquaretky_sample-contextpoi-USG-Oct-28-2024_09-00-00/top_k_recommendations.json\n",
      "Metrics for foursquaretky_sample-contextpoi-USG-Sep-16-2024_09-00-00: {'precision': 0.07073, 'recall': 0.08268, 'ndcg': 0.0914, 'map': 0.04442}\n",
      "Saved general_evaluation.json to /Volumes/Forster Neu/Masterarbeit Data/foursquaretky_dataset/recommendations/foursquaretky_sample-contextpoi-USG-Sep-16-2024_09-00-00/general_evaluation.json\n",
      "Saved top_k_recommendations.json to /Volumes/Forster Neu/Masterarbeit Data/foursquaretky_dataset/recommendations/foursquaretky_sample-contextpoi-USG-Sep-16-2024_09-00-00/top_k_recommendations.json\n"
     ]
    }
   ],
   "source": [
    "for dataset in available_datasets:\n",
    "    OUTPUT_DIR = f\"{BASE_DIR}{dataset}_dataset/recommendations/\"\n",
    "    recs = os.listdir(OUTPUT_DIR)\n",
    "    \n",
    "    if '.DS_Store' in recs:\n",
    "        recs.remove('.DS_Store')\n",
    "\n",
    "    capri_recs = []\n",
    "    for dir in recs:\n",
    "        if dir.split(\"-\")[1] == \"contextpoi\":  # Filter for contextpoi directories\n",
    "            capri_recs.append(dir)\n",
    "    \n",
    "    for dir in capri_recs:\n",
    "        # Get the correct directory path for the current dataset and capri_rec directory\n",
    "        dir_path = os.path.join(OUTPUT_DIR, dir)\n",
    "        files = os.listdir(dir_path)\n",
    "        \n",
    "        # Find the file that starts with 'Eval'\n",
    "        eval_file = next((f for f in files if f.startswith('Eval')), None)\n",
    "        \n",
    "        if eval_file:\n",
    "            eval_csv = os.path.join(dir_path, eval_file)  # Full path to the correct CSV file\n",
    "            json_file = os.path.join(dir_path, 'general_evaluation.json')\n",
    "\n",
    "            # Read the evaluation CSV into a pandas DataFrame\n",
    "            eval_df = pd.read_csv(eval_csv)\n",
    "\n",
    "            # Assuming the CSV has a single row with all the metrics, convert the row to a dictionary\n",
    "            metrics = eval_df.iloc[0].to_dict()\n",
    "            print(f\"Metrics for {dir}: {metrics}\")\n",
    "\n",
    "            # Create the structure for the JSON output\n",
    "            evaluation_data = {\n",
    "                \"test_result\": {\n",
    "                    \"recall@10\": metrics.get(\"recall\"),\n",
    "                    \"ndcg@10\": metrics.get(\"ndcg\"),\n",
    "                    \"precision@10\": metrics.get(\"precision\"),\n",
    "                    \"map@10\": metrics.get(\"map\")\n",
    "                }\n",
    "            }\n",
    "\n",
    "            # Write the evaluation data to a JSON file\n",
    "            with open(json_file, 'w') as f:\n",
    "                json.dump(evaluation_data, f, indent=4)\n",
    "\n",
    "            print(f\"Saved general_evaluation.json to {json_file}\")\n",
    "        else:\n",
    "            print(f\"No Eval file found in {dir_path}\")\n",
    "\n",
    "        # Find the file that starts with 'Rec'\n",
    "        rec_file = next((f for f in files if f.startswith('Rec')), None)\n",
    "        \n",
    "        if rec_file:\n",
    "            rec_txt = os.path.join(dir_path, rec_file)  # Full path to the Rec txt file\n",
    "            json_file = os.path.join(dir_path, 'top_k_recommendations.json')\n",
    "\n",
    "            # Create an empty dictionary to store the recommendations\n",
    "            recommendations = {}\n",
    "\n",
    "            # Read the Rec txt file\n",
    "            with open(rec_txt, 'r') as f:\n",
    "                for line in f:\n",
    "                    # Split the line into three components (index, user_id, item_ids)\n",
    "                    parts = line.strip().split(\"\\t\")\n",
    "                    \n",
    "                    if len(parts) == 3:\n",
    "                        user_id = parts[1]  # Second column is the user_id\n",
    "                        item_ids = parts[2].split(\",\")  # Third column is the comma-separated item_ids\n",
    "\n",
    "                        # Convert user_id and item_ids to strings with \"_x\" suffix\n",
    "                        user_id = f\"{user_id}_x\"\n",
    "                        item_ids = [f\"{item}_x\" for item in item_ids]\n",
    "\n",
    "                        # Add the recommendations to the dictionary\n",
    "                        recommendations[user_id] = [{\"item_id\": item_ids}]\n",
    "            \n",
    "            # Write the recommendations to a JSON file\n",
    "            with open(json_file, 'w') as f:\n",
    "                json.dump(recommendations, f, indent=4)\n",
    "\n",
    "            print(f\"Saved top_k_recommendations.json to {json_file}\")\n",
    "        else:\n",
    "            print(f\"No Rec file found in {dir_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
