{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from globals import YELP_DIR\n",
    "import json\n",
    "import os\n",
    "\n",
    "YELP_DIR = \"/Volumes/Forster Neu/Masterarbeit Data/yelp_dataset/\"\n",
    "ORIGINAL_DATA_FOLDER = \"/Users/andreaforster/dev/thesis/CAPRI/Data/Yelp/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Yelp dataset was used in the following script: https://www.yelp.com/dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "business_df = pd.read_json(YELP_DIR + \"yelp_academic_dataset_business.json\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkin_df = pd.read_json(YELP_DIR + \"yelp_academic_dataset_checkin.json\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_big_json(file_path):\n",
    "    data = []\n",
    "\n",
    "    # Open the file and read it line by line\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            # Parse the JSON data and append to the list\n",
    "            data.append(json.loads(line))\n",
    "\n",
    "    # Create a DataFrame from the list of records\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    # Print the first few rows of the DataFram\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_df = open_big_json(YELP_DIR + \"yelp_academic_dataset_user.json\")\n",
    "review_df = open_big_json(YELP_DIR + \"yelp_academic_dataset_review.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def review_binary(row):\n",
    "#     if row['stars'] >= 4:\n",
    "#         return 1\n",
    "#     else:\n",
    "#         return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9q/p0b6nwnd5071040x3849mdvc0000gn/T/ipykernel_52678/2360509686.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  business_df_filtered[\"popularity\"] = business_df_filtered[\"review_count\"] / max_num_reviews\n"
     ]
    }
   ],
   "source": [
    "# filtering out users and businesses with less than 10 reviews\n",
    "\n",
    "business_counts = review_df[\"business_id\"].value_counts()\n",
    "mask = review_df['business_id'].map(business_counts) >= 10\n",
    "review_df_filtered = review_df.loc[mask]\n",
    "\n",
    "counts = review_df_filtered['user_id'].value_counts()\n",
    "mask = review_df_filtered['user_id'].map(counts) >= 10\n",
    "review_df_filtered = review_df_filtered.loc[mask]\n",
    "\n",
    "\n",
    "# dropping text column\n",
    "review_df_filtered = review_df_filtered.drop(\"text\", axis=1)\n",
    "# turning reviews (stars) into implicit feedback (binary)\n",
    "#review_df_filtered[\"stars_bin\"] = review_df_filtered.apply(review_binary, axis=1)\n",
    "\n",
    "# getting the ids of the remaining users and businesses\n",
    "users_with_more_than_10_reviews = review_df_filtered['user_id'].unique()\n",
    "businesses_with_more_than_10_reviews = review_df_filtered['business_id'].unique()\n",
    "\n",
    "# filtering out the other users and businesses from the original dataframes\n",
    "user_df_filtered = user_df[user_df['user_id'].isin(users_with_more_than_10_reviews)]\n",
    "business_df_filtered = business_df[business_df['business_id'].isin(businesses_with_more_than_10_reviews)]\n",
    "\n",
    "\n",
    "# getting the highest number of reviews for a business to normalize the popularity of businesses\n",
    "max_num_reviews = business_df_filtered[\"review_count\"].max()\n",
    "business_df_filtered[\"popularity\"] = business_df_filtered[\"review_count\"] / max_num_reviews "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lengh of review_df_filtered: 3111228 vs. length of review_df: 6990280\n",
      "Length of user_df_filtered: 111434 vs. length of user_df: 1987897\n",
      "Length of business_df_filtered: 100184 vs. length of business_df: 150346\n"
     ]
    }
   ],
   "source": [
    "print(f\"Lengh of review_df_filtered: {len(review_df_filtered)} vs. length of review_df: {len(review_df)}\")\n",
    "print(f\"Length of user_df_filtered: {len(user_df_filtered)} vs. length of user_df: {len(user_df)}\")\n",
    "print(f\"Length of business_df_filtered: {len(business_df_filtered)} vs. length of business_df: {len(business_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "business_id\n",
       "ytynqOUb3hjKeJfRj5Tshw    2856\n",
       "_ab50qdWOk0DdB6XOrBitw    1996\n",
       "9PZxjhTIU7OgPIzuGi89Ew    1875\n",
       "ctHjyadbDQAtUFfkcAFEHw    1817\n",
       "GXFMD0Z4jEVZBCsbPf4CTQ    1770\n",
       "                          ... \n",
       "Ew1jBB6kHoQUhuqqXrJa-A       1\n",
       "gmmRfSIX0ixOCenBmGwlBQ       1\n",
       "Zo9n9WMGsEBJBL18tP1ekQ       1\n",
       "wqBCl5-yZQ2z1Bm4tL-JxA       1\n",
       "uY96VNf906Az5p0iA54xYQ       1\n",
       "Name: count, Length: 100184, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_df_filtered[\"business_id\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user_id\n",
       "_BcWyKQL16ndpBdggh2kNA    2772\n",
       "ET8n-r7glWYqZhuR6GcdNw    1601\n",
       "Xw7ZjaGfr0WNVt6s_5KZfA    1600\n",
       "0Igx-a1wAstiBDerGxXk2A    1528\n",
       "-G7Zkl1wIWBBmD0KRy_sCw    1509\n",
       "                          ... \n",
       "0GxT4IW5yLRZOksENl4MqA      10\n",
       "sjz1ERGjiTIP-kLOTrshVg      10\n",
       "Kf1n2U67z8485JR5VWkCwQ      10\n",
       "tfANULks7555uJ7UznUqpg      10\n",
       "VcMZN1b6QbdoAHmvc-2ueg      10\n",
       "Name: count, Length: 111434, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_df_filtered[\"user_id\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_popularity_calculator(user_df, review_df, business_df):\n",
    "    review_business_df = review_df.merge(business_df, on=\"business_id\", how=\"inner\")\n",
    "    average_popularity_per_user = review_business_df.groupby('user_id')['popularity'].mean().reset_index()\n",
    "    user_df = pd.merge(user_df, average_popularity_per_user, on='user_id', how='left')\n",
    "\n",
    "    user_df = user_df.loc[user_df[\"popularity\"] > 0]\n",
    "\n",
    "    #user_df = user_df.sort_values(by='popularity', ascending=False)\n",
    "\n",
    "    # Calculate thresholds for high, medium, and low popularity\n",
    "    threshold_low = user_df['popularity'].quantile(0.2)\n",
    "    threshold_med = user_df['popularity'].quantile(0.8)\n",
    "    \n",
    "    # Filter users based on thresholds\n",
    "    high_pop_user_df = user_df[user_df['popularity'] >= threshold_med]\n",
    "    medium_pop_user_df = user_df[(user_df['popularity'] >= threshold_low) & (user_df['popularity'] < threshold_med)]\n",
    "    low_pop_user_df = user_df[user_df['popularity'] < threshold_low]\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    return high_pop_user_df, medium_pop_user_df, low_pop_user_df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_pop_user_df, medium_pop_user_df, low_pop_user_df = user_popularity_calculator(user_df_filtered, review_df_filtered, business_df_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_sample_maker(high_pop_user_df, medium_pop_user_df, low_pop_user_df, review_df, business_df):\n",
    "    high_pop_user_df_sample = high_pop_user_df.sample(n=1000, random_state=123)\n",
    "    medium_pop_user_df_sample = medium_pop_user_df.sample(n=1000, random_state=123)\n",
    "    low_pop_user_df_sample = low_pop_user_df.sample(n=1000, random_state=123)\n",
    "\n",
    "    unique_users = list(set(high_pop_user_df_sample[\"user_id\"].tolist() + medium_pop_user_df_sample[\"user_id\"].tolist() + low_pop_user_df_sample[\"user_id\"].tolist()))\n",
    "\n",
    "    review_df_sample = review_df.loc[review_df[\"user_id\"].isin(unique_users)]\n",
    "\n",
    "    business_df_sample = business_df.loc[business_df[\"business_id\"].isin(review_df_sample[\"business_id\"].tolist())]\n",
    "\n",
    "    return review_df_sample, business_df_sample, high_pop_user_df_sample, medium_pop_user_df_sample, low_pop_user_df_sample\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_df_sample, business_df_sample, high_pop_user_df_sample, medium_pop_user_df_sample, low_pop_user_df_sample = data_sample_maker(high_pop_user_df, medium_pop_user_df, low_pop_user_df, review_df_filtered, business_df_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_df_sample = pd.concat([high_pop_user_df_sample, medium_pop_user_df_sample, low_pop_user_df_sample])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9q/p0b6nwnd5071040x3849mdvc0000gn/T/ipykernel_52678/4232908792.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  review_df_sample['checkin_count'] = review_df_sample.groupby(['user_id', 'business_id'])['business_id'].transform('count')\n"
     ]
    }
   ],
   "source": [
    "review_df_sample['checkin_count'] = review_df_sample.groupby(['user_id', 'business_id'])['business_id'].transform('count')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_df_sample = review_df_sample.drop([\"stars_bin\",\"stars\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>business_id</th>\n",
       "      <th>useful</th>\n",
       "      <th>funny</th>\n",
       "      <th>cool</th>\n",
       "      <th>date</th>\n",
       "      <th>checkin_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>cvQXRFLCyr0S7EgFb4lZqw</td>\n",
       "      <td>ZGjgfSvjQK886kiTzLwfLQ</td>\n",
       "      <td>EtKSTHV5Qx_Q7Aur9o4kQQ</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2009-10-14 01:15:04</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>EZarjNNbO_2yH1Xbizog9g</td>\n",
       "      <td>R_W9WlKiA56VzVbRzTULQQ</td>\n",
       "      <td>pR8u8hXf1vvzoAGOoKHQqQ</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-08-25 17:17:46</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>pl5AjpEcFxFTltkBvHjsRA</td>\n",
       "      <td>YjS6MDNwGbueb5WtALIJ2A</td>\n",
       "      <td>EBn3U4mpnIRLIy2lKuilRQ</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2012-11-06 18:54:49</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>WHBZtv1ZabwX0r-alDjA3g</td>\n",
       "      <td>x1qKiRxnPLf3JvOsUAsv_Q</td>\n",
       "      <td>GgGfhKUGusCbP-rvjHiS3A</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-01-17 18:07:08</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>uwPhE21CZLlp1kkSMPvvYw</td>\n",
       "      <td>5OnQqP3q2_9auNdDKpLdsw</td>\n",
       "      <td>WKMJwqnfZKsAae75RMP6jA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2012-11-06 23:35:15</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6990047</th>\n",
       "      <td>jsBz-uJy6M--L8ogPG52dA</td>\n",
       "      <td>bJ5FtCtZX3ZZacz2_2PJjA</td>\n",
       "      <td>mBgaPljP3OYkl_vGKTyFNw</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2012-03-16 05:37:03</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6990196</th>\n",
       "      <td>EQQWfhD7l2X767XHZykdDA</td>\n",
       "      <td>hVXj8lnaTIMLTkD_yjSj6A</td>\n",
       "      <td>PlMXeyXhy1FcnvOSLBGFQQ</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-09-11 19:03:01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6990234</th>\n",
       "      <td>oVH6oK8G_FTYiaglrIk09A</td>\n",
       "      <td>piIljcy0fhEW6IhB1eyrFA</td>\n",
       "      <td>oBNrLz4EDhiscSlbOl8uAw</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-11-27 02:19:59</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6990239</th>\n",
       "      <td>me7QTotYCOjWNVA8bzN1eg</td>\n",
       "      <td>bJ5FtCtZX3ZZacz2_2PJjA</td>\n",
       "      <td>wMQkdK2aNMvq2xoojC98Mw</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2007-07-27 20:12:11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6990240</th>\n",
       "      <td>5n_oSwXspiiSsZgNwjp48g</td>\n",
       "      <td>bJ5FtCtZX3ZZacz2_2PJjA</td>\n",
       "      <td>SOsjW1JARmtHUFtpFlp8rw</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2017-02-23 19:11:04</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>75469 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      review_id                 user_id  \\\n",
       "49       cvQXRFLCyr0S7EgFb4lZqw  ZGjgfSvjQK886kiTzLwfLQ   \n",
       "74       EZarjNNbO_2yH1Xbizog9g  R_W9WlKiA56VzVbRzTULQQ   \n",
       "101      pl5AjpEcFxFTltkBvHjsRA  YjS6MDNwGbueb5WtALIJ2A   \n",
       "135      WHBZtv1ZabwX0r-alDjA3g  x1qKiRxnPLf3JvOsUAsv_Q   \n",
       "243      uwPhE21CZLlp1kkSMPvvYw  5OnQqP3q2_9auNdDKpLdsw   \n",
       "...                         ...                     ...   \n",
       "6990047  jsBz-uJy6M--L8ogPG52dA  bJ5FtCtZX3ZZacz2_2PJjA   \n",
       "6990196  EQQWfhD7l2X767XHZykdDA  hVXj8lnaTIMLTkD_yjSj6A   \n",
       "6990234  oVH6oK8G_FTYiaglrIk09A  piIljcy0fhEW6IhB1eyrFA   \n",
       "6990239  me7QTotYCOjWNVA8bzN1eg  bJ5FtCtZX3ZZacz2_2PJjA   \n",
       "6990240  5n_oSwXspiiSsZgNwjp48g  bJ5FtCtZX3ZZacz2_2PJjA   \n",
       "\n",
       "                    business_id  useful  funny  cool                 date  \\\n",
       "49       EtKSTHV5Qx_Q7Aur9o4kQQ       3      1     1  2009-10-14 01:15:04   \n",
       "74       pR8u8hXf1vvzoAGOoKHQqQ       1      0     0  2016-08-25 17:17:46   \n",
       "101      EBn3U4mpnIRLIy2lKuilRQ       0      0     0  2012-11-06 18:54:49   \n",
       "135      GgGfhKUGusCbP-rvjHiS3A       0      0     0  2016-01-17 18:07:08   \n",
       "243      WKMJwqnfZKsAae75RMP6jA       0      0     0  2012-11-06 23:35:15   \n",
       "...                         ...     ...    ...   ...                  ...   \n",
       "6990047  mBgaPljP3OYkl_vGKTyFNw       4      1     4  2012-03-16 05:37:03   \n",
       "6990196  PlMXeyXhy1FcnvOSLBGFQQ       2      0     0  2020-09-11 19:03:01   \n",
       "6990234  oBNrLz4EDhiscSlbOl8uAw       0      1     0  2021-11-27 02:19:59   \n",
       "6990239  wMQkdK2aNMvq2xoojC98Mw       3      1     3  2007-07-27 20:12:11   \n",
       "6990240  SOsjW1JARmtHUFtpFlp8rw       5      2     5  2017-02-23 19:11:04   \n",
       "\n",
       "         checkin_count  \n",
       "49                   1  \n",
       "74                   1  \n",
       "101                  1  \n",
       "135                  1  \n",
       "243                  1  \n",
       "...                ...  \n",
       "6990047              1  \n",
       "6990196              1  \n",
       "6990234              1  \n",
       "6990239              1  \n",
       "6990240              1  \n",
       "\n",
       "[75469 rows x 8 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_df_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_saver(df, filename, framework):\n",
    "    if not os.path.exists(YELP_DIR + \"processed_data_\" + framework):\n",
    "        os.makedirs(YELP_DIR + \"processed_data_\" + framework)\n",
    "    \n",
    "    df.to_csv(YELP_DIR + \"processed_data_\" + framework + \"/\" + filename + \".csv\")\n",
    "    print(\"Data saved as \" + framework + filename + \".csv\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_saver_recbole(df, framework, suffix):\n",
    "    \n",
    "    if not os.path.exists(YELP_DIR + \"processed_data_\" + framework):\n",
    "        os.makedirs(YELP_DIR + \"processed_data_\" + framework)\n",
    "\n",
    "    df.to_csv(f\"{YELP_DIR}processed_data_{framework}/yelp_sample.{suffix}\", sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved as cornacuser_events.csv\n",
      "Data saved as cornacbusinesses.csv\n",
      "Data saved as cornachigh_pop_user_sample.csv\n",
      "Data saved as cornacmedium_pop_user_sample.csv\n",
      "Data saved as cornaclow_pop_user_sample.csv\n"
     ]
    }
   ],
   "source": [
    "# first of all saving data for cornac\n",
    "data_saver(review_df_sample, \"user_events\", \"cornac\")\n",
    "data_saver(business_df_sample, \"businesses\", \"cornac\")\n",
    "data_saver(high_pop_user_df_sample, \"high_pop_user_sample\", \"cornac\")\n",
    "data_saver(medium_pop_user_df_sample, \"medium_pop_user_sample\", \"cornac\")\n",
    "data_saver(low_pop_user_df_sample, \"low_pop_user_sample\", \"cornac\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"['stars'] not found in axis\"\n"
     ]
    }
   ],
   "source": [
    "# secondly making adjustments to the column names to fit the format in recbole\n",
    "review_df_sample_recbole = review_df_sample.copy()\n",
    "review_df_sample_recbole.rename(columns={\"user_id\":\"user_id:token\", \"business_id\":\"item_id:token\", \"checkin_count\":\"rating:float\", \"date\":\"timestamp:float\", \"useful\":\"useful:float\", \"funny\":\"funny:float\", \"cool\": \"cool:float\", \"review_id\": \"review_id:token\"}, inplace=True)\n",
    "try:\n",
    "    review_df_sample_recbole.drop(\"stars\", axis=1, inplace=True)\n",
    "    review_df_sample_recbole.drop(\"stars_bin\", axis=1, inplace=True)\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_df_sample_recbole = business_df_sample.copy()\n",
    "item_df_sample_recbole.rename(columns={\"business_id\":\"item_id:token\", \"name\":\"item_name_token_seq\", \"address\":\"address:token_seq\", \"city\":\"city:token_seq\", \"state\":\"state:token\", \"postal_code\":\"postal_code:token\", \"latitude\":\"latitude:float\", \"longitude\":\"longitude:float\", \"stars\":\"item_stars:float\", \"review_count\":\"item_review_count:float\", \"is_open\":\"is_open:float\", \"categories\":\"categories:token_seq\"}, inplace=True)\n",
    "\n",
    "try:\n",
    "    item_df_sample_recbole.drop([\"popularity\", \"attributes\", \"hours\"], axis=1, inplace=True)\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_df_sample_recbole = user_df_sample.copy()\n",
    "user_df_sample_recbole.rename(columns={\"user_id\":\"user_id:token\", \"name\":\"user_name:token\", \"review_count\":\"user_review_count:float\", \"yelping_since\":\"yelping_since:float\", \"useful\":\"user_useful:float\", \"funny\":\"user_funny:float\", \"cool\":\"user_cool:float\", \"elite\": \"elite:token\", \"fans\":\"fans:float\", \"average_stars\":\"average_stars:float\", \"compliment_hot\":\"compliment_hot:float\", \"compliment_more\":\"compliment_more:float\", \"compliment_profile\":\"compliment_profile:float\", \"compliment_cute\":\"compliment_cute:float\", \"compliment_list\":\"compliment_list:float\", \"compliment_note\":\"compliment_note:float\", \"compliment_plain\":\"compliment_plain:float\", \"compliment_cool\":\"compliment_cool:float\", \"compliment_funny\":\"compliment_funny:float\", \"compliment_writer\":\"compliment_writer:float\", \"compliment_photos\":\"compliment_photos:float\"}, inplace=True)\n",
    "try:\n",
    "    user_df_sample_recbole.drop([\"popularity\"], axis=1, inplace=True)\n",
    "except Exception as e:\n",
    "    print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_df_sample_recbole = review_df_sample_recbole.drop_duplicates(subset=[\"user_id:token\", \"item_id:token\"], keep=\"first\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id:token</th>\n",
       "      <th>user_id:token</th>\n",
       "      <th>item_id:token</th>\n",
       "      <th>useful:float</th>\n",
       "      <th>funny:float</th>\n",
       "      <th>cool:float</th>\n",
       "      <th>timestamp:float</th>\n",
       "      <th>rating:float</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>cvQXRFLCyr0S7EgFb4lZqw</td>\n",
       "      <td>ZGjgfSvjQK886kiTzLwfLQ</td>\n",
       "      <td>EtKSTHV5Qx_Q7Aur9o4kQQ</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2009-10-14 01:15:04</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>EZarjNNbO_2yH1Xbizog9g</td>\n",
       "      <td>R_W9WlKiA56VzVbRzTULQQ</td>\n",
       "      <td>pR8u8hXf1vvzoAGOoKHQqQ</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-08-25 17:17:46</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>pl5AjpEcFxFTltkBvHjsRA</td>\n",
       "      <td>YjS6MDNwGbueb5WtALIJ2A</td>\n",
       "      <td>EBn3U4mpnIRLIy2lKuilRQ</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2012-11-06 18:54:49</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>WHBZtv1ZabwX0r-alDjA3g</td>\n",
       "      <td>x1qKiRxnPLf3JvOsUAsv_Q</td>\n",
       "      <td>GgGfhKUGusCbP-rvjHiS3A</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-01-17 18:07:08</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>uwPhE21CZLlp1kkSMPvvYw</td>\n",
       "      <td>5OnQqP3q2_9auNdDKpLdsw</td>\n",
       "      <td>WKMJwqnfZKsAae75RMP6jA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2012-11-06 23:35:15</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6990047</th>\n",
       "      <td>jsBz-uJy6M--L8ogPG52dA</td>\n",
       "      <td>bJ5FtCtZX3ZZacz2_2PJjA</td>\n",
       "      <td>mBgaPljP3OYkl_vGKTyFNw</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2012-03-16 05:37:03</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6990196</th>\n",
       "      <td>EQQWfhD7l2X767XHZykdDA</td>\n",
       "      <td>hVXj8lnaTIMLTkD_yjSj6A</td>\n",
       "      <td>PlMXeyXhy1FcnvOSLBGFQQ</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-09-11 19:03:01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6990234</th>\n",
       "      <td>oVH6oK8G_FTYiaglrIk09A</td>\n",
       "      <td>piIljcy0fhEW6IhB1eyrFA</td>\n",
       "      <td>oBNrLz4EDhiscSlbOl8uAw</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-11-27 02:19:59</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6990239</th>\n",
       "      <td>me7QTotYCOjWNVA8bzN1eg</td>\n",
       "      <td>bJ5FtCtZX3ZZacz2_2PJjA</td>\n",
       "      <td>wMQkdK2aNMvq2xoojC98Mw</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2007-07-27 20:12:11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6990240</th>\n",
       "      <td>5n_oSwXspiiSsZgNwjp48g</td>\n",
       "      <td>bJ5FtCtZX3ZZacz2_2PJjA</td>\n",
       "      <td>SOsjW1JARmtHUFtpFlp8rw</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2017-02-23 19:11:04</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>71545 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                review_id:token           user_id:token  \\\n",
       "49       cvQXRFLCyr0S7EgFb4lZqw  ZGjgfSvjQK886kiTzLwfLQ   \n",
       "74       EZarjNNbO_2yH1Xbizog9g  R_W9WlKiA56VzVbRzTULQQ   \n",
       "101      pl5AjpEcFxFTltkBvHjsRA  YjS6MDNwGbueb5WtALIJ2A   \n",
       "135      WHBZtv1ZabwX0r-alDjA3g  x1qKiRxnPLf3JvOsUAsv_Q   \n",
       "243      uwPhE21CZLlp1kkSMPvvYw  5OnQqP3q2_9auNdDKpLdsw   \n",
       "...                         ...                     ...   \n",
       "6990047  jsBz-uJy6M--L8ogPG52dA  bJ5FtCtZX3ZZacz2_2PJjA   \n",
       "6990196  EQQWfhD7l2X767XHZykdDA  hVXj8lnaTIMLTkD_yjSj6A   \n",
       "6990234  oVH6oK8G_FTYiaglrIk09A  piIljcy0fhEW6IhB1eyrFA   \n",
       "6990239  me7QTotYCOjWNVA8bzN1eg  bJ5FtCtZX3ZZacz2_2PJjA   \n",
       "6990240  5n_oSwXspiiSsZgNwjp48g  bJ5FtCtZX3ZZacz2_2PJjA   \n",
       "\n",
       "                  item_id:token  useful:float  funny:float  cool:float  \\\n",
       "49       EtKSTHV5Qx_Q7Aur9o4kQQ             3            1           1   \n",
       "74       pR8u8hXf1vvzoAGOoKHQqQ             1            0           0   \n",
       "101      EBn3U4mpnIRLIy2lKuilRQ             0            0           0   \n",
       "135      GgGfhKUGusCbP-rvjHiS3A             0            0           0   \n",
       "243      WKMJwqnfZKsAae75RMP6jA             0            0           0   \n",
       "...                         ...           ...          ...         ...   \n",
       "6990047  mBgaPljP3OYkl_vGKTyFNw             4            1           4   \n",
       "6990196  PlMXeyXhy1FcnvOSLBGFQQ             2            0           0   \n",
       "6990234  oBNrLz4EDhiscSlbOl8uAw             0            1           0   \n",
       "6990239  wMQkdK2aNMvq2xoojC98Mw             3            1           3   \n",
       "6990240  SOsjW1JARmtHUFtpFlp8rw             5            2           5   \n",
       "\n",
       "             timestamp:float  rating:float  \n",
       "49       2009-10-14 01:15:04             1  \n",
       "74       2016-08-25 17:17:46             1  \n",
       "101      2012-11-06 18:54:49             1  \n",
       "135      2016-01-17 18:07:08             1  \n",
       "243      2012-11-06 23:35:15             1  \n",
       "...                      ...           ...  \n",
       "6990047  2012-03-16 05:37:03             1  \n",
       "6990196  2020-09-11 19:03:01             1  \n",
       "6990234  2021-11-27 02:19:59             1  \n",
       "6990239  2007-07-27 20:12:11             1  \n",
       "6990240  2017-02-23 19:11:04             1  \n",
       "\n",
       "[71545 rows x 8 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_df_sample_recbole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_df_sample_recbole[\"timestamp:float\"] = pd.to_datetime(review_df_sample_recbole[\"timestamp:float\"]).apply(lambda x: int(x.timestamp()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_df_sample_recbole = user_df_sample_recbole.drop([\"friends\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id:token</th>\n",
       "      <th>user_name:token</th>\n",
       "      <th>user_review_count:float</th>\n",
       "      <th>yelping_since:float</th>\n",
       "      <th>user_useful:float</th>\n",
       "      <th>user_funny:float</th>\n",
       "      <th>user_cool:float</th>\n",
       "      <th>elite:token</th>\n",
       "      <th>fans:float</th>\n",
       "      <th>average_stars:float</th>\n",
       "      <th>...</th>\n",
       "      <th>compliment_more:float</th>\n",
       "      <th>compliment_profile:float</th>\n",
       "      <th>compliment_cute:float</th>\n",
       "      <th>compliment_list:float</th>\n",
       "      <th>compliment_note:float</th>\n",
       "      <th>compliment_plain:float</th>\n",
       "      <th>compliment_cool:float</th>\n",
       "      <th>compliment_funny:float</th>\n",
       "      <th>compliment_writer:float</th>\n",
       "      <th>compliment_photos:float</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>55684</th>\n",
       "      <td>k1SkRKGIX2YZu98GoytWsg</td>\n",
       "      <td>Lisa</td>\n",
       "      <td>40</td>\n",
       "      <td>2011-12-05 00:54:47</td>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>3.93</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96103</th>\n",
       "      <td>xBqn1EyblQBPrCpSL_iu1A</td>\n",
       "      <td>Bronson</td>\n",
       "      <td>105</td>\n",
       "      <td>2010-09-01 21:27:19</td>\n",
       "      <td>226</td>\n",
       "      <td>78</td>\n",
       "      <td>139</td>\n",
       "      <td>2018,2019,20,20,2021</td>\n",
       "      <td>9</td>\n",
       "      <td>3.98</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64225</th>\n",
       "      <td>13ZAPxr6DPkzK71_nGNi3w</td>\n",
       "      <td>Carolina</td>\n",
       "      <td>328</td>\n",
       "      <td>2010-03-24 20:24:04</td>\n",
       "      <td>347</td>\n",
       "      <td>91</td>\n",
       "      <td>137</td>\n",
       "      <td>2014,2015,2016,2017,2018,2019,20,20,2021</td>\n",
       "      <td>15</td>\n",
       "      <td>3.80</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104498</th>\n",
       "      <td>3ZObaHG9jvLKboVUKPKQaA</td>\n",
       "      <td>Becca</td>\n",
       "      <td>319</td>\n",
       "      <td>2011-04-04 22:32:20</td>\n",
       "      <td>575</td>\n",
       "      <td>89</td>\n",
       "      <td>186</td>\n",
       "      <td>2013,2014,2015,2016,2017,2018,2019,20,20,2021</td>\n",
       "      <td>16</td>\n",
       "      <td>4.21</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18702</th>\n",
       "      <td>4l1qyHWA8iQyFeZl2cnc8g</td>\n",
       "      <td>Alisa</td>\n",
       "      <td>50</td>\n",
       "      <td>2014-05-03 23:49:01</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>4.22</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110839</th>\n",
       "      <td>PnLZNjlzeCBzWY4sfuOc8Q</td>\n",
       "      <td>Amy</td>\n",
       "      <td>22</td>\n",
       "      <td>2016-09-02 14:57:58</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>3.87</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30276</th>\n",
       "      <td>MK-IYG8gyI3liNvklNt7DQ</td>\n",
       "      <td>Crystal</td>\n",
       "      <td>14</td>\n",
       "      <td>2013-03-21 16:55:39</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>4.43</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86187</th>\n",
       "      <td>jBMZpYkoMueVzgO9FSti3w</td>\n",
       "      <td>Tom</td>\n",
       "      <td>10</td>\n",
       "      <td>2018-07-21 19:53:46</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>3.83</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54198</th>\n",
       "      <td>GjV7x4bM1o838d5XSUk0ww</td>\n",
       "      <td>Greg</td>\n",
       "      <td>39</td>\n",
       "      <td>2014-06-05 14:04:56</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>4.30</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108443</th>\n",
       "      <td>_7u7oUTjHbFHyJHtBkr5gw</td>\n",
       "      <td>K.</td>\n",
       "      <td>14</td>\n",
       "      <td>2019-10-29 17:57:17</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>4.21</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 user_id:token user_name:token  user_review_count:float  \\\n",
       "55684   k1SkRKGIX2YZu98GoytWsg            Lisa                       40   \n",
       "96103   xBqn1EyblQBPrCpSL_iu1A         Bronson                      105   \n",
       "64225   13ZAPxr6DPkzK71_nGNi3w        Carolina                      328   \n",
       "104498  3ZObaHG9jvLKboVUKPKQaA           Becca                      319   \n",
       "18702   4l1qyHWA8iQyFeZl2cnc8g           Alisa                       50   \n",
       "...                        ...             ...                      ...   \n",
       "110839  PnLZNjlzeCBzWY4sfuOc8Q             Amy                       22   \n",
       "30276   MK-IYG8gyI3liNvklNt7DQ         Crystal                       14   \n",
       "86187   jBMZpYkoMueVzgO9FSti3w             Tom                       10   \n",
       "54198   GjV7x4bM1o838d5XSUk0ww            Greg                       39   \n",
       "108443  _7u7oUTjHbFHyJHtBkr5gw              K.                       14   \n",
       "\n",
       "        yelping_since:float  user_useful:float  user_funny:float  \\\n",
       "55684   2011-12-05 00:54:47                 21                 2   \n",
       "96103   2010-09-01 21:27:19                226                78   \n",
       "64225   2010-03-24 20:24:04                347                91   \n",
       "104498  2011-04-04 22:32:20                575                89   \n",
       "18702   2014-05-03 23:49:01                 10                 5   \n",
       "...                     ...                ...               ...   \n",
       "110839  2016-09-02 14:57:58                  4                 1   \n",
       "30276   2013-03-21 16:55:39                 11                 0   \n",
       "86187   2018-07-21 19:53:46                  5                 0   \n",
       "54198   2014-06-05 14:04:56                 35                 1   \n",
       "108443  2019-10-29 17:57:17                  4                 0   \n",
       "\n",
       "        user_cool:float                                    elite:token  \\\n",
       "55684                 5                                                  \n",
       "96103               139                           2018,2019,20,20,2021   \n",
       "64225               137       2014,2015,2016,2017,2018,2019,20,20,2021   \n",
       "104498              186  2013,2014,2015,2016,2017,2018,2019,20,20,2021   \n",
       "18702                 6                                                  \n",
       "...                 ...                                            ...   \n",
       "110839                0                                                  \n",
       "30276                 0                                                  \n",
       "86187                 4                                                  \n",
       "54198                10                                                  \n",
       "108443                0                                                  \n",
       "\n",
       "        fans:float  average_stars:float  ...  compliment_more:float  \\\n",
       "55684            0                 3.93  ...                      0   \n",
       "96103            9                 3.98  ...                      2   \n",
       "64225           15                 3.80  ...                      1   \n",
       "104498          16                 4.21  ...                      5   \n",
       "18702            0                 4.22  ...                      0   \n",
       "...            ...                  ...  ...                    ...   \n",
       "110839           0                 3.87  ...                      0   \n",
       "30276            0                 4.43  ...                      0   \n",
       "86187            0                 3.83  ...                      0   \n",
       "54198            0                 4.30  ...                      0   \n",
       "108443           0                 4.21  ...                      0   \n",
       "\n",
       "        compliment_profile:float  compliment_cute:float  \\\n",
       "55684                          0                      0   \n",
       "96103                          0                      0   \n",
       "64225                          0                      0   \n",
       "104498                         1                      0   \n",
       "18702                          0                      0   \n",
       "...                          ...                    ...   \n",
       "110839                         0                      0   \n",
       "30276                          0                      0   \n",
       "86187                          0                      0   \n",
       "54198                          0                      0   \n",
       "108443                         0                      0   \n",
       "\n",
       "        compliment_list:float  compliment_note:float  compliment_plain:float  \\\n",
       "55684                       0                      1                       0   \n",
       "96103                       0                      5                       8   \n",
       "64225                       0                     10                       3   \n",
       "104498                      0                      7                      14   \n",
       "18702                       0                      1                       0   \n",
       "...                       ...                    ...                     ...   \n",
       "110839                      0                      1                       0   \n",
       "30276                       0                      0                       1   \n",
       "86187                       0                      0                       0   \n",
       "54198                       0                      0                       0   \n",
       "108443                      0                      0                       0   \n",
       "\n",
       "        compliment_cool:float  compliment_funny:float  \\\n",
       "55684                       0                       0   \n",
       "96103                       7                       7   \n",
       "64225                      32                      32   \n",
       "104498                     20                      20   \n",
       "18702                       0                       0   \n",
       "...                       ...                     ...   \n",
       "110839                      0                       0   \n",
       "30276                       0                       0   \n",
       "86187                       0                       0   \n",
       "54198                       0                       0   \n",
       "108443                      0                       0   \n",
       "\n",
       "        compliment_writer:float  compliment_photos:float  \n",
       "55684                         1                        0  \n",
       "96103                         5                        5  \n",
       "64225                         4                        1  \n",
       "104498                       13                       10  \n",
       "18702                         0                        0  \n",
       "...                         ...                      ...  \n",
       "110839                        1                        0  \n",
       "30276                         0                        0  \n",
       "86187                         0                        0  \n",
       "54198                         0                        0  \n",
       "108443                        0                        0  \n",
       "\n",
       "[3000 rows x 21 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_df_sample_recbole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_saver_recbole(review_df_sample_recbole, \"recbole\", \"inter\")\n",
    "data_saver_recbole(user_df_sample_recbole, \"recbole\", \"user\")\n",
    "data_saver_recbole(item_df_sample_recbole, \"recbole\", \"item\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method IPythonKernel._clean_thread_parent_frames of <ipykernel.ipkernel.IPythonKernel object at 0x105f59550>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/andreaforster/dev/thesis/preprocessing/prep_venv/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 775, in _clean_thread_parent_frames\n",
      "    def _clean_thread_parent_frames(\n",
      "\n",
      "KeyboardInterrupt: \n"
     ]
    }
   ],
   "source": [
    "# convert time stamp to unix format for temporal splitting\n",
    "\n",
    "def convert_timestamp_to_unix(input_path,output_path,timestamp_column):\n",
    "    # Read the CSV file\n",
    "    df = pd.read_csv(input_path, sep='\\t')\n",
    "\n",
    "    # Convert the timestamp column to UNIX format\n",
    "    df[timestamp_column] = pd.to_datetime(df[timestamp_column]).apply(lambda x: int(x.timestamp()))\n",
    "\n",
    "    \n",
    "    # Save the updated DataFrame to a new CSV file\n",
    "    df.to_csv(output_path, sep='\\t', index=False)\n",
    "\n",
    "\n",
    "# Define input and output paths\n",
    "framework = \"recbole\"\n",
    "suffix = \"inter\"\n",
    "timestamp_column = \"timestamp:float\"  # replace with the name of your timestamp column\n",
    "\n",
    "input_path = os.path.join(YELP_DIR, f\"processed_data_{framework}/yelp_sample.{suffix}\")\n",
    "output_path = os.path.join(YELP_DIR, f\"processed_data_{framework}/yelp_sample_unix.{suffix}\")\n",
    "\n",
    "# Convert timestamps and save the new file\n",
    "convert_timestamp_to_unix(input_path, output_path,timestamp_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lastly, getting the data ready for CAPRI the POI recommendation framework\n",
    "\n",
    "business_df_sample = pd.read_csv(YELP_DIR + \"processed_data_cornac/businesses.csv\", index_col=0)\n",
    "review_df_sample = pd.read_csv(YELP_DIR + \"processed_data_cornac/user_events.csv\", index_col=0)\n",
    "high_pop_user_df_sample = pd.read_csv(YELP_DIR + \"processed_data_cornac/high_pop_user_sample.csv\", index_col=0)\n",
    "medium_pop_user_df_sample = pd.read_csv(YELP_DIR + \"processed_data_cornac/medium_pop_user_sample.csv\", index_col=0)\n",
    "low_pop_user_df_sample = pd.read_csv(YELP_DIR + \"processed_data_cornac/low_pop_user_sample.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>business_id</th>\n",
       "      <th>useful</th>\n",
       "      <th>funny</th>\n",
       "      <th>cool</th>\n",
       "      <th>date</th>\n",
       "      <th>checkin_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1338449</th>\n",
       "      <td>BXQ8clxxE04aFt2rlsOc5Q</td>\n",
       "      <td>Sa6MxEeKd8euwZTsid4Tkg</td>\n",
       "      <td>I220i0Sx3jkkO_1EzLo7QA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-04-27 01:48:20</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1260799</th>\n",
       "      <td>ATne4P-jh4IXcoaAMUJr-g</td>\n",
       "      <td>Sa6MxEeKd8euwZTsid4Tkg</td>\n",
       "      <td>I220i0Sx3jkkO_1EzLo7QA</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-07-11 00:17:10</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1308431</th>\n",
       "      <td>vC6ZSrLs7HH1r0-VCv2FyA</td>\n",
       "      <td>Sa6MxEeKd8euwZTsid4Tkg</td>\n",
       "      <td>I220i0Sx3jkkO_1EzLo7QA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-07-14 23:38:20</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1253548</th>\n",
       "      <td>s3audIDspfa65P8UYjMYRQ</td>\n",
       "      <td>Sa6MxEeKd8euwZTsid4Tkg</td>\n",
       "      <td>I220i0Sx3jkkO_1EzLo7QA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-10-05 15:59:04</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1285864</th>\n",
       "      <td>yn10HPu03MF-EITPOymmMA</td>\n",
       "      <td>Sa6MxEeKd8euwZTsid4Tkg</td>\n",
       "      <td>I220i0Sx3jkkO_1EzLo7QA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-09-30 19:42:01</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2413375</th>\n",
       "      <td>tDJteE67q1HWRN6Wj3qT7Q</td>\n",
       "      <td>pBTvkU93L9vaIxvCQOur_Q</td>\n",
       "      <td>p73i2GDzPRZJbYBa8qtpSQ</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2013-02-12 23:33:27</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2413403</th>\n",
       "      <td>QhKurTx5_BnpuMPhRWbFfw</td>\n",
       "      <td>dKRYOegmDF4eJ0PssDsCRw</td>\n",
       "      <td>me3mlZsR26fV89fMw2uR6Q</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2015-01-29 18:37:49</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2413423</th>\n",
       "      <td>7Vkvl3N0isYha2ugO6uusQ</td>\n",
       "      <td>B4KEizUmIP-UzhHjxxS_VA</td>\n",
       "      <td>cE8U_UdSFT4U7rsLqFhZig</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2014-06-24 12:11:27</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2413434</th>\n",
       "      <td>ixKQ9QsFvX5RB_Qx6RfX2A</td>\n",
       "      <td>iCNiJk_p3LPfrZaUwUe1ag</td>\n",
       "      <td>vC2vhaJmX1RpExoHcPOb_A</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-01-16 18:18:51</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6990240</th>\n",
       "      <td>5n_oSwXspiiSsZgNwjp48g</td>\n",
       "      <td>bJ5FtCtZX3ZZacz2_2PJjA</td>\n",
       "      <td>SOsjW1JARmtHUFtpFlp8rw</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2017-02-23 19:11:04</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>75469 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      review_id                 user_id  \\\n",
       "1338449  BXQ8clxxE04aFt2rlsOc5Q  Sa6MxEeKd8euwZTsid4Tkg   \n",
       "1260799  ATne4P-jh4IXcoaAMUJr-g  Sa6MxEeKd8euwZTsid4Tkg   \n",
       "1308431  vC6ZSrLs7HH1r0-VCv2FyA  Sa6MxEeKd8euwZTsid4Tkg   \n",
       "1253548  s3audIDspfa65P8UYjMYRQ  Sa6MxEeKd8euwZTsid4Tkg   \n",
       "1285864  yn10HPu03MF-EITPOymmMA  Sa6MxEeKd8euwZTsid4Tkg   \n",
       "...                         ...                     ...   \n",
       "2413375  tDJteE67q1HWRN6Wj3qT7Q  pBTvkU93L9vaIxvCQOur_Q   \n",
       "2413403  QhKurTx5_BnpuMPhRWbFfw  dKRYOegmDF4eJ0PssDsCRw   \n",
       "2413423  7Vkvl3N0isYha2ugO6uusQ  B4KEizUmIP-UzhHjxxS_VA   \n",
       "2413434  ixKQ9QsFvX5RB_Qx6RfX2A  iCNiJk_p3LPfrZaUwUe1ag   \n",
       "6990240  5n_oSwXspiiSsZgNwjp48g  bJ5FtCtZX3ZZacz2_2PJjA   \n",
       "\n",
       "                    business_id  useful  funny  cool                 date  \\\n",
       "1338449  I220i0Sx3jkkO_1EzLo7QA       0      0     0  2017-04-27 01:48:20   \n",
       "1260799  I220i0Sx3jkkO_1EzLo7QA       1      0     0  2018-07-11 00:17:10   \n",
       "1308431  I220i0Sx3jkkO_1EzLo7QA       0      0     0  2019-07-14 23:38:20   \n",
       "1253548  I220i0Sx3jkkO_1EzLo7QA       0      0     0  2017-10-05 15:59:04   \n",
       "1285864  I220i0Sx3jkkO_1EzLo7QA       0      0     0  2016-09-30 19:42:01   \n",
       "...                         ...     ...    ...   ...                  ...   \n",
       "2413375  p73i2GDzPRZJbYBa8qtpSQ       0      0     0  2013-02-12 23:33:27   \n",
       "2413403  me3mlZsR26fV89fMw2uR6Q       0      0     0  2015-01-29 18:37:49   \n",
       "2413423  cE8U_UdSFT4U7rsLqFhZig       0      0     0  2014-06-24 12:11:27   \n",
       "2413434  vC2vhaJmX1RpExoHcPOb_A       0      0     0  2018-01-16 18:18:51   \n",
       "6990240  SOsjW1JARmtHUFtpFlp8rw       5      2     5  2017-02-23 19:11:04   \n",
       "\n",
       "         checkin_count  \n",
       "1338449             12  \n",
       "1260799             12  \n",
       "1308431             12  \n",
       "1253548             12  \n",
       "1285864             12  \n",
       "...                ...  \n",
       "2413375              1  \n",
       "2413403              1  \n",
       "2413423              1  \n",
       "2413434              1  \n",
       "6990240              1  \n",
       "\n",
       "[75469 rows x 8 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_df_sample.sort_values(by=\"checkin_count\", ascending=False)\n",
    "\n",
    "review_df_sample[\"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of users: 7135, number of POIs: 16621, number of categories: 595\n",
      "Length of train, test, tune:  196866 61344 27398\n",
      "... and in percent of the total data:  0.6524077639658926 0.2032920965160247 0.09079611470308498\n"
     ]
    }
   ],
   "source": [
    "reference_checkins = pd.read_csv(f'{ORIGINAL_DATA_FOLDER}checkins.txt', sep='\\s+', header=None, names=['user_id', 'item_id', 'checkin_timestamp'])\n",
    "reference_categories = pd.read_csv(f'{ORIGINAL_DATA_FOLDER}poiCategories.txt', sep='\\s+', header=None, names=['item_id', 'category_id'])\n",
    "print(f\"Number of users: {len(reference_checkins['user_id'].unique())}, number of POIs: {len(reference_checkins['item_id'].unique())}, number of categories: {len(reference_categories['category_id'].unique())}\")\n",
    "reference_datasize = pd.read_csv(f'{ORIGINAL_DATA_FOLDER}datasize.txt', sep='\\s+', header=None, names=['num_users', 'num_items', 'num_categories'])\n",
    "reference_coos = pd.read_csv(f'{ORIGINAL_DATA_FOLDER}poiCoos.txt', sep='\\s+', header=None, names=['item_id', 'latitude', 'longitude'])\n",
    "reference_socials = pd.read_csv(f'{ORIGINAL_DATA_FOLDER}socialRelations.txt', sep='\\s+', header=None, names=['user_id', 'user_id_friend'])\n",
    "\n",
    "\n",
    "reference_test = pd.read_csv(f'{ORIGINAL_DATA_FOLDER}test.txt', sep='\\s+', header=None, names=['user_id', 'item_id', 'no_checkins'])\n",
    "reference_train = pd.read_csv(f'{ORIGINAL_DATA_FOLDER}train.txt', sep='\\s+', header=None, names=['user_id', 'item_id', 'no_checkins'])\n",
    "reference_tune = pd.read_csv(f'{ORIGINAL_DATA_FOLDER}tune.txt', sep='\\s+', header=None, names=['user_id', 'item_id', 'no_checkins'])\n",
    "\n",
    "print(\"Length of train, test, tune: \", len(reference_train), len(reference_test), len(reference_tune))\n",
    "print(\"... and in percent of the total data: \", len(reference_train) / len(reference_checkins), len(reference_test) / len(reference_checkins), len(reference_tune) / len(reference_checkins))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_users</th>\n",
       "      <th>num_items</th>\n",
       "      <th>num_categories</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7135</td>\n",
       "      <td>16621</td>\n",
       "      <td>595</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   num_users  num_items  num_categories\n",
       "0       7135      16621             595"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reference_datasize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# since in this dataset there are no repeated check-ins, we will test out the binary implicit feedback approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_unix_timestamp(df, column_name):\n",
    "    \"\"\"\n",
    "    Convert a column of timestamps in a DataFrame to Unix timestamps.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The DataFrame containing the timestamp column.\n",
    "        column_name (str): The name of the column with timestamps in \"%Y-%m-%d %H:%M:%S\" format.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The DataFrame with an additional column for Unix timestamps.\n",
    "    \"\"\"\n",
    "    # Convert the column to datetime objects\n",
    "    df[column_name] = pd.to_datetime(df[column_name], format=\"%Y-%m-%d %H:%M:%S\")\n",
    "    \n",
    "    # Convert datetime objects to Unix timestamps\n",
    "    df[f'{column_name}_unix'] = df[column_name].apply(lambda x: x.timestamp())\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unstack_categories(df, column_name):\n",
    "    \"\"\"\n",
    "    Unstack a DataFrame column with comma-separated categories into separate rows.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The input DataFrame.\n",
    "        column_name (str): The name of the column with comma-separated categories.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The DataFrame with each category in a separate row.\n",
    "    \"\"\"\n",
    "    # Split the categories into lists\n",
    "    df[column_name] = df[column_name].str.split(', ')\n",
    "    \n",
    "    # Explode the lists into separate rows\n",
    "    df = df.explode(column_name)\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def factorize_categories(df, column_name):\n",
    "    \"\"\"\n",
    "    Factorize categories in a DataFrame column into unique integer codes.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The input DataFrame.\n",
    "        column_name (str): The name of the column with categories.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The DataFrame with factorized categories.\n",
    "        pd.Index: The unique categories found in the column.\n",
    "    \"\"\"\n",
    "    # Factorize the categories\n",
    "    df[column_name + '_codes'], unique_categories = pd.factorize(df[column_name])\n",
    "\n",
    "    return df, unique_categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reverting to unix timestamps and only using the necessary columns\n",
    "review_df_sample = convert_to_unix_timestamp(review_df_sample, \"date\")\n",
    "#ALMOST FINAL - STARS_BIN MUST BE REMOVED FOR checkins.txt AND date_unix FOR train/test/tune.txt\n",
    "checkins_capri_min = review_df_sample[[\"user_id\", \"business_id\", \"date_unix\"]]\n",
    "checkins_capri_train_test_tune = review_df_sample[[\"user_id\", \"business_id\", \"date_unix\", \"checkin_count\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9q/p0b6nwnd5071040x3849mdvc0000gn/T/ipykernel_20615/3621935470.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[column_name] = df[column_name].str.split(', ')\n"
     ]
    }
   ],
   "source": [
    "categories_capri = unstack_categories(business_df_sample, \"categories\")\n",
    "categories_capri[\"category_id\"], unique_categories = pd.factorize(categories_capri[\"categories\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtering out categories with less than 10 POIs\n",
    "category_counts = categories_capri[\"category_id\"].value_counts()\n",
    "mask = categories_capri[\"category_id\"].map(category_counts) >= 10\n",
    "categories_capri = categories_capri.loc[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FINAL 2\n",
    "categories_capri_min = categories_capri[[\"business_id\", \"category_id\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of users:  3000\n",
      "Length of POIs:  35278\n",
      "Length of categories_capri_min:  645\n"
     ]
    }
   ],
   "source": [
    "len(checkins_capri_min[\"user_id\"].unique())\n",
    "len(checkins_capri_min[\"business_id\"].unique())\n",
    "len(categories_capri_min[\"category_id\"].unique())\n",
    "\n",
    "print(\"Length of users: \", len(checkins_capri_min[\"user_id\"].unique()))\n",
    "print(\"Length of POIs: \", len(checkins_capri_min[\"business_id\"].unique()))\n",
    "print(\"Length of categories_capri_min: \", len(categories_capri_min[\"category_id\"].unique()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FINAL 3\n",
    "datasize_capri = pd.DataFrame(data={\"num_users\" : [len(checkins_capri_min[\"user_id\"].unique())], \"num_items\" : [len(checkins_capri_min[\"business_id\"].unique())], \"num_categories\" : [len(categories_capri_min[\"category_id\"].unique())]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FINAL 4\n",
    "poi_coos_capri = business_df_sample[[\"business_id\", \"latitude\", \"longitude\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_df_sample = pd.concat([high_pop_user_df_sample, medium_pop_user_df_sample, low_pop_user_df_sample])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "social_relations_capri = unstack_categories(user_df_sample, \"friends\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtering out friends so only those that are in the subset are listed as friends\n",
    "users = list(social_relations_capri[\"user_id\"].unique())\n",
    "social_relations_min = social_relations_capri.loc[social_relations_capri[\"friends\"].isin(users)]\n",
    "# FINAL 5\n",
    "social_relations_min = social_relations_min[[\"user_id\", \"friends\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9q/p0b6nwnd5071040x3849mdvc0000gn/T/ipykernel_20615/606899870.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  checkins_capri_min['user_id_int'], user_id_map = pd.factorize(checkins_capri_min['user_id'])\n",
      "/var/folders/9q/p0b6nwnd5071040x3849mdvc0000gn/T/ipykernel_20615/606899870.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  checkins_capri_min['business_id_int'], business_id_map = pd.factorize(checkins_capri_min['business_id'])\n"
     ]
    }
   ],
   "source": [
    "checkins_capri_min['user_id_int'], user_id_map = pd.factorize(checkins_capri_min['user_id'])\n",
    "checkins_capri_min['business_id_int'], business_id_map = pd.factorize(checkins_capri_min['business_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FINAL 2.0\n",
    "checkins_capri_min_int = checkins_capri_min[[\"user_id_int\", \"business_id_int\", \"date_unix\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create mapping dictionaries\n",
    "user_id_mapping = {original: i for i, original in enumerate(user_id_map)}\n",
    "business_id_mapping = {original: i for i, original in enumerate(business_id_map)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9q/p0b6nwnd5071040x3849mdvc0000gn/T/ipykernel_20615/1417031790.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  categories_capri_min['business_id_int'] = categories_capri_min['business_id'].map(business_id_mapping)\n"
     ]
    }
   ],
   "source": [
    "categories_capri_min['business_id_int'] = categories_capri_min['business_id'].map(business_id_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FINAL 2.0 \n",
    "categories_capri_min_int = categories_capri_min[[\"business_id_int\", \"category_id\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9q/p0b6nwnd5071040x3849mdvc0000gn/T/ipykernel_20615/209793819.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  poi_coos_capri[\"business_id_int\"] = poi_coos_capri[\"business_id\"].map(business_id_mapping)\n"
     ]
    }
   ],
   "source": [
    "poi_coos_capri[\"business_id_int\"] = poi_coos_capri[\"business_id\"].map(business_id_mapping)\n",
    "# FINAL 2.0\n",
    "poi_coos_capri_int = poi_coos_capri[[\"business_id_int\", \"latitude\", \"longitude\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "social_relations_min['user_id_int'] = social_relations_min['user_id'].map(user_id_mapping)\n",
    "social_relations_min[\"friends_int\"] = social_relations_min[\"friends\"].map(user_id_mapping)\n",
    "# FINAL 2.0\n",
    "social_relations_min_int = social_relations_min[[\"user_id_int\", \"friends_int\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9q/p0b6nwnd5071040x3849mdvc0000gn/T/ipykernel_20615/1750645828.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  checkins_capri_train_test_tune['user_id_int'] = checkins_capri_train_test_tune['user_id'].map(user_id_mapping)\n",
      "/var/folders/9q/p0b6nwnd5071040x3849mdvc0000gn/T/ipykernel_20615/1750645828.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  checkins_capri_train_test_tune['business_id_int'] = checkins_capri_train_test_tune['business_id'].map(business_id_mapping)\n"
     ]
    }
   ],
   "source": [
    "checkins_capri_train_test_tune['user_id_int'] = checkins_capri_train_test_tune['user_id'].map(user_id_mapping)\n",
    "checkins_capri_train_test_tune['business_id_int'] = checkins_capri_train_test_tune['business_id'].map(business_id_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Set:\n",
      "         user_id_int  business_id_int  checkin_count\n",
      "6303988            0            31917              1\n",
      "6339649            0            31771              1\n",
      "3810321            0            19666              1\n",
      "1220922            0             4027              1\n",
      "3843050            0            19819              1\n",
      "\n",
      "Validation Set:\n",
      "         user_id_int  business_id_int  checkin_count\n",
      "1217978            0             4240              1\n",
      "5992674            0            28981              1\n",
      "4743551            0            24117              1\n",
      "2435811            0            12435              1\n",
      "4357977            0            21150              1\n",
      "\n",
      "Test Set:\n",
      "         user_id_int  business_id_int  checkin_count\n",
      "2966116            0            14323              1\n",
      "1549974            0             7868              1\n",
      "3545077            0            18107              1\n",
      "2840083            0            14453              1\n",
      "1569488            0             8297              1\n"
     ]
    }
   ],
   "source": [
    "# splitting the data into train, test, and tune\n",
    "checkins_capri_train_test_tune = checkins_capri_train_test_tune.sort_values(by=[\"user_id_int\", \"date_unix\"])\n",
    "checkins_capri_train_test_tune = checkins_capri_train_test_tune[[\"user_id_int\", \"business_id_int\", \"checkin_count\"]]\n",
    "\n",
    "# Split the data\n",
    "train_list = []\n",
    "val_list = []\n",
    "test_list = []\n",
    "\n",
    "for user, group in checkins_capri_train_test_tune.groupby('user_id_int'):\n",
    "    n = len(group)\n",
    "    train_end = int(n * 0.65)\n",
    "    val_end = int(n * 0.80)\n",
    "    \n",
    "    train_list.append(group.iloc[:train_end])\n",
    "    val_list.append(group.iloc[train_end:val_end])\n",
    "    test_list.append(group.iloc[val_end:])\n",
    "\n",
    "# Combine lists into DataFrames\n",
    "train_df = pd.concat(train_list)\n",
    "val_df = pd.concat(val_list)\n",
    "test_df = pd.concat(test_list)\n",
    "\n",
    "\n",
    "\n",
    "# Check the splits\n",
    "\n",
    "# FINAL 6-8\n",
    "print(\"Train Set:\")\n",
    "print(train_df.head())\n",
    "print(\"\\nValidation Set:\")\n",
    "print(val_df.head())\n",
    "print(\"\\nTest Set:\")\n",
    "print(test_df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "******"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def datasaver_capri(df, filename):\n",
    "    \n",
    "    if not os.path.exists(YELP_DIR + \"processed_data_capri\"):\n",
    "        os.makedirs(YELP_DIR + \"processed_data_capri\")\n",
    "    \n",
    "    df.to_csv(YELP_DIR + \"processed_data_capri/\" + filename + \".txt\", sep='\\t', index=False, header=False)\n",
    "    print(\"Data saved as \" + filename + \".txt\")\n",
    "    \n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved as checkins.txt\n",
      "Data saved as dataSize.txt\n",
      "Data saved as poiCategories.txt\n",
      "Data saved as poiCoos.txt\n",
      "Data saved as socialRelations.txt\n",
      "Data saved as train.txt\n",
      "Data saved as tune.txt\n",
      "Data saved as test.txt\n"
     ]
    }
   ],
   "source": [
    "datasaver_capri(checkins_capri_min_int, \"checkins\")\n",
    "datasaver_capri(datasize_capri, \"dataSize\")\n",
    "datasaver_capri(categories_capri_min_int, \"poiCategories\")\n",
    "datasaver_capri(poi_coos_capri_int, \"poiCoos\")\n",
    "datasaver_capri(social_relations_min_int, \"socialRelations\")\n",
    "datasaver_capri(train_df, \"train\")\n",
    "datasaver_capri(val_df, \"tune\")\n",
    "datasaver_capri(test_df, \"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next To-Do's: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Potentially changing the hash's to numeric id's\n",
    "\n",
    "constructing a train, test and tuning set with all the user'id's present in each set "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
